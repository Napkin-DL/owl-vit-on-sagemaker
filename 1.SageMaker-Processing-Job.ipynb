{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "671a9042-54fc-4b4d-a568-c28485f942d8",
   "metadata": {},
   "source": [
    "# 1. SageMaker Processing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f30f03e-c48a-47cc-8102-6ca49a74a002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "install_needed = True\n",
    "# install_needed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd0129cf-804d-4476-8dbf-30fbafdd4660",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already revised\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "\n",
    "DAEMON_PATH=\"/etc/docker\"\n",
    "MEMORY_SIZE=10G\n",
    "\n",
    "FLAG=$(cat $DAEMON_PATH/daemon.json | jq 'has(\"data-root\")')\n",
    "# echo $FLAG\n",
    "\n",
    "if [ \"$FLAG\" == true ]; then\n",
    "    echo \"Already revised\"\n",
    "else\n",
    "    sudo service docker stop\n",
    "    echo \"Add data-root and default-shm-size=$MEMORY_SIZE\"\n",
    "    sudo cp $DAEMON_PATH/daemon.json $DAEMON_PATH/daemon.json.bak\n",
    "    sudo cat $DAEMON_PATH/daemon.json.bak | jq '. += {\"data-root\":\"/home/ec2-user/SageMaker/.container/docker\",\"default-shm-size\":\"'$MEMORY_SIZE'\"}' | sudo tee $DAEMON_PATH/daemon.json > /dev/null\n",
    "    sudo rsync -aP /var/lib/docker /home/ec2-user/SageMaker/.container\n",
    "    sudo service docker start\n",
    "    echo \"Docker Restart\"\n",
    "fi\n",
    "\n",
    "# sudo curl -L \"https://github.com/docker/compose/releases/download/v2.7.0/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n",
    "# sudo chmod +x /usr/local/bin/docker-compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aa57513-d4fe-401a-b7c9-69922db6c9bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installing deps and restarting kernel\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install --upgrade pip --quiet\n",
    "    !{sys.executable} -m pip install -U sagemaker huggingface_hub transformers --quiet\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370522f7-db75-4f8f-8b1c-6c7a24afed58",
   "metadata": {},
   "source": [
    "![image](./imgs/processing-job-image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe18e0fb-d4a3-4ed3-a9e5-7a42786e0c95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import huggingface_hub\n",
    "from pathlib import Path\n",
    "from time import strftime\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer\n",
    ")\n",
    "import torch\n",
    "\n",
    "\n",
    "source_dir = f\"{Path.cwd()}/src\"\n",
    "os.makedirs(source_dir, exist_ok=True)\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"240929-owl-vit\"\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c290195e-6f5e-40e8-8eb9-8226b77592aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['HF_DATASETS_CACHE'] = '/home/ec2-user/SageMaker/.cache'\n",
    "os.environ['HF_CACHE_HOME'] = '/home/ec2-user/SageMaker/.cache'\n",
    "os.environ['HUGGINGFACE_HUB_CACHE'] = '/home/ec2-user/SageMaker/.cache'\n",
    "# os.environ['TRANSFORMERS_HOME'] = '/home/ec2-user/SageMaker/.cache'\n",
    "# os.environ['HF_HOME'] = '/home/ec2-user/SageMaker/.cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1296f331-7b59-43c3-9e19-5340974acf2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_model_id = 'google/owlvit-base-patch32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10f3fef9-ab65-4d6f-9045-dad0e8b9580a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab90453ab59b49dd8c4f8be4b234b27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "huggingface_hub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53c6d76f-8657-49aa-a6ab-f663abc3f49c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registered_model : owlvit-base-patch32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de37d63cb3304cba8b9f507ba74e0aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52f8b72ac3c4520b33915495ecdb7e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/613M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77a49b4da1a49f0a681a122501f4db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/392 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60cc4e2fa8943849e18d22917c9f861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e446882e32904d629b87028a07d84467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/613M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faae935ae2734291a3ca252fc6bb2180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1380414b0d6b4fcd8f5518da54fe3621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa74cb3da3e5467dbc1d6396f14aeef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072f9a1cf6da4bcfa1129f2ddbc6401e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/775 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c695ceeb7a4480976859a389f7791b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808acc6a8653403e8cfa326bc5ca4a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/owl-vit-on-sagemaker/owlvit-base-patch32'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registered_model = test_model_id.split(\"/\")[-1].lower().replace(\".\", \"-\")\n",
    "print(f\"registered_model : {registered_model}\")\n",
    "os.makedirs(registered_model, exist_ok=True)\n",
    "\n",
    "huggingface_hub.snapshot_download(\n",
    "    repo_id=test_model_id,\n",
    "    revision=\"main\",\n",
    "    local_dir=registered_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adcf7c62-bfdd-4755-b2e5-1635cea1e405",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'owlvit-base-patch32'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model_weight = test_model_id.split(\"/\")[-1].lower().replace(\".\", \"-\")\n",
    "local_model_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4c01521-7a5e-4057-9d33-37eadbaf4604",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weight spec (in this case, just an S3 path): s3://sagemaker-us-east-1-714932599119/240929-owl-vit/owlvit-base-patch32\n"
     ]
    }
   ],
   "source": [
    "s3_model_weight_path = sagemaker_session.upload_data(path=f'./{local_model_weight}', bucket=bucket, key_prefix=f\"{prefix}/{local_model_weight}\")\n",
    "print('Model weight spec (in this case, just an S3 path): {}'.format(s3_model_weight_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e841f6-f69b-4ad7-ac6a-763167805d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_input_data_path = sagemaker_session.upload_data(path=f'./ecommerce-products', bucket=bucket, key_prefix=f\"{prefix}/ecommerce-products\")\n",
    "print('input spec (in this case, just an S3 path): {}'.format(s3_input_data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba55141-586a-482c-a4de-b2c6b7f4fd1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "len(glob.glob(\"./ecommerce-products/tv/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25453a0b-9cba-4704-8600-4f2e4551f959",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile src/requirements.txt\n",
    "transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbed9ce0-2378-44ef-beb9-ef8cfc337d2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile src/evaluation.py\n",
    "import os\n",
    "import csv\n",
    "import glob\n",
    "import requests\n",
    "from PIL import Image\n",
    "import torch\n",
    "from time import strftime\n",
    "from pathlib import Path\n",
    "\n",
    "from transformers import OwlViTProcessor, OwlViTForObjectDetection\n",
    "\n",
    "current_time = strftime(\"%m%d-%H%M%s\")\n",
    "hostname = os.environ.get('HOSTNAME').split(\".\")[0]\n",
    "\n",
    "weights_path = \"/opt/ml/processing/weights\"\n",
    "input_path = \"/opt/ml/processing/data\"\n",
    "output_path = Path(f\"/opt/ml/processing/output/{current_time}-test_result-{hostname}.csv\")\n",
    "\n",
    "\n",
    "# processor = OwlViTProcessor.from_pretrained(\"google/owlvit-base-patch32\")\n",
    "# model = OwlViTForObjectDetection.from_pretrained(\"google/owlvit-base-patch32\")\n",
    "processor = OwlViTProcessor.from_pretrained(weights_path)\n",
    "model = OwlViTForObjectDetection.from_pretrained(weights_path)\n",
    "\n",
    "# url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "res = []\n",
    "for image_path in glob.glob(f\"{input_path}/*\"):\n",
    "    print(f\"image_path : {image_path}\")\n",
    "    image = Image.open(image_path)\n",
    "    image = image.convert(\"RGB\")  # RGB로 변환\n",
    "    \n",
    "    texts = [[\"a photo of a tv\", \"a photo of a dog\"]]\n",
    "    inputs = processor(text=texts, images=image, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Target image sizes (height, width) to rescale box predictions [batch_size, 2]\n",
    "    target_sizes = torch.Tensor([image.size[::-1]])\n",
    "    # Convert outputs (bounding boxes and class logits) to Pascal VOC format (xmin, ymin, xmax, ymax)\n",
    "    results = processor.post_process_object_detection(outputs=outputs, target_sizes=target_sizes, threshold=0.1)\n",
    "    i = 0  # Retrieve predictions for the first image for the corresponding text queries\n",
    "    text = texts[i]\n",
    "    boxes, scores, labels = results[i][\"boxes\"], results[i][\"scores\"], results[i][\"labels\"]\n",
    "        \n",
    "    for box, score, label in zip(boxes, scores, labels):\n",
    "        box = [round(i, 2) for i in box.tolist()]\n",
    "        confidence = round(score.item(), 3)\n",
    "        label_name = texts[0][label]\n",
    "        print(f\"Detected {label_name} in {image_path} with confidence {confidence} at location {box}\")\n",
    "        res.append([str(image_path), label_name, confidence, box])\n",
    "\n",
    "print(f\"num of results : {len(res)}\")\n",
    "\n",
    "fields = ['image_name', 'label_name', 'confidence', 'location']\n",
    "with output_path.open('w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(fields)\n",
    "    writer.writerows(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8576de5b-9022-47e3-a0b6-8cd63a4ef12d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%writefile src/evaluation.py\n",
    "# import os\n",
    "# import csv\n",
    "# import numpy as np\n",
    "# import glob\n",
    "# import argparse\n",
    "# from pathlib import Path\n",
    "# from PIL import Image\n",
    "# import torch\n",
    "# from transformers import OwlViTProcessor, OwlViTForObjectDetection\n",
    "# from datetime import datetime\n",
    "# from time import strftime\n",
    "# import multiprocessing as mp\n",
    "\n",
    "# def process_image(image_path, texts, threshold, weights_path):\n",
    "#     processor = OwlViTProcessor.from_pretrained(weights_path)\n",
    "#     model = OwlViTForObjectDetection.from_pretrained(weights_path)\n",
    "    \n",
    "#     print(f\"image_path : {image_path}\")\n",
    "#     image = Image.open(image_path).convert(\"RGB\")\n",
    "#     image_size = image.size\n",
    "#     image = np.array(image)\n",
    "    \n",
    "#     if image.ndim == 2:\n",
    "#         image = np.stack((image,)*3, axis=-1)\n",
    "\n",
    "#     inputs = processor(text=texts, images=image, return_tensors=\"pt\")\n",
    "#     outputs = model(**inputs)\n",
    "\n",
    "#     target_sizes = torch.Tensor([image_size[::-1]])\n",
    "#     results = processor.post_process_object_detection(outputs=outputs, target_sizes=target_sizes, threshold=threshold)[0]\n",
    "\n",
    "#     boxes, scores, labels = results[\"boxes\"], results[\"scores\"], results[\"labels\"]\n",
    "#     detections = []\n",
    "#     for box, score, label in zip(boxes, scores, labels):\n",
    "#         label_name = texts[0][label]\n",
    "#         confidence = round(score.item(), 3)\n",
    "#         box_coords = [round(i, 2) for i in box.tolist()]\n",
    "#         print(f\"Detected {label_name} in {image_path} with confidence {confidence} at location {box_coords}\")\n",
    "#         detections.append((str(image_path), label_name, confidence, box_coords)) \n",
    "    \n",
    "#     return detections\n",
    "\n",
    "# current_time = strftime(\"%m%d-%H%M%s\")\n",
    "# hostname = os.environ.get('HOSTNAME').split(\".\")[0]\n",
    "\n",
    "# weights_path = \"/opt/ml/processing/weights\"\n",
    "# input_path = \"/opt/ml/processing/data\"\n",
    "# output_path = Path(f\"/opt/ml/processing/output/{current_time}-test_result-{hostname}.csv\")\n",
    "\n",
    "# start_time = datetime.now()\n",
    "# print(f\"Job started at: {start_time}\")\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--threshold\", type=float, default=0.1, help=\"confidence threshold\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# texts = [[\"a photo of a tv\", \"a photo of a dog\"]]\n",
    "\n",
    "# image_paths = glob.glob(f\"{input_path}/*\")\n",
    "# print(f\"num of image_paths : {len(image_paths)}\")\n",
    "\n",
    "# with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "#     results = pool.starmap(process_image, [(path, texts, args.threshold, weights_path) for path in image_paths])\n",
    "\n",
    "# # Flatten the results list\n",
    "# res = [item for sublist in results if sublist for item in sublist]\n",
    "# print(f\"num of results : {len(res)}\")\n",
    "# end_time = datetime.now()\n",
    "# total_time = end_time - start_time\n",
    "\n",
    "# fields = ['image_name', 'label_name', 'confidence', 'location']\n",
    "\n",
    "# # Check if file exists to determine whether to write headers\n",
    "# file_exists = output_path.exists()\n",
    "\n",
    "# with output_path.open('w', newline='') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     if not file_exists:\n",
    "#         writer.writerow(fields)\n",
    "#     writer.writerows(res)\n",
    "\n",
    "# print(f\"Job started at: {start_time}\")\n",
    "# print(f\"Job ended at: {end_time}\")\n",
    "# print(f\"Total execution time: {total_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015a9385-eb84-4f18-8820-2282c319376d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.m5.2xlarge\"\n",
    "# instance_type = \"local\"\n",
    "instance_count=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60784584-568a-4eb8-bae3-593b417feafa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if instance_type =='local':\n",
    "    import os\n",
    "    from sagemaker.local import LocalSession\n",
    "\n",
    "    sagemaker_session = LocalSession()\n",
    "    input_image_path = f\"{Path.cwd()}/ecommerce-products/tv\"\n",
    "    model_weight_path = f\"{Path.cwd()}/{local_model_weight}\"\n",
    "    output_path = f\"{Path.cwd()}/output\"\n",
    "    s3_data_distribution_type=\"FullyReplicated\"\n",
    "else:\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    input_image_path = f\"{s3_input_data_path}/tv\"\n",
    "    model_weight_path = s3_model_weight_path\n",
    "    output_path = f\"s3://{bucket}/{prefix}/output\"\n",
    "    s3_data_distribution_type=\"ShardedByS3Key\"\n",
    "input_image_path, model_weight_path, output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57894605-a6ca-4113-a096-cb0970332e95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 rm $output_path --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed5ed9-fa57-473f-b6f6-e26b96a0b4df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.processing import Processor, ScriptProcessor, FrameworkProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "from time import strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d83cd96-dc27-45b2-b3e9-4c892296f02d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_time = strftime(\"%m%d-%H%M%s\")\n",
    "i_type = instance_type.replace('.','-')\n",
    "job_name = f'owl-vit-{i_type}-{instance_count}-{current_time}'\n",
    "\n",
    "eval_processor = FrameworkProcessor(\n",
    "    PyTorch,\n",
    "    framework_version=\"2.3\",\n",
    "    py_version=\"py311\",\n",
    "    role=role, \n",
    "    instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    sagemaker_session=sagemaker_session\n",
    "    )\n",
    "\n",
    "\n",
    "eval_processor.run(\n",
    "    code=\"evaluation.py\",\n",
    "    source_dir=source_dir,\n",
    "    wait=False,\n",
    "    inputs=[ProcessingInput(source=input_image_path, \n",
    "                            input_name=\"test_data\", \n",
    "                            destination=\"/opt/ml/processing/data\", \n",
    "                            s3_data_distribution_type=s3_data_distribution_type),\n",
    "            ProcessingInput(source=model_weight_path, \n",
    "                            input_name=\"model_weight\", \n",
    "                            destination=\"/opt/ml/processing/weights\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(source=\"/opt/ml/processing/output\", destination=output_path),\n",
    "    ],\n",
    "    arguments=[\"--threshold\", \"0.1\"],\n",
    "    job_name=job_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583aace5-c24f-467f-a156-cbce5a158194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_processor.sagemaker_session.logs_for_processing_job(job_name, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2e075-a6e6-4bac-bc1f-2034a557cdcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf ./output && mkdir ./output\n",
    "!aws s3 cp $output_path ./output --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4bed69-9985-4309-b2b7-afc8c29cb95d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "dfs = []\n",
    "folder_path = \"./output\"\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            dfs.append(df)\n",
    "            print(f\"Successfully read: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {str(e)}\")\n",
    "\n",
    "if dfs:\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(\"\\nCombined DataFrame:\")\n",
    "    print(combined_df)\n",
    "    \n",
    "    # 추가 정보 출력\n",
    "    print(f\"\\n총 행 수: {len(combined_df)}\")\n",
    "    print(f\"컬럼: {combined_df.columns.tolist()}\")\n",
    "    \n",
    "    # 처음 5행 보기\n",
    "    print(\"\\n처음 5행:\")\n",
    "    print(combined_df.head())\n",
    "else:\n",
    "    print(\"No CSV files found in the output folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e432b8c-2c55-4351-80b4-a6bf320a5f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34448ad2-4217-4beb-90dd-24a5a62d83b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac479d-3831-4138-b934-f533b0a31bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
