{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SageMaker BatchTransform Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "install_needed = True\n",
    "install_needed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already revised\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 24.5M  100 24.5M    0     0   144M      0 --:--:-- --:--:-- --:--:--  144M\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "\n",
    "DAEMON_PATH=\"/etc/docker\"\n",
    "MEMORY_SIZE=10G\n",
    "\n",
    "FLAG=$(cat $DAEMON_PATH/daemon.json | jq 'has(\"data-root\")')\n",
    "# echo $FLAG\n",
    "\n",
    "if [ \"$FLAG\" == true ]; then\n",
    "    echo \"Already revised\"\n",
    "else\n",
    "    echo \"Add data-root and default-shm-size=$MEMORY_SIZE\"\n",
    "    sudo cp $DAEMON_PATH/daemon.json $DAEMON_PATH/daemon.json.bak\n",
    "    sudo cat $DAEMON_PATH/daemon.json.bak | jq '. += {\"data-root\":\"/home/ec2-user/SageMaker/.container/docker\",\"default-shm-size\":\"'$MEMORY_SIZE'\"}' | sudo tee $DAEMON_PATH/daemon.json > /dev/null\n",
    "    sudo service docker restart\n",
    "    echo \"Docker Restart\"\n",
    "fi\n",
    "\n",
    "sudo curl -L \"https://github.com/docker/compose/releases/download/v2.7.0/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n",
    "sudo chmod +x /usr/local/bin/docker-compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install --upgrade pip --quiet\n",
    "    !{sys.executable} -m pip install -U sagemaker huggingface_hub transformers --quiet\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import huggingface_hub\n",
    "from pathlib import Path\n",
    "from time import strftime\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer\n",
    ")\n",
    "import torch\n",
    "\n",
    "\n",
    "source_dir = f\"{Path.cwd()}/src\"\n",
    "os.makedirs(source_dir, exist_ok=True)\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"240929-deploy-owl-vit\"\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['HF_DATASETS_CACHE'] = '/home/ec2-user/SageMaker/.cache'\n",
    "os.environ['HF_CACHE_HOME'] = '/home/ec2-user/SageMaker/.cache'\n",
    "os.environ['HUGGINGFACE_HUB_CACHE'] = '/home/ec2-user/SageMaker/.cache'\n",
    "# os.environ['TRANSFORMERS_HOME'] = '/home/ec2-user/SageMaker/.cache'\n",
    "# os.environ['HF_HOME'] = '/home/ec2-user/SageMaker/.cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_model_id = 'google/owlvit-base-patch32'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## [**Step 1**] Storing model artifacts and serving/scoring logic\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Downloading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registered_model : owlvit-base-patch32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c376ee76fb4454b333fbd9a5965151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/owl-vit-on-sagemaker/owlvit-base-patch32'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registered_model = test_model_id.split(\"/\")[-1].lower().replace(\".\", \"-\")\n",
    "print(f\"registered_model : {registered_model}\")\n",
    "os.makedirs(registered_model, exist_ok=True)\n",
    "\n",
    "huggingface_hub.snapshot_download(\n",
    "    repo_id=test_model_id,\n",
    "    revision=\"main\",\n",
    "    local_dir=registered_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'owlvit-base-patch32'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model_weight = test_model_id.split(\"/\")[-1].lower().replace(\".\", \"-\")\n",
    "local_model_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weight spec (in this case, just an S3 path): s3://sagemaker-us-east-1-714932599119/240929-deploy-owl-vit/owlvit-base-patch32\n"
     ]
    }
   ],
   "source": [
    "s3_model_weight_path = sagemaker_session.upload_data(path=f'./{local_model_weight}', bucket=bucket, key_prefix=f\"{prefix}/{local_model_weight}\")\n",
    "print('Model weight spec (in this case, just an S3 path): {}'.format(s3_model_weight_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://sagemaker-us-east-1-714932599119/240929-deploy-owl-vit/ecommerce-products\n"
     ]
    }
   ],
   "source": [
    "s3_input_data_path = sagemaker_session.upload_data(path=f'./ecommerce-products', bucket=bucket, key_prefix=f\"{prefix}/ecommerce-products\")\n",
    "print('input spec (in this case, just an S3 path): {}'.format(s3_input_data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드 셀은 src 디렉토리에 SageMaker 추론 스크립트를 저장합니다.\n",
    "\n",
    "#### Option 1.\n",
    "- `model_fn(model_dir)`: S3의 `model_dir`에 저장된 모델 아티팩트를 로드합니다.\n",
    "- `input_fn(request_body, content_type)`: 입력 데이터를 전처리합니다. `content_type`은 입력 데이터 종류에 따라 다양하게 처리 가능합니다. (예: `application/x-npy`, `application/json`, `application/csv`등)\n",
    "- `predict_fn(input_object, model)`: `input_fn(...)`을 통해 들어온 데이터에 대해 추론을 수행합니다.\n",
    "- `output_fn(prediction, accept_type)`: `predict_fn(...)`에서 받은 추론 결과를 후처리를 거쳐 프론트엔드로 전송합니다.\n",
    "\n",
    "#### Option 2.\n",
    "- `model_fn(model_dir)`: S3의 model_dir에 저장된 모델 아티팩트를 로드합니다.\n",
    "- `transform_fn(model, request_body, content_type, accept_type)`: `input_fn(...), predict_fn(...), output_fn(...)`을 `transform_fn(...)`으로 통합할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'owlvit-base-patch32'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(f\"{local_model_weight}/code\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing owlvit-base-patch32/code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {local_model_weight}/code/requirements.txt\n",
    "transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing owlvit-base-patch32/code/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {local_model_weight}/code/inference.py\n",
    "import logging\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from typing import Union, Tuple, List, Any\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "try:\n",
    "    threshold = float(os.environ.get(\"threshold\", \"0.1\"))\n",
    "except ValueError:\n",
    "    logging.warning(\"Invalid threshold value in environment variable. Using default value 0.1\")\n",
    "    threshold = 0.1\n",
    "\n",
    "try:\n",
    "    texts = json.loads(os.environ.get(\"texts\", \"[]\"))\n",
    "except json.JSONDecodeError:\n",
    "    logging.error(\"Invalid JSON in texts environment variable\")\n",
    "    texts = []\n",
    "\n",
    "from transformers import OwlViTProcessor, OwlViTForObjectDetection\n",
    "\n",
    "def decode_input(encoded_image: Union[str, bytearray, bytes]) -> Image.Image:\n",
    "    try:\n",
    "        # Try base64 decoding first\n",
    "        image_data = base64.b64decode(encoded_image)\n",
    "        image = Image.open(BytesIO(image_data)).convert(\"RGB\")\n",
    "    except:\n",
    "        # If base64 decoding fails, assume it's already in bytes format\n",
    "        image = Image.open(BytesIO(encoded_image)).convert(\"RGB\")\n",
    "    return image\n",
    "\n",
    "\n",
    "def model_fn(model_dir: str) -> Tuple[OwlViTProcessor, OwlViTForObjectDetection]:\n",
    "    try:\n",
    "        processor = OwlViTProcessor.from_pretrained(model_dir)\n",
    "        model = OwlViTForObjectDetection.from_pretrained(model_dir)\n",
    "        logging.info(\"Model loaded successfully\")\n",
    "        return (processor, model)\n",
    "    except Exception:\n",
    "        logging.exception(f\"Failed to load model from: {model_dir}\")\n",
    "        raise\n",
    "\n",
    "def input_fn(input_data: Union[str, bytearray, bytes], content_type: str) -> Tuple[np.ndarray, Tuple[int, int]]:\n",
    "    if content_type == \"application/x-image\":\n",
    "        try:\n",
    "            image = decode_input(input_data)\n",
    "            image_size = image.size\n",
    "            logging.info(f\"Image size: {image_size}\")\n",
    "            image_array = np.array(image)\n",
    "\n",
    "            if image_array.ndim == 2:\n",
    "                image_array = np.stack((image_array,)*3, axis=-1)\n",
    "            return (image_array, image_size)\n",
    "        except Exception as e:\n",
    "            logging.exception(f\"Error occurred when loading/decoding: {str(e)}\")\n",
    "            raise\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported content type: {content_type}\")\n",
    "\n",
    "def predict_fn(input_data: Tuple[np.ndarray, Tuple[int, int]], model_dict: Tuple[OwlViTProcessor, OwlViTForObjectDetection]) -> List[Tuple[str, float, List[float]]]:\n",
    "    processor, model = model_dict\n",
    "    image_array, image_size = input_data\n",
    "    \n",
    "    logging.info(f\"Processing image of size: {image_size}\")\n",
    "    logging.info(f\"texts: {texts}\")\n",
    "    \n",
    "    inputs = processor(text=texts, images=image_array, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    target_sizes = torch.Tensor([image_size[::-1]])\n",
    "    \n",
    "    results = processor.post_process_object_detection(outputs=outputs, target_sizes=target_sizes, threshold=threshold)[0]\n",
    "    \n",
    "    boxes, scores, labels = results[\"boxes\"], results[\"scores\"], results[\"labels\"]\n",
    "    detections = [\n",
    "        (texts[0][label], round(score.item(), 3), [round(i, 2) for i in box.tolist()])\n",
    "        for box, score, label in zip(boxes, scores, labels)\n",
    "    ]\n",
    "    logging.info(f\"detections: {detections}\")\n",
    "    for detection in detections:\n",
    "        logging.info(f\"Detected {detection[0]} with confidence {detection[1]} at location {detection[2]}\")\n",
    "    \n",
    "    return detections\n",
    "\n",
    "def output_fn(prediction: List[Tuple[str, float, List[float]]], accept: str) -> Tuple[str, str]:\n",
    "    if accept == \"application/json\":\n",
    "        return json.dumps(prediction), accept\n",
    "    raise ValueError(f\"Unsupported accept type: {accept}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## [**Step 3**] Validating the container for hosting your model on SageMaker\n",
    "---\n",
    "\n",
    "SageMaker 호스팅 엔드포인트로 배포하기 전에 로컬 모드 엔드포인트로 배포할 수 있습니다. 로컬 모드는 현재 개발 중인 환경에서 도커 컨테이너를 실행하여 SageMaker 프로세싱/훈련/추론 작업을 에뮬레이트할 수 있습니다. 추론 작업의 경우는 Amazon ECR의 딥러닝 프레임워크 기반 추론 컨테이너를 로컬로 가져오고(docker pull) 컨테이너를 실행하여(docker run) 모델 서버를 시작합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!sudo rm -rf {local_model_weight}/.ipynb_checkpoints/\n",
    "!sudo rm -rf {local_model_weight}/__pycache__/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('shell', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing shell/model_compression_upload.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile shell/model_compression_upload.sh\n",
    "\n",
    "cd owlvit-base-patch32\n",
    "tar cvf - * | pigz > model.tar.gz\n",
    "\n",
    "mv model.tar.gz ../model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code/\n",
      "code/inference.py\n",
      "code/requirements.txt\n",
      "config.json\n",
      "merges.txt\n",
      "model.safetensors\n",
      "preprocessor_config.json\n",
      "pytorch_model.bin\n",
      "README.md\n",
      "special_tokens_map.json\n",
      "tokenizer_config.json\n",
      "vocab.json\n",
      "CPU times: user 313 ms, sys: 33.9 ms, total: 347 ms\n",
      "Wall time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!sh ./shell/model_compression_upload.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-714932599119/240929-deploy-owl-vit/compressed_model\n",
      "upload: ./model.tar.gz to s3://sagemaker-us-east-1-714932599119/240929-deploy-owl-vit/compressed_model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_data_url = f's3://{bucket}/{prefix}/compressed_model'\n",
    "print(model_data_url)\n",
    "\n",
    "!aws s3 cp ./model.tar.gz {model_data_url}/model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SageMaker Endpoint (Local Mode)\n",
    "\n",
    "로컬 모드는 필수로 수행할 필요는 없지만, 디버깅에 많은 도움이 됩니다. 또한, 로컬 모드 사용 시에는 모델을 S3에 반드시 업로드할 필요 없이 로컬 디렉터리에서도 로드할 수 있습니다. (`container` 변수 참조)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_uri: 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:2.3-cpu-py311 \n",
      "docker_account_id : 763104351884\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework='pytorch',\n",
    "    region=region,\n",
    "    image_scope='inference',\n",
    "    version='2.3',\n",
    "    instance_type='ml.m5.2xlarge'\n",
    ")\n",
    "docker_account_id = image_uri.split('.')[0]\n",
    "print(f'image_uri: {image_uri} \\ndocker_account_id : {docker_account_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///home/ec2-user/SageMaker/owl-vit-on-sagemaker/owlvit-base-patch32'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "# Set to True to enable SageMaker to run locally\n",
    "local_mode = True\n",
    "# local_mode = False\n",
    "if local_mode:\n",
    "    from sagemaker.local import LocalSession\n",
    "    instance_type = \"local_gpu\"\n",
    "    sm_session = LocalSession()\n",
    "    sm_session.config = {'local': {'local_code': True}}\n",
    "    sm_client = sagemaker.local.LocalSagemakerClient()\n",
    "    smr_client = sagemaker.local.LocalSagemakerRuntimeClient()\n",
    "    model_data=f\"file://{Path.cwd()}/{local_model_weight}\"\n",
    "    input_image_path = f\"file://{Path.cwd()}/ecommerce-products/tv\"\n",
    "    output_path = f\"file://{Path.cwd()}/batchtransform-output\"\n",
    "else:\n",
    "    instance_type = \"ml.m5.2xlarge\"\n",
    "    sm_session = sagemaker.Session()\n",
    "    sm_client = boto3.client(\"sagemaker\")\n",
    "    smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "    model_data = f\"{model_data_url}/model.tar.gz\"\n",
    "    input_image_path = f\"{s3_input_data_path}/tv\"\n",
    "    output_path = f\"s3://{bucket}/{prefix}/batchtransform-output\"\n",
    "\n",
    "instance_count = 1\n",
    "ts = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "sm_model_name = f\"{local_model_weight}-model-{ts}\"\n",
    "endpoint_config_name = f\"{local_model_weight}-endpoint-config-{ts}\"\n",
    "job_name = f\"{local_model_weight}-batchtranform-{ts}\"\n",
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "container = {\n",
    "    \"Image\": image_uri,\n",
    "    \"ModelDataUrl\": model_data,\n",
    "    \"Environment\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local Mode only supports 1 ConcurrentTransform. Setting MaxConcurrentTransforms to 1\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Attaching to awyhp9kkim-algo-1-h60p9\n",
      "awyhp9kkim-algo-1-h60p9  | Collecting transformers (from -r /opt/ml/model/code/requirements.txt (line 1))\n",
      "awyhp9kkim-algo-1-h60p9  |   Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "awyhp9kkim-algo-1-h60p9  | \u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (3.14.0)\n",
      "awyhp9kkim-algo-1-h60p9  | Collecting huggingface-hub<1.0,>=0.23.2 (from transformers->-r /opt/ml/model/code/requirements.txt (line 1))\n",
      "awyhp9kkim-algo-1-h60p9  |   Downloading huggingface_hub-0.25.1-py3-none-any.whl.metadata (13 kB)\n",
      "awyhp9kkim-algo-1-h60p9  | Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (1.26.4)\n",
      "awyhp9kkim-algo-1-h60p9  | Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (23.2)\n",
      "awyhp9kkim-algo-1-h60p9  | Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (6.0)\n",
      "awyhp9kkim-algo-1-h60p9  | Collecting regex!=2019.12.17 (from transformers->-r /opt/ml/model/code/requirements.txt (line 1))\n",
      "awyhp9kkim-algo-1-h60p9  |   Downloading regex-2024.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "awyhp9kkim-algo-1-h60p9  | \u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (2.32.3)\n",
      "awyhp9kkim-algo-1-h60p9  | Collecting safetensors>=0.4.1 (from transformers->-r /opt/ml/model/code/requirements.txt (line 1))\n",
      "awyhp9kkim-algo-1-h60p9  |   Downloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "awyhp9kkim-algo-1-h60p9  | Collecting tokenizers<0.21,>=0.20 (from transformers->-r /opt/ml/model/code/requirements.txt (line 1))\n",
      "awyhp9kkim-algo-1-h60p9  |   Downloading tokenizers-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "awyhp9kkim-algo-1-h60p9  | Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (4.66.4)\n",
      "awyhp9kkim-algo-1-h60p9  | Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (2024.6.0)\n",
      "awyhp9kkim-algo-1-h60p9  | Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (4.12.2)\n",
      "awyhp9kkim-algo-1-h60p9  | Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (3.3.2)\n",
      "awyhp9kkim-algo-1-h60p9  | Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (3.7)\n",
      "awyhp9kkim-algo-1-h60p9  | Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (1.26.20)\n",
      "awyhp9kkim-algo-1-h60p9  | Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers->-r /opt/ml/model/code/requirements.txt (line 1)) (2024.8.30)\n",
      "awyhp9kkim-algo-1-h60p9  | Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m135.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "awyhp9kkim-algo-1-h60p9  | \u001b[?25hDownloading huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 kB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m-:--:--\u001b[0m\n",
      "awyhp9kkim-algo-1-h60p9  | \u001b[?25hDownloading regex-2024.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.8/792.8 kB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m-:--:--\u001b[0m\n",
      "awyhp9kkim-algo-1-h60p9  | \u001b[?25hDownloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m-:--:--\u001b[0m\n",
      "awyhp9kkim-algo-1-h60p9  | \u001b[?25hDownloading tokenizers-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m129.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m-:--:--\u001b[0m\n",
      "awyhp9kkim-algo-1-h60p9  | \u001b[?25hInstalling collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "awyhp9kkim-algo-1-h60p9  | Successfully installed huggingface-hub-0.25.1 regex-2024.9.11 safetensors-0.4.5 tokenizers-0.20.0 transformers-4.45.2\n",
      "awyhp9kkim-algo-1-h60p9  | \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "awyhp9kkim-algo-1-h60p9  | \u001b[0m\n",
      "awyhp9kkim-algo-1-h60p9  | \u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "awyhp9kkim-algo-1-h60p9  | \u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "awyhp9kkim-algo-1-h60p9  | ['torchserve', '--start', '--model-store', '/.sagemaker/ts/models', '--ts-config', '/etc/sagemaker-ts.properties', '--log-config', '/opt/conda/lib/python3.11/site-packages/sagemaker_pytorch_serving_container/etc/log4j2.xml', '--models', 'model=/opt/ml/model']\n",
      "awyhp9kkim-algo-1-h60p9  | Warning: TorchServe is using non-default JVM parameters: -XX:-UseContainerSupport\n",
      "awyhp9kkim-algo-1-h60p9  | WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:15,662 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:15,665 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:15,724 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/lib/python3.11/site-packages/ts/configs/metrics.yaml\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:15,814 [INFO ] main org.pytorch.serve.ModelServer - \n",
      "awyhp9kkim-algo-1-h60p9  | Torchserve version: 0.11.0\n",
      "awyhp9kkim-algo-1-h60p9  | TS Home: /opt/conda/lib/python3.11/site-packages\n",
      "awyhp9kkim-algo-1-h60p9  | Current directory: /\n",
      "awyhp9kkim-algo-1-h60p9  | Temp directory: /tmp\n",
      "awyhp9kkim-algo-1-h60p9  | Metrics config path: /opt/conda/lib/python3.11/site-packages/ts/configs/metrics.yaml\n",
      "awyhp9kkim-algo-1-h60p9  | Number of GPUs: 0\n",
      "awyhp9kkim-algo-1-h60p9  | Number of CPUs: 4\n",
      "awyhp9kkim-algo-1-h60p9  | Max heap size: 3924 M\n",
      "awyhp9kkim-algo-1-h60p9  | Python executable: /opt/conda/bin/python3.11\n",
      "awyhp9kkim-algo-1-h60p9  | Config file: /etc/sagemaker-ts.properties\n",
      "awyhp9kkim-algo-1-h60p9  | Inference address: http://0.0.0.0:8080\n",
      "awyhp9kkim-algo-1-h60p9  | Management address: http://0.0.0.0:8080\n",
      "awyhp9kkim-algo-1-h60p9  | Metrics address: http://127.0.0.1:8082\n",
      "awyhp9kkim-algo-1-h60p9  | Model Store: /.sagemaker/ts/models\n",
      "awyhp9kkim-algo-1-h60p9  | Initial Models: model=/opt/ml/model\n",
      "awyhp9kkim-algo-1-h60p9  | Log dir: /logs\n",
      "awyhp9kkim-algo-1-h60p9  | Metrics dir: /logs\n",
      "awyhp9kkim-algo-1-h60p9  | Netty threads: 0\n",
      "awyhp9kkim-algo-1-h60p9  | Netty client threads: 0\n",
      "awyhp9kkim-algo-1-h60p9  | Default workers per model: 4\n",
      "awyhp9kkim-algo-1-h60p9  | Blacklist Regex: N/A\n",
      "awyhp9kkim-algo-1-h60p9  | Maximum Response Size: 6553500\n",
      "awyhp9kkim-algo-1-h60p9  | Maximum Request Size: 6553500\n",
      "awyhp9kkim-algo-1-h60p9  | Limit Maximum Image Pixels: true\n",
      "awyhp9kkim-algo-1-h60p9  | Prefer direct buffer: false\n",
      "awyhp9kkim-algo-1-h60p9  | Allowed Urls: [file://.*|http(s)?://.*]\n",
      "awyhp9kkim-algo-1-h60p9  | Custom python dependency for model allowed: false\n",
      "awyhp9kkim-algo-1-h60p9  | Enable metrics API: true\n",
      "awyhp9kkim-algo-1-h60p9  | Metrics mode: LOG\n",
      "awyhp9kkim-algo-1-h60p9  | Disable system metrics: false\n",
      "awyhp9kkim-algo-1-h60p9  | Workflow Store: /.sagemaker/ts/models\n",
      "awyhp9kkim-algo-1-h60p9  | CPP log config: N/A\n",
      "awyhp9kkim-algo-1-h60p9  | Model config: N/A\n",
      "awyhp9kkim-algo-1-h60p9  | System metrics command: default\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:15,821 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:15,841 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: /opt/ml/model\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:15,850 [INFO ] main org.pytorch.serve.archive.model.ModelArchive - createTempDir /tmp/models/a5706b30b5ec49adb4c0fbe17134c98e\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:15,851 [INFO ] main org.pytorch.serve.archive.model.ModelArchive - createSymbolicDir /tmp/models/a5706b30b5ec49adb4c0fbe17134c98e/model\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:15,852 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive version is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:15,852 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive createdOn is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:15,855 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:15,867 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:16,037 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:16,038 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:16,057 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\n",
      "awyhp9kkim-algo-1-h60p9  | Model server started.\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:16,617 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:16,700 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361336\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:16,701 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:86.60509872436523|#Level:Host|#hostname:58781440e71c,timestamp:1728361336\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:16,702 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:6.626277923583984|#Level:Host|#hostname:58781440e71c,timestamp:1728361336\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:16,702 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:7.1|#Level:Host|#hostname:58781440e71c,timestamp:1728361336\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:16,703 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12995.09765625|#Level:Host|#hostname:58781440e71c,timestamp:1728361336\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:16,703 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2367.70703125|#Level:Host|#hostname:58781440e71c,timestamp:1728361336\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:16,704 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:17.2|#Level:Host|#hostname:58781440e71c,timestamp:1728361336\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,213 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9001, pid=55\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,215 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,224 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.11/site-packages/ts/configs/metrics.yaml.\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,225 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]55\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,226 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,227 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.11.9\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,244 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,280 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,294 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361338294\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,324 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9003, pid=58\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,324 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9000, pid=56\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,326 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,326 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9003\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,354 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.11/site-packages/ts/configs/metrics.yaml.\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,355 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]58\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,356 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,357 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.11.9\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,354 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.11/site-packages/ts/configs/metrics.yaml.\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,358 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]56\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,358 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,357 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,359 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.11.9\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,358 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,365 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,366 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9003.\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,373 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361338373\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,374 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - s_name_part0=/tmp/.ts.sock, s_name_part1=9002, pid=57\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,376 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9002\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,389 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,391 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361338391\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,446 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.11/site-packages/ts/configs/metrics.yaml.\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,446 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]57\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,446 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,446 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.11.9\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,447 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,447 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,462 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9002.\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,463 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361338463\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,547 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:18,581 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:20,376 [INFO ] pool-2-thread-5 ACCESS_LOG - /172.18.0.1:57766 \"GET /ping HTTP/1.1\" 200 81\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:20,386 [INFO ] pool-2-thread-5 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361340\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:20,477 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /172.18.0.1:57778 \"GET /execution-parameters HTTP/1.1\" 404 2\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:20,479 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361340\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:20,590 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361340\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:21,972 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Model loaded successfully\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:21,976 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3585\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:21,977 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:6114.0|#WorkerName:W-9003-model_1.0,Level:Host|#hostname:58781440e71c,timestamp:1728361341\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:21,978 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:26.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361341\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:21,978 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361341978\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:21,981 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361341\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:22,003 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Model loaded successfully\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:22,004 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3709\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:22,005 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:6142.0|#WorkerName:W-9001-model_1.0,Level:Host|#hostname:58781440e71c,timestamp:1728361342\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:22,009 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:17.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361342\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:22,023 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Model loaded successfully\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:22,024 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3561\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:22,024 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:6161.0|#WorkerName:W-9002-model_1.0,Level:Host|#hostname:58781440e71c,timestamp:1728361342\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:22,025 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361342\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:22,024 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (500, 498)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:22,026 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 498)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:22,026 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:22,045 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Model loaded successfully\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:22,045 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3671\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:22,045 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:6183.0|#WorkerName:W-9000-model_1.0,Level:Host|#hostname:58781440e71c,timestamp:1728361342\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:22,046 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:10.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361342\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:23,144 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.556, [94.76, 151.3, 404.75, 346.96])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:23,145 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.556 at location [94.76, 151.3, 404.75, 346.96]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:23,149 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1164.82|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361343,e23abf10-5b1b-4687-9d64-4997ebe3cb3d, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:23,150 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 2564\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:23,150 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:1164.82|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:e23abf10-5b1b-4687-9d64-4997ebe3cb3d,timestamp:1728361343\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:23,150 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361343\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:23,151 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2558871.053|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361343\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:23,151 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1387051.541|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361343\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:23,152 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:1387.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361343\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:23,152 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1171\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:23,152 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361343\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:23,180 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361343\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:23,181 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361343181\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:23,183 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361343\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:23,210 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:23,211 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:23,212 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:24,170 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:24,173 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:989.99|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361344,ce4797c6-0a2d-4b8e-9b6e-5797ee7c1354, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:24,173 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 993\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:24,174 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:989.99|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:ce4797c6-0a2d-4b8e-9b6e-5797ee7c1354,timestamp:1728361344\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:24,175 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361344\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:24,175 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:992629.685|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361344\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:24,175 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:244.074|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361344\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:24,176 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361344\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:24,176 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 988\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:24,176 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:7.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361344\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:24,196 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361344\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:24,197 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361344197\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:24,199 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361344\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:24,237 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1080, 1080)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:24,239 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1080, 1080)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:24,239 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:25,193 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:25,196 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:997.35|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361345,e884fd9e-1fc3-4971-83ae-be98380685be, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:25,198 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:997.35|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:e884fd9e-1fc3-4971-83ae-be98380685be,timestamp:1728361345\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:25,197 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 1001\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:25,199 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361345\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:25,202 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1000430.631|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361345\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:25,203 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:259.226|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361345\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:25,204 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361345\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:25,204 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1000\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:25,205 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:7.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361345\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:25,222 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361345\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:25,223 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361345223\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:25,224 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361345\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:25,255 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1067, 800)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:25,256 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1067, 800)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:25,257 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:26,251 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.238, [629.72, 210.68, 1038.89, 512.78])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:26,251 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.238 at location [629.72, 210.68, 1038.89, 512.78]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:26,254 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1029.8|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361346,1742e524-c78c-4ff8-84e9-461791260783, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:26,255 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 1033\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:26,256 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361346\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:26,258 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1032149.251|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361346\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:26,257 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:1029.8|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:1742e524-c78c-4ff8-84e9-461791260783,timestamp:1728361346\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:26,258 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:142.546|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361346\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:26,260 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361346\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:26,260 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1032\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:26,260 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:5.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361346\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:26,282 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361346\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:26,283 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361346283\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:26,289 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361346\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:26,297 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1500, 951)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:26,299 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 951)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:26,300 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,075 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.258, [17.02, 10.59, 1509.16, 895.44])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,076 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.258 at location [17.02, 10.59, 1509.16, 895.44]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,078 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:794.01|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361347,95696995-3416-4511-8db9-dbb02dab12bc, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,079 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:794.01|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:95696995-3416-4511-8db9-dbb02dab12bc,timestamp:1728361347\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,080 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 798\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,080 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361347\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,081 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:797119.903|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361347\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,081 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:119.938|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361347\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,082 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361347\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,082 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 797\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,082 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361347\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,107 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361347\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,108 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361347108\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,109 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361347\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,122 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,127 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,127 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,883 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.22, [59.4, 277.11, 1484.36, 1375.83])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,883 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.22 at location [59.4, 277.11, 1484.36, 1375.83]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,887 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:777.05|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361347,3024df0f-f44c-41e7-87c5-2879e3ed3b91, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,887 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:777.05|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:3024df0f-f44c-41e7-87c5-2879e3ed3b91,timestamp:1728361347\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,887 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 781\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,888 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361347\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,888 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:779677.821|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361347\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,888 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:147.627|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361347\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,888 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361347\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,889 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 779\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,889 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361347\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,912 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361347\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,913 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361347913\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,914 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361347\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,929 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,931 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:27,931 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:28,675 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.234, [27.36, 77.6, 971.64, 636.3]), ('a photo of a tv', 0.102, [432.53, 749.15, 569.08, 924.91])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:28,675 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.234 at location [27.36, 77.6, 971.64, 636.3]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:28,675 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.102 at location [432.53, 749.15, 569.08, 924.91]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:28,677 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:762.63|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361348,37778565-9ce7-4543-9db5-a12c66d36e9c, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:28,678 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 766\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:28,678 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:762.63|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:37778565-9ce7-4543-9db5-a12c66d36e9c,timestamp:1728361348\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:28,678 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361348\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:28,678 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:764913.687|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361348\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:28,679 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:275.33|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361348\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:28,679 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361348\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:28,679 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 765\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:28,679 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361348\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:28,699 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361348\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:28,699 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361348699\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:28,701 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361348\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:28,710 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1000, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:28,712 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:28,713 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:29,485 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:29,487 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:786.28|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361349,9ef553df-2953-4703-9a31-34c3cc378133, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:29,488 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:786.28|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:9ef553df-2953-4703-9a31-34c3cc378133,timestamp:1728361349\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:29,488 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 790\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:29,489 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361349\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:29,489 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:788822.896|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361349\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:29,489 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:92.668|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361349\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:29,489 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361349\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:29,490 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 789\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:29,490 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361349\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:29,510 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361349\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:29,511 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361349511\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:29,512 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361349\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:29,531 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1600, 1200)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:29,535 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1200)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:29,535 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:30,329 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:30,331 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 821\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:30,332 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361350\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:30,333 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:820786.43|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361350\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:30,333 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:226.228|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361350\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:30,333 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361350\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:30,333 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 820\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:30,333 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361350\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:30,334 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:818.8|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361350,3a24f7a5-160f-4853-a04b-ecb2e4943197, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:30,334 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:818.8|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:3a24f7a5-160f-4853-a04b-ecb2e4943197,timestamp:1728361350\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:30,354 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361350\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:30,355 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361350355\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:30,357 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361350\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:30,383 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1500, 1500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:30,387 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 1500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:30,388 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,122 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.3, [146.35, 101.61, 1336.8, 779.55])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,124 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.3 at location [146.35, 101.61, 1336.8, 779.55]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,124 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:766.64|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361351,6c4321da-166a-4b6f-bcf4-0802556c3532, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,125 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:766.64|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:6c4321da-166a-4b6f-bcf4-0802556c3532,timestamp:1728361351\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,125 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 771\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,125 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361351\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,126 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:769773.999|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361351\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,126 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:127.651|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361351\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,126 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361351\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,126 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 769\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,126 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361351\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,146 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361351\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,146 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361351146\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,148 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361351\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,167 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,172 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,173 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,911 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.324, [13.32, 331.42, 1571.82, 1349.36])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,912 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.324 at location [13.32, 331.42, 1571.82, 1349.36]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,914 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:765.98|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361351,1f84d17d-24c3-4437-9898-dfaee2a65f7f, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,915 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:765.98|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:1f84d17d-24c3-4437-9898-dfaee2a65f7f,timestamp:1728361351\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,915 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 770\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,915 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361351\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,915 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:768254.227|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361351\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,916 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:115.568|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361351\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,916 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361351\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,916 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 767\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,916 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361351\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,939 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361351\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,940 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361351940\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,941 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361351\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,955 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,961 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:31,961 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:32,726 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.263, [59.14, 347.57, 1533.67, 1251.82]), ('a photo of a tv', 0.125, [54.61, 363.85, 1550.45, 1341.9])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:32,726 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.263 at location [59.14, 347.57, 1533.67, 1251.82]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:32,726 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.125 at location [54.61, 363.85, 1550.45, 1341.9]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:32,730 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:788.65|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361352,37656d33-e3e6-4488-b1ce-849b8ad8db19, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:32,730 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:788.65|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:37656d33-e3e6-4488-b1ce-849b8ad8db19,timestamp:1728361352\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:32,730 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 791\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:32,731 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361352\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:32,731 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:790739.406|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361352\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:32,731 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:96.378|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361352\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:32,731 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361352\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:32,731 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 790\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:32,732 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361352\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:32,749 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361352\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:32,750 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361352750\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:32,751 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361352\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:32,761 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:32,763 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:32,764 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:33,498 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.41, [19.76, 197.14, 988.91, 816.58])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:33,498 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.41 at location [19.76, 197.14, 988.91, 816.58]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:33,503 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:751.34|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361353,a486a6c2-32c8-4365-90a2-0257c3766048, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:33,503 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:751.34|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:a486a6c2-32c8-4365-90a2-0257c3766048,timestamp:1728361353\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:33,503 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 754\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:33,504 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361353\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:33,504 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:753574.823|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361353\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:33,504 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:196.1|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361353\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:33,504 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361353\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:33,504 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 753\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:33,504 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361353\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:33,527 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361353\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:33,527 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361353527\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:33,528 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361353\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:33,550 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1602, 1602)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:33,555 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1602, 1602)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:33,555 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:34,292 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.36, [69.08, 396.98, 1527.08, 1245.99])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:34,292 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.36 at location [69.08, 396.98, 1527.08, 1245.99]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:34,294 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:765.03|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361354,23d65abb-8a5c-4975-8225-66a13e6d60f1, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:34,294 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:765.03|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:23d65abb-8a5c-4975-8225-66a13e6d60f1,timestamp:1728361354\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:34,294 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 768\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:34,295 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361354\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:34,295 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:767261.509|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361354\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:34,295 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:112.515|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361354\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:34,295 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361354\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:34,295 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 767\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:34,296 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361354\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:34,318 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361354\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:34,318 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361354318\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:34,320 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361354\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:34,374 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (2560, 2560)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:34,386 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 2560)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:34,386 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,149 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.412, [89.11, 579.47, 2484.97, 2042.52])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,150 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.412 at location [89.11, 579.47, 2484.97, 2042.52]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,153 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:833.06|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361355,eed72f67-c691-485b-8d1e-ede8d4ab56f5, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,153 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:833.06|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:eed72f67-c691-485b-8d1e-ede8d4ab56f5,timestamp:1728361355\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,154 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 837\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,154 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361355\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,154 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:835559.481|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361355\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,155 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:112.352|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361355\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,155 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361355\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,155 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 835\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,155 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361355\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,173 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361355\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,174 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361355174\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,175 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361355\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,180 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1024, 1024)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,182 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1024, 1024)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,183 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,916 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.556, [38.94, 235.41, 982.17, 822.94])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,916 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.556 at location [38.94, 235.41, 982.17, 822.94]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,918 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:742.68|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361355,65348a39-09df-42b4-8814-99011685696f, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,919 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:742.68|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:65348a39-09df-42b4-8814-99011685696f,timestamp:1728361355\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,919 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 746\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,919 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361355\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,919 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:744865.108|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361355\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,919 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:110.67|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361355\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,919 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361355\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,919 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 744\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,919 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361355\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,947 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361355\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,947 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361355947\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:35,949 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361355\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:36,017 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (2500, 2560)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:36,029 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (2500, 2560)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:36,029 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:36,818 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.493, [121.58, 140.79, 2389.28, 1500.09])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:36,818 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.493 at location [121.58, 140.79, 2389.28, 1500.09]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:36,821 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:871.96|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361356,8cd45ffd-1ff6-47b6-8e37-d64f32dc80fc, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:36,821 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:871.96|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:8cd45ffd-1ff6-47b6-8e37-d64f32dc80fc,timestamp:1728361356\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:36,822 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 877\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:36,822 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361356\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:36,822 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:874706.642|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361356\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:36,822 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:130.834|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361356\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:36,822 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361356\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:36,822 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 874\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:36,822 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361356\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:36,844 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361356\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:36,845 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361356845\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:36,846 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361356\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:36,877 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (2000, 2000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:36,885 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (2000, 2000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:36,886 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:37,642 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.318, [448.39, 323.89, 1541.11, 968.84])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:37,642 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.318 at location [448.39, 323.89, 1541.11, 968.84]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:37,645 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:799.15|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361357,10a7a7c8-cba1-4f1a-9515-a3d51d99ed76, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:37,646 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:799.15|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:10a7a7c8-cba1-4f1a-9515-a3d51d99ed76,timestamp:1728361357\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:37,646 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 803\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:37,646 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361357\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:37,647 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:801448.449|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361357\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:37,647 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:122.309|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361357\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:37,647 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361357\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:37,647 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 801\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:37,647 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361357\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:37,668 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361357\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:37,668 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361357668\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:37,670 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361357\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:37,690 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:37,696 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:37,696 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:38,432 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.324, [13.32, 331.42, 1571.82, 1349.36])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:38,432 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.324 at location [13.32, 331.42, 1571.82, 1349.36]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:38,434 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:764.7|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361358,56aff608-c76d-40e3-9b24-349b6217a379, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:38,435 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:764.7|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:56aff608-c76d-40e3-9b24-349b6217a379,timestamp:1728361358\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:38,435 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 768\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:38,435 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361358\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:38,436 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:766985.936|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361358\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:38,436 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:125.252|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361358\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:38,436 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361358\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:38,436 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 767\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:38,436 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361358\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:38,454 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361358\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:38,455 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361358455\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:38,456 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361358\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:38,463 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1024, 1024)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:38,465 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1024, 1024)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:38,466 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,199 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.648, [50.47, 254.94, 958.64, 838.39])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,200 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.648 at location [50.47, 254.94, 958.64, 838.39]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,201 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:745.19|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361359,a4751409-7bc9-4275-8678-65fb5482b7ba, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,202 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:745.19|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:a4751409-7bc9-4275-8678-65fb5482b7ba,timestamp:1728361359\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,202 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 748\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,202 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361359\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,202 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:747246.098|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361359\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,202 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:221.093|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361359\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,203 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361359\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,203 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 747\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,203 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361359\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,222 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361359\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,222 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361359222\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,229 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361359\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,230 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (800, 800)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,231 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (800, 800)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,231 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,967 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,969 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:745.34|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361359,488dbef5-bee2-465e-885c-f1b0a236b861, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,969 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 748\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,969 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:745.34|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:488dbef5-bee2-465e-885c-f1b0a236b861,timestamp:1728361359\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,970 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361359\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,970 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:747391.05|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361359\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,970 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:142.123|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361359\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,970 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361359\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,970 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 747\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,971 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361359\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,991 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361359\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,992 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361359992\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:39,993 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361359\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:40,018 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (2560, 1707)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:40,026 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1707)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:40,027 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:40,787 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.18, [107.36, 124.48, 2475.23, 1506.52])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:40,788 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.18 at location [107.36, 124.48, 2475.23, 1506.52]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:40,791 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:797.25|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361360,a0f99fa8-aece-4d65-9957-d9adae9ea358, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:40,791 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:797.25|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:a0f99fa8-aece-4d65-9957-d9adae9ea358,timestamp:1728361360\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:40,792 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 802\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:40,792 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361360\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:40,792 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:799595.728|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361360\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:40,792 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:188.924|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361360\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:40,792 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361360\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:40,792 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 799\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:40,792 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361360\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:40,812 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361360\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:40,812 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361360812\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:40,813 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361360\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:40,827 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1200, 1151)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:40,830 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1200, 1151)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:40,830 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:41,610 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:41,611 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:797.83|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361361,dd004461-0fb0-4378-94fc-c02f0f87b7c4, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:41,612 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:797.83|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:dd004461-0fb0-4378-94fc-c02f0f87b7c4,timestamp:1728361361\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:41,612 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 801\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:41,612 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361361\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:41,612 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:799625.118|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361361\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:41,613 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:184.417|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361361\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:41,613 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361361\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:41,613 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 800\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:41,613 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361361\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:41,633 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361361\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:41,634 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361361634\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:41,635 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361361\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:41,641 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (800, 800)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:41,642 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (800, 800)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:41,642 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:42,368 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.497, [42.76, 168.83, 758.64, 622.75])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:42,368 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.497 at location [42.76, 168.83, 758.64, 622.75]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:42,370 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:734.72|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361362,361b8dae-763d-4012-931c-f29d658f2d75, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:42,370 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:734.72|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:361b8dae-763d-4012-931c-f29d658f2d75,timestamp:1728361362\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:42,370 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 737\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:42,371 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361362\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:42,371 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:736597.61|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361362\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:42,371 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:118.909|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361362\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:42,371 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361362\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:42,371 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 736\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:42,371 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361362\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:42,390 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361362\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:42,391 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361362391\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:42,392 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361362\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:42,412 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1200, 1200)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:42,415 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1200, 1200)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:42,416 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,150 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.338, [123.69, 115.55, 1093.3, 660.16])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,151 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.338 at location [123.69, 115.55, 1093.3, 660.16]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,152 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:760.01|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361363,152df6ae-c32f-48ef-a200-b06ba9adccc1, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,153 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:760.01|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:152df6ae-c32f-48ef-a200-b06ba9adccc1,timestamp:1728361363\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,153 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 763\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,153 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361363\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,154 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:762223.614|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361363\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,154 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:206.086|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361363\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,154 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361363\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,154 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 762\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,154 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361363\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,171 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361363\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,171 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361363171\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,172 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361363\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,180 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,182 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,182 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,918 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.535, [16.99, 356.57, 481.2, 638.64])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,918 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.535 at location [16.99, 356.57, 481.2, 638.64]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,922 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:749.32|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361363,46ab2cfd-d331-486e-b879-8e4b3295ef07, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,922 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:749.32|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:46ab2cfd-d331-486e-b879-8e4b3295ef07,timestamp:1728361363\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,923 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 753\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,923 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361363\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,923 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:751414.62|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361363\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,923 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:190.962|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361363\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,923 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361363\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,924 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 751\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,924 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361363\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,943 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361363\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,943 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361363943\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,952 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361363\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,966 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (2560, 1707)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,974 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1707)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:43,974 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:44,725 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.483, [98.83, 122.91, 2480.66, 1544.4])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:44,726 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.483 at location [98.83, 122.91, 2480.66, 1544.4]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:44,729 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:783.89|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361364,41b5f15f-a5b3-4fe8-957a-ec1318fe72c2, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:44,729 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:783.89|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:41b5f15f-a5b3-4fe8-957a-ec1318fe72c2,timestamp:1728361364\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:44,730 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 788\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:44,730 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361364\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:44,730 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:786458.141|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361364\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:44,730 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:224.46|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361364\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:44,730 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361364\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:44,730 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 784\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:44,730 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361364\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:44,747 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361364\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:44,748 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361364748\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:44,749 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361364\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:44,756 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:44,758 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:44,758 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:45,479 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.562, [101.67, 12.02, 947.19, 809.19])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:45,479 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.562 at location [101.67, 12.02, 947.19, 809.19]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:45,481 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:731.2|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361365,f6125d92-499b-4c89-929c-ccc36c7fddb1, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:45,481 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:731.2|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:f6125d92-499b-4c89-929c-ccc36c7fddb1,timestamp:1728361365\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:45,481 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 734\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:45,482 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361365\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:45,482 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:733585.242|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361365\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:45,482 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:486.032|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361365\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:45,483 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361365\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:45,483 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 733\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:45,483 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361365\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:45,501 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361365\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:45,502 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361365502\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:45,503 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361365\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:45,509 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:45,511 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:45,511 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:46,238 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.2, [1.11, 7.11, 989.59, 621.2]), ('a photo of a tv', 0.11, [395.66, 779.22, 568.99, 998.96])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:46,238 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.2 at location [1.11, 7.11, 989.59, 621.2]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:46,238 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.11 at location [395.66, 779.22, 568.99, 998.96]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:46,240 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:736.82|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361366,9b19ba19-0dd2-48a0-83d8-8b46e2d6a927, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:46,240 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:736.82|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:9b19ba19-0dd2-48a0-83d8-8b46e2d6a927,timestamp:1728361366\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:46,240 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 739\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:46,240 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361366\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:46,241 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:738661.429|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361366\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:46,241 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:252.825|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361366\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:46,241 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361366\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:46,241 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 738\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:46,241 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361366\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:46,259 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361366\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:46,260 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361366260\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:46,261 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361366\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:46,272 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1000, 667)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:46,274 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 667)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:46,274 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,010 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.357, [28.08, 40.34, 959.39, 591.82])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,011 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.357 at location [28.08, 40.34, 959.39, 591.82]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,012 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:750.7|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361367,37a5721e-2548-4024-b1ee-d623cefb9dbd, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,012 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:750.7|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:37a5721e-2548-4024-b1ee-d623cefb9dbd,timestamp:1728361367\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,012 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 753\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,012 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361367\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,013 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:752610.47|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361367\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,013 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:140.293|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361367\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,013 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361367\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,013 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 752\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,013 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361367\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,030 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361367\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,031 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361367031\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,032 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361367\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,037 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,039 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,039 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,768 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.362, [5.55, 164.72, 994.73, 764.57])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,769 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.362 at location [5.55, 164.72, 994.73, 764.57]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,771 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:738.81|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361367,bcd477d7-53fd-4cfa-9781-014e0bc03c83, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,771 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:738.81|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:bcd477d7-53fd-4cfa-9781-014e0bc03c83,timestamp:1728361367\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,772 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 741\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,772 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361367\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,772 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:740913.75|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361367\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,772 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:189.741|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361367\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,772 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361367\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,772 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 740\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,773 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361367\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,791 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361367\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,791 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361367791\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,792 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361367\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,795 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,796 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:47,796 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:48,532 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:48,534 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:742.11|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361368,6cded691-5f6f-4e8f-a43b-2cbea7375be8, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:48,535 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 745\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:48,535 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:742.11|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:6cded691-5f6f-4e8f-a43b-2cbea7375be8,timestamp:1728361368\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:48,535 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361368\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:48,536 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:743697.753|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361368\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:48,536 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:143.375|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361368\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:48,536 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361368\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:48,536 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 743\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:48,537 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361368\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:48,555 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361368\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:48,555 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361368555\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:48,557 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361368\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:48,564 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:48,566 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:48,566 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:49,289 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:49,291 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:734.26|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361369,791a71ea-cab7-46c1-9170-6c6a6a1d2ab6, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:49,291 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:734.26|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:791a71ea-cab7-46c1-9170-6c6a6a1d2ab6,timestamp:1728361369\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:49,292 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 738\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:49,292 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361369\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:49,292 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:736222.116|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361369\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:49,292 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:109.432|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361369\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:49,292 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361369\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:49,293 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 735\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:49,293 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361369\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:49,309 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361369\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:49,310 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361369309\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:49,311 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361369\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:49,312 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (355, 355)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:49,313 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (355, 355)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:49,313 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,035 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.405, [31.04, 82.34, 323.36, 260.4])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,035 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.405 at location [31.04, 82.34, 323.36, 260.4]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,037 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:726.3|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361370,39803ec8-553e-4920-8c4b-428e23b76801, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,037 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:726.3|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:39803ec8-553e-4920-8c4b-428e23b76801,timestamp:1728361370\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,038 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 729\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,038 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361370\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,038 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:728124.946|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361370\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,038 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:174.249|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361370\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,038 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361370\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,038 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 727\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,038 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361370\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,058 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361370\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,058 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361370058\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,059 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361370\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,073 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1096, 1350)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,075 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1096, 1350)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,075 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,810 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.124, [107.81, 7.3, 1010.18, 595.34])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,810 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.124 at location [107.81, 7.3, 1010.18, 595.34]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,812 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:752.9|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361370,466d6e03-272e-44c6-b0fb-614c8cda431a, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,812 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:752.9|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:466d6e03-272e-44c6-b0fb-614c8cda431a,timestamp:1728361370\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,813 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 756\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,813 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361370\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,813 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:754476.115|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361370\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,813 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:100.335|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361370\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,813 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361370\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,813 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 754\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,813 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361370\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,834 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361370\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,835 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361370835\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,837 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361370\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,915 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (2474, 2560)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,927 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (2474, 2560)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:50,927 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:51,697 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.153, [101.07, 217.56, 2356.59, 1508.04])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:51,697 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.153 at location [101.07, 217.56, 2356.59, 1508.04]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:51,700 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:863.63|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361371,02d5d740-2247-40eb-8e3d-3efa373bb84b, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:51,701 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 868\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:51,701 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:863.63|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:02d5d740-2247-40eb-8e3d-3efa373bb84b,timestamp:1728361371\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:51,701 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361371\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:51,701 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:866120.031|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361371\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:51,701 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:124.956|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361371\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:51,701 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361371\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:51,701 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 866\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:51,701 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361371\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:51,723 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361371\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:51,724 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361371724\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:51,729 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361371\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:51,732 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1024, 1024)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:51,735 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1024, 1024)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:51,735 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:52,502 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.401, [110.43, 101.04, 886.38, 946.76])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:52,503 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.401 at location [110.43, 101.04, 886.38, 946.76]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:52,504 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:778.7|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361372,4c8e5a83-2000-48a3-a7cf-5335def9fd90, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:52,504 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:778.7|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:4c8e5a83-2000-48a3-a7cf-5335def9fd90,timestamp:1728361372\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:52,504 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 782\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:52,505 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361372\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:52,505 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:780785.808|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361372\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:52,505 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:145.212|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361372\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:52,505 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361372\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:52,506 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 779\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:52,506 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361372\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:52,527 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361372\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:52,528 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361372528\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:52,529 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361372\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:52,548 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1200, 1200)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:52,551 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1200, 1200)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:52,551 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:53,325 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.354, [123.21, 113.43, 1095.53, 660.21])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:53,326 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.354 at location [123.21, 113.43, 1095.53, 660.21]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:53,327 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:798.27|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361373,eeb72431-4905-4c23-8bbe-7754c2e57fb8, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:53,328 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 801\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:53,328 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361373\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:53,328 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:800075.791|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361373\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:53,328 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:164.088|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361373\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:53,328 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361373\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:53,330 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 799\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:53,330 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361373\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:53,330 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:798.27|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:eeb72431-4905-4c23-8bbe-7754c2e57fb8,timestamp:1728361373\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:53,347 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361373\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:53,348 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361373348\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:53,350 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361373\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:53,362 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:53,363 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:53,364 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,099 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,101 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:750.33|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361374,c67eacfe-3816-4954-9f21-b817105c0fe8, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,101 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:750.33|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:c67eacfe-3816-4954-9f21-b817105c0fe8,timestamp:1728361374\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,101 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 754\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,101 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361374\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,101 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:753332.725|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361374\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,101 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:236.115|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361374\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,101 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361374\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,102 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 753\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,102 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361374\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,119 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361374\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,120 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361374120\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,121 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361374\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,128 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,131 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,131 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,874 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.423, [69.67, 62.53, 946.0, 857.17])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,874 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.423 at location [69.67, 62.53, 946.0, 857.17]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,876 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:755.35|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361374,fe52e1b2-c97d-439c-8e7d-ae6a76efae87, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,876 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:755.35|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:fe52e1b2-c97d-439c-8e7d-ae6a76efae87,timestamp:1728361374\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,877 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 758\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,877 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361374\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,877 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:757519.265|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361374\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,877 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:354.738|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361374\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,877 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361374\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,877 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 757\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,877 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361374\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,900 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361374\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,901 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361374901\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,902 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361374\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,903 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,904 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:54,904 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:55,667 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.403, [42.61, 131.83, 460.11, 395.16])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:55,667 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.403 at location [42.61, 131.83, 460.11, 395.16]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:55,669 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:767.28|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361375,5c6782dc-d34c-4947-a213-c3e81063029e, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:55,669 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:767.28|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:5c6782dc-d34c-4947-a213-c3e81063029e,timestamp:1728361375\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:55,670 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 770\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:55,670 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361375\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:55,670 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:769478.073|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361375\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:55,670 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:152.624|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361375\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:55,671 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361375\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:55,671 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 769\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:55,671 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361375\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:55,693 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361375\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:55,694 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361375694\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:55,695 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361375\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:55,714 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1350, 1080)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:55,718 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1350, 1080)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:55,718 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:56,483 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:56,485 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:790.05|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361376,def8c22c-4b8c-42fd-9af4-e70658e5b36d, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:56,485 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 797\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:56,486 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361376\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:56,486 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:790.05|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:def8c22c-4b8c-42fd-9af4-e70658e5b36d,timestamp:1728361376\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:56,487 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:791922.439|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361376\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:56,487 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:193.408|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361376\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:56,487 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361376\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:56,487 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 791\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:56,487 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361376\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:56,509 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361376\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:56,509 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361376509\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:56,510 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361376\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:56,517 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:56,520 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:56,520 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:57,254 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.517, [25.44, 200.68, 976.99, 813.84])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:57,255 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.517 at location [25.44, 200.68, 976.99, 813.84]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:57,257 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:746.37|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361377,39d0bc69-847a-44b8-8930-cc6fa6f21af6, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:57,257 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:746.37|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:39d0bc69-847a-44b8-8930-cc6fa6f21af6,timestamp:1728361377\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:57,257 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 749\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:57,257 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361377\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:57,257 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:748283.364|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361377\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:57,258 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:142.283|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361377\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:57,258 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361377\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:57,259 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 748\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:57,259 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361377\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:57,280 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361377\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:57,281 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361377280\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:57,282 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361377\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:57,294 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:57,295 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:57,296 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,086 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.159, [1.01, 138.81, 991.76, 723.69]), ('a photo of a tv', 0.166, [418.87, 715.18, 567.0, 909.27])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,087 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.159 at location [1.01, 138.81, 991.76, 723.69]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,087 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.166 at location [418.87, 715.18, 567.0, 909.27]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,091 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:809.03|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361378,686ab82b-1c34-4be0-90e8-bc6a03e91b2d, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,091 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:809.03|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:686ab82b-1c34-4be0-90e8-bc6a03e91b2d,timestamp:1728361378\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,091 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 811\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,091 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361378\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,091 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:810660.033|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361378\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,091 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:142.181|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361378\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,091 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361378\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,092 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 810\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,092 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361378\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,114 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361378\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,114 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361378114\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,115 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361378\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,124 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,126 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,127 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,863 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.404, [70.43, 121.1, 917.44, 872.43])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,863 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.404 at location [70.43, 121.1, 917.44, 872.43]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,867 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:751.13|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361378,84ce1f23-eb5c-4eef-b011-cfcacce4d701, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,867 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 753\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,867 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:751.13|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:84ce1f23-eb5c-4eef-b011-cfcacce4d701,timestamp:1728361378\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,867 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361378\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,868 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:752842.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361378\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,868 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:122.311|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361378\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,868 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361378\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,868 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 752\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,868 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361378\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,885 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361378\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,886 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361378886\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,887 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361378\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,897 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,899 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:58,899 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:59,681 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:59,683 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:795.71|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361379,96c052d0-eb0b-4d11-a46c-a1ae60cd23e7, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:59,683 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:795.71|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:96c052d0-eb0b-4d11-a46c-a1ae60cd23e7,timestamp:1728361379\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:59,683 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 798\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:59,683 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361379\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:59,684 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:797333.833|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361379\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:59,684 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:204.963|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361379\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:59,684 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361379\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:59,684 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 797\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:59,684 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361379\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:59,700 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361379\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:59,701 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361379701\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:59,702 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361379\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:59,727 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:59,732 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:22:59,732 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:00,494 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:00,498 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:795.76|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361380,26a40a07-acc7-40ca-8791-938b5f8cd0b2, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:00,498 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:795.76|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:26a40a07-acc7-40ca-8791-938b5f8cd0b2,timestamp:1728361380\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:00,498 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 798\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:00,498 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361380\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:00,499 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:797654.731|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361380\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:00,499 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:94.603|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361380\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:00,499 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361380\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:00,499 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 797\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:00,499 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361380\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:00,518 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361380\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:00,518 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361380518\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:00,525 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361380\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:00,549 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1764, 1390)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:00,554 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1764, 1390)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:00,554 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:01,334 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.409, [256.62, 86.77, 1544.77, 873.97])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:01,334 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.409 at location [256.62, 86.77, 1544.77, 873.97]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:01,336 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:816.16|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361381,3c527b00-7aab-4843-a112-66010bb5dfd1, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:01,336 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:816.16|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:3c527b00-7aab-4843-a112-66010bb5dfd1,timestamp:1728361381\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:01,337 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 819\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:01,337 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361381\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:01,337 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:818390.379|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361381\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:01,337 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:256.829|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361381\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:01,337 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361381\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:01,337 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 818\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:01,337 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361381\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:01,357 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361381\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:01,357 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361381357\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:01,358 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361381\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:01,369 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:01,371 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:01,371 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,160 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,162 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:803.57|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361382,938a8197-9708-476f-857f-61542609ec9c, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,162 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:803.57|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:938a8197-9708-476f-857f-61542609ec9c,timestamp:1728361382\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,163 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 806\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,163 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361382\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,163 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:805220.186|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361382\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,163 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:136.349|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361382\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,163 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361382\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,163 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 805\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,163 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361382\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,181 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361382\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,181 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361382181\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,182 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361382\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,184 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,185 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,185 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,914 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,916 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:734.01|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361382,7a43391e-46cd-4ec5-8446-baacd2a54189, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,916 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:734.01|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:7a43391e-46cd-4ec5-8446-baacd2a54189,timestamp:1728361382\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,917 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 736\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,917 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361382\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,917 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:735731.395|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361382\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,917 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:308.722|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361382\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,917 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361382\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,917 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 735\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,919 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361382\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,934 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361382\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,934 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361382934\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,937 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361382\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,946 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,948 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:02,948 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:03,675 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.313, [3.21, 133.89, 981.79, 700.98]), ('a photo of a tv', 0.113, [31.21, 731.98, 154.34, 896.65])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:03,675 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.313 at location [3.21, 133.89, 981.79, 700.98]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:03,675 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.113 at location [31.21, 731.98, 154.34, 896.65]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:03,677 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:740.11|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361383,d9ed425c-3ac0-4e20-8319-573f531b6532, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:03,677 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:740.11|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:d9ed425c-3ac0-4e20-8319-573f531b6532,timestamp:1728361383\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:03,677 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 743\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:03,677 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361383\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:03,677 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:742721.076|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361383\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:03,678 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:107.538|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361383\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:03,678 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361383\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:03,678 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 743\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:03,678 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361383\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:03,695 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361383\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:03,695 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361383695\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:03,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361383\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:03,707 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1248, 1248)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:03,710 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1248, 1248)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:03,711 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:04,462 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.615, [2.47, 186.15, 1242.83, 1064.09])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:04,462 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.615 at location [2.47, 186.15, 1242.83, 1064.09]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:04,466 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:769.62|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361384,5c2db6cc-ead2-4062-97c2-e0171553243a, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:04,466 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:769.62|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:5c2db6cc-ead2-4062-97c2-e0171553243a,timestamp:1728361384\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:04,466 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 771\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:04,466 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361384\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:04,467 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:771074.64|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361384\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:04,467 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:127.381|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361384\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:04,467 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361384\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:04,467 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 771\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:04,467 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361384\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:04,485 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361384\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:04,485 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361384485\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:04,486 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361384\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:04,503 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1500, 951)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:04,505 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 951)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:04,505 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:05,230 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.258, [17.02, 10.59, 1509.16, 895.44])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:05,230 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.258 at location [17.02, 10.59, 1509.16, 895.44]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:05,232 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:746.06|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361385,45b9b8c6-dc48-4395-a9e9-9dcb651e4c3a, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:05,232 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:746.06|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:45b9b8c6-dc48-4395-a9e9-9dcb651e4c3a,timestamp:1728361385\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:05,233 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 749\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:05,233 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361385\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:05,233 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:747848.048|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361385\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:05,233 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:104.632|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361385\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:05,233 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361385\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:05,233 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 748\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:05,233 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361385\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:05,253 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361385\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:05,254 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361385254\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:05,254 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361385\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:05,273 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:05,278 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:05,278 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,050 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,052 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:797.01|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361386,e9117021-5cd2-4aca-b0ad-dfbe887374db, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,052 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:797.01|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:e9117021-5cd2-4aca-b0ad-dfbe887374db,timestamp:1728361386\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,052 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 799\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,052 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361386\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,053 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:798848.421|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361386\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,053 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:104.093|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361386\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,053 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361386\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,053 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 798\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,053 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361386\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,070 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361386\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,070 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361386070\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,077 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361386\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,080 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1000, 925)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,082 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 925)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,082 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,858 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.471, [28.19, 8.09, 985.64, 567.61]), ('a photo of a tv', 0.325, [3.11, 579.06, 252.14, 890.2])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,859 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.471 at location [28.19, 8.09, 985.64, 567.61]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,859 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.325 at location [3.11, 579.06, 252.14, 890.2]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,862 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:790.62|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361386,2ec49a73-f4a0-4f9c-8e4b-ce7c227923d2, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,862 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:790.62|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:2ec49a73-f4a0-4f9c-8e4b-ce7c227923d2,timestamp:1728361386\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,863 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 793\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,863 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361386\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,863 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:792609.975|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361386\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,865 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:108.719|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361386\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,865 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361386\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,866 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 793\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,866 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361386\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,883 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361386\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,883 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361386883\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,889 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361386\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,895 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1024, 1024)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,896 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1024, 1024)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:06,897 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:07,664 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.192, [30.32, 104.0, 960.8, 913.7])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:07,665 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.192 at location [30.32, 104.0, 960.8, 913.7]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:07,666 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:782.18|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361387,1033f15c-ea0e-4361-98ea-037552f70e4b, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:07,667 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:782.18|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:1033f15c-ea0e-4361-98ea-037552f70e4b,timestamp:1728361387\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:07,667 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 785\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:07,667 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361387\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:07,667 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:783955.419|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361387\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:07,668 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:218.926|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361387\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:07,668 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361387\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:07,668 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 784\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:07,668 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361387\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:07,687 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361387\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:07,688 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361387688\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:07,689 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361387\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:07,704 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1500, 951)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:07,707 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 951)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:07,707 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:08,436 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.258, [17.02, 10.59, 1509.16, 895.44])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:08,436 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.258 at location [17.02, 10.59, 1509.16, 895.44]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:08,438 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:749.35|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361388,cc9d908e-0fce-443a-ae2c-e550bb8d1ce7, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:08,439 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:749.35|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:cc9d908e-0fce-443a-ae2c-e550bb8d1ce7,timestamp:1728361388\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:08,439 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 752\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:08,439 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361388\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:08,439 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:751166.716|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361388\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:08,439 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:88.311|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361388\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:08,439 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361388\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:08,439 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 751\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:08,439 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361388\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:08,457 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361388\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:08,457 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361388457\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:08,458 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361388\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:08,467 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:08,469 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:08,469 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,194 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,196 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:738.09|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361389,41b1990c-4953-4634-90b4-9d13252e8e24, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,197 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:738.09|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:41b1990c-4953-4634-90b4-9d13252e8e24,timestamp:1728361389\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,197 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 741\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,197 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361389\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,198 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:740057.138|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361389\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,198 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:205.376|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361389\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,198 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361389\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,198 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 740\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,198 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361389\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,215 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361389\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,217 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361389217\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,218 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361389\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,223 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,225 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,225 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,997 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.635, [12.91, 355.0, 489.6, 639.63]), ('a photo of a tv', 0.122, [19.54, 360.72, 482.3, 629.16])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,997 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.635 at location [12.91, 355.0, 489.6, 639.63]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,998 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.122 at location [19.54, 360.72, 482.3, 629.16]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,999 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:781.2|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361389,e911eb7d-04c3-479a-a75a-f4ac54719c15, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:09,999 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:781.2|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:e911eb7d-04c3-479a-a75a-f4ac54719c15,timestamp:1728361389\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,000 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 785\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,000 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361390\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,000 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:784432.293|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361390\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,000 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1879.838|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361390\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,000 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361390\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,000 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 782\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,000 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361390\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,018 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361390\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,018 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361390018\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,019 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361390\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,028 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1000, 892)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,030 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 892)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,030 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,748 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.192, [0.79, -2.61, 992.68, 571.46])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,748 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.192 at location [0.79, -2.61, 992.68, 571.46]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,750 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:730.54|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361390,a4cf5847-d3c4-4b8b-a73c-ed837d37107f, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,750 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:730.54|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:a4cf5847-d3c4-4b8b-a73c-ed837d37107f,timestamp:1728361390\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,750 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 732\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,750 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361390\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,750 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:732116.863|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361390\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,751 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:124.029|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361390\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,751 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361390\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,751 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 732\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,751 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361390\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,768 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361390\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,769 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361390769\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,770 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361390\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,772 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (476, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,772 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (476, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:10,772 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:11,492 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a dog', 0.208, [158.87, 147.68, 285.43, 267.75]), ('a photo of a tv', 0.521, [5.83, 16.25, 468.78, 496.23])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:11,492 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a dog with confidence 0.208 at location [158.87, 147.68, 285.43, 267.75]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:11,492 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.521 at location [5.83, 16.25, 468.78, 496.23]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:11,494 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:724.27|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361391,b1133687-70fa-4827-bf23-a7eb9108014e, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:11,494 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:724.27|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:b1133687-70fa-4827-bf23-a7eb9108014e,timestamp:1728361391\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:11,494 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 726\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:11,495 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361391\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:11,495 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:725927.235|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361391\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:11,495 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:239.266|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361391\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:11,495 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361391\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:11,495 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 725\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:11,495 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361391\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:11,512 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361391\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:11,512 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361391512\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:11,516 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361391\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:11,516 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (400, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:11,517 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (400, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:11,517 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:12,236 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:12,238 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:724.42|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361392,9bca25cc-2f17-48b0-a09b-8b9f66036f6f, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:12,238 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:724.42|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:9bca25cc-2f17-48b0-a09b-8b9f66036f6f,timestamp:1728361392\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:12,238 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 726\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:12,239 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361392\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:12,239 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:726169.984|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361392\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:12,241 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:99.567|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361392\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:12,241 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361392\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:12,241 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 726\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:12,241 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361392\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:12,256 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361392\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:12,256 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361392256\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:12,258 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361392\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:12,280 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:12,285 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:12,286 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,020 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.409, [127.87, 408.65, 1480.81, 1241.77])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,020 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.409 at location [127.87, 408.65, 1480.81, 1241.77]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,022 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:764.39|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361393,ba68569f-c0dd-4dc2-83f4-50b4abd7819b, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,023 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 767\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,023 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361393\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,023 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:766337.86|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361393\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,023 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:136.252|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361393\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,024 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361393\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,024 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 767\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,023 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:764.39|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:ba68569f-c0dd-4dc2-83f4-50b4abd7819b,timestamp:1728361393\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,024 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361393\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,045 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361393\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,045 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361393045\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,047 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361393\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,097 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (2560, 1707)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,105 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1707)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,105 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,866 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.124, [100.25, 84.51, 2465.71, 1467.32])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,866 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.124 at location [100.25, 84.51, 2465.71, 1467.32]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,872 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:825.14|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361393,c7deec0c-3954-4bcd-a0b8-d926d08a9bb0, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,872 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:825.14|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:c7deec0c-3954-4bcd-a0b8-d926d08a9bb0,timestamp:1728361393\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,872 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 828\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,872 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361393\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,872 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:827275.826|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361393\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,873 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:312.874|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361393\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,873 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361393\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,873 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 826\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,873 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361393\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,890 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361393\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,890 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361393890\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,891 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361393\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,896 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,898 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:13,898 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:14,619 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:14,622 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:730.14|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361394,25794896-05af-4597-a713-cec4b6afdb45, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:14,622 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:730.14|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:25794896-05af-4597-a713-cec4b6afdb45,timestamp:1728361394\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:14,622 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 732\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:14,622 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361394\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:14,622 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:731564.376|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361394\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:14,622 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:96.918|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361394\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:14,622 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361394\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:14,622 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 732\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:14,623 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361394\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:14,639 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361394\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:14,640 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361394640\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:14,641 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361394\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:14,644 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:14,645 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:14,645 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:15,372 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:15,374 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:732.55|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361395,39c52ba2-adc9-4dac-970a-71d0889fe2f2, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:15,374 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:732.55|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:39c52ba2-adc9-4dac-970a-71d0889fe2f2,timestamp:1728361395\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:15,374 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 735\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:15,374 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361395\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:15,374 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:734328.964|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361395\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:15,375 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:135.494|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361395\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:15,375 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361395\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:15,375 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 734\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:15,375 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361395\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:15,391 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361395\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:15,392 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361395392\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:15,397 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361395\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:15,398 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:15,400 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:15,401 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,134 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.365, [106.44, 74.93, 877.71, 905.11])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,134 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.365 at location [106.44, 74.93, 877.71, 905.11]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,136 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:743.09|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361396,f53e37c0-cd88-4688-9088-67b44645bfe5, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,136 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:743.09|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:f53e37c0-cd88-4688-9088-67b44645bfe5,timestamp:1728361396\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,136 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 745\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,136 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361396\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,136 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:744688.962|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361396\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,136 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:115.838|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361396\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,137 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361396\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,137 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 744\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,137 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361396\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,155 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361396\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,155 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361396155\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,156 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361396\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,196 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1992, 1951)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,203 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1992, 1951)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,204 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,724 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361396\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,729 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:86.60452270507812|#Level:Host|#hostname:58781440e71c,timestamp:1728361396\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,730 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:6.626853942871094|#Level:Host|#hostname:58781440e71c,timestamp:1728361396\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,730 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:7.1|#Level:Host|#hostname:58781440e71c,timestamp:1728361396\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,730 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:8833.796875|#Level:Host|#hostname:58781440e71c,timestamp:1728361396\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,731 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:6528.9921875|#Level:Host|#hostname:58781440e71c,timestamp:1728361396\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,731 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:43.7|#Level:Host|#hostname:58781440e71c,timestamp:1728361396\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,997 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.291, [96.19, 340.51, 1908.02, 1467.95])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,997 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.291 at location [96.19, 340.51, 1908.02, 1467.95]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,999 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:842.03|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361396,9eae0853-2133-4b99-a1a8-55c45df7340b, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,999 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:842.03|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:9eae0853-2133-4b99-a1a8-55c45df7340b,timestamp:1728361396\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,999 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 845\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,999 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361396\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,999 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:844023.811|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361396\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,999 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:192.556|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361396\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:16,999 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361396\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,000 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 844\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,000 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361397\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,030 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361397\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,031 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361397031\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,033 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361397\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,043 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1500, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,046 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,046 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,803 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.184, [129.85, 108.44, 1382.91, 830.29])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,803 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.184 at location [129.85, 108.44, 1382.91, 830.29]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,805 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:773.08|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361397,04496867-4157-48ff-9299-6ac38388b692, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,806 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:773.08|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:04496867-4157-48ff-9299-6ac38388b692,timestamp:1728361397\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,806 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 776\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,806 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361397\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,806 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:775414.762|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361397\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,806 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:411.407|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361397\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,806 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361397\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,806 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 774\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,806 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361397\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,832 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361397\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,833 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361397833\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,837 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361397\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,869 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (2560, 1920)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,879 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1920)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:17,879 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:18,640 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:18,642 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:807.52|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361398,8ee187de-18a7-4786-9915-b3dc12683174, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:18,642 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:807.52|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:8ee187de-18a7-4786-9915-b3dc12683174,timestamp:1728361398\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:18,642 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 810\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:18,642 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361398\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:18,643 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:809839.676|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361398\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:18,643 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:335.037|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361398\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:18,643 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361398\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:18,643 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 809\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:18,643 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361398\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:18,660 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361398\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:18,660 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361398660\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:18,662 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361398\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:18,672 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1500, 1500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:18,676 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 1500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:18,676 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:19,407 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:19,409 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:746.85|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361399,776d041a-1ccc-4473-aa63-f4a1e79a32f6, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:19,409 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 749\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:19,409 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361399\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:19,409 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:748652.483|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361399\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:19,409 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:746.85|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:776d041a-1ccc-4473-aa63-f4a1e79a32f6,timestamp:1728361399\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:19,410 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:110.517|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361399\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:19,410 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361399\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:19,410 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 749\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:19,410 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361399\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:19,427 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361399\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:19,427 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361399427\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:19,428 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361399\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:19,441 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1500, 951)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:19,444 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 951)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:19,444 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,179 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.258, [17.02, 10.59, 1509.16, 895.44])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,180 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.258 at location [17.02, 10.59, 1509.16, 895.44]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,184 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:755.97|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361400,1cc066ad-e2e3-4dd4-9b03-3e8bd6983556, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,184 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:755.97|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:1cc066ad-e2e3-4dd4-9b03-3e8bd6983556,timestamp:1728361400\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,185 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 758\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,185 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361400\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,185 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:757459.745|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361400\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,185 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:102.851|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361400\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,185 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361400\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,185 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 757\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,185 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361400\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,203 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361400\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,204 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361400204\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,205 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361400\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,232 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,238 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,238 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,978 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,980 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:775.49|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361400,97d168b3-ae19-4ec8-863e-14394c7fe871, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,980 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:775.49|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:97d168b3-ae19-4ec8-863e-14394c7fe871,timestamp:1728361400\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,981 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 778\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,981 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361400\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,981 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:777063.456|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361400\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,981 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:136.839|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361400\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,981 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361400\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,981 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 776\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,981 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361400\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,998 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361400\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:20,999 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361400999\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,000 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361400\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,011 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,016 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,016 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,761 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.392, [46.49, 80.79, 1547.59, 1439.22])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,761 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.392 at location [46.49, 80.79, 1547.59, 1439.22]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,763 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:762.89|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361401,6a68052a-6d1d-4e6f-8a58-116673ea5d2e, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,763 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:762.89|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:6a68052a-6d1d-4e6f-8a58-116673ea5d2e,timestamp:1728361401\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,763 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 765\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,763 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361401\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,763 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:764667.067|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361401\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,763 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:174.069|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361401\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,763 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361401\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,763 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 764\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,764 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361401\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,780 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361401\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,780 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361401780\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,781 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361401\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,793 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (938, 1428)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,795 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (938, 1428)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:21,795 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:22,522 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.266, [9.4, 64.38, 917.6, 630.48]), ('a photo of a tv', 0.114, [26.25, 39.48, 919.41, 854.31])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:22,522 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.266 at location [9.4, 64.38, 917.6, 630.48]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:22,522 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.114 at location [26.25, 39.48, 919.41, 854.31]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:22,524 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:742.83|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361402,dd3131e3-a98e-4e51-a8d5-8ca102184cba, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:22,524 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:742.83|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:dd3131e3-a98e-4e51-a8d5-8ca102184cba,timestamp:1728361402\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:22,525 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 745\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:22,525 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361402\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:22,525 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:744579.465|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361402\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:22,525 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:181.997|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361402\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:22,525 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361402\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:22,525 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 744\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:22,525 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361402\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:22,547 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361402\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:22,547 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361402547\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:22,548 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361402\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:22,560 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:22,565 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:22,565 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:23,361 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.455, [41.37, 235.08, 1536.21, 1434.55])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:23,361 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.455 at location [41.37, 235.08, 1536.21, 1434.55]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:23,364 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:815.96|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361403,5b73d25d-7498-4203-8fad-32d1786391e2, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:23,364 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:815.96|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:5b73d25d-7498-4203-8fad-32d1786391e2,timestamp:1728361403\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:23,365 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 819\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:23,365 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361403\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:23,365 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:817720.021|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361403\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:23,365 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:131.408|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361403\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:23,365 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361403\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:23,365 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 817\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:23,366 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361403\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:23,381 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361403\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:23,381 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361403381\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:23,382 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361403\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:23,387 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (800, 800)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:23,388 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (800, 800)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:23,388 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,151 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,154 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:772.57|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361404,4657ec6b-e6e9-4d24-bbae-073a68e7dd79, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,155 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:772.57|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:4657ec6b-e6e9-4d24-bbae-073a68e7dd79,timestamp:1728361404\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,155 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 774\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,155 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361404\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,155 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:774006.957|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361404\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,155 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:109.529|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361404\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,155 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361404\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,155 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 774\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,155 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361404\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,173 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361404\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,174 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361404174\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,184 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361404\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,186 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,187 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,187 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,903 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.512, [54.11, 225.53, 934.67, 780.64])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,903 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.512 at location [54.11, 225.53, 934.67, 780.64]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,905 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:726.92|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361404,8e84657b-d1b4-42f9-b6e2-6c37a820c095, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,905 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:726.92|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:8e84657b-d1b4-42f9-b6e2-6c37a820c095,timestamp:1728361404\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,905 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 732\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,905 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361404\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,906 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:731711.38|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361404\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,906 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:97.457|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361404\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,906 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361404\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,906 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 731\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,906 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361404\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,923 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361404\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,923 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361404923\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,925 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361404\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,941 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,943 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:24,943 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:25,676 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:25,678 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:753.33|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361405,f6291677-f6de-45ea-b694-1778ee76fd3b, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:25,678 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:753.33|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:f6291677-f6de-45ea-b694-1778ee76fd3b,timestamp:1728361405\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:25,679 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 756\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:25,679 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361405\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:25,679 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:755191.982|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361405\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:25,679 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:111.174|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361405\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:25,679 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361405\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:25,679 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 754\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:25,679 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361405\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:25,696 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361405\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:25,696 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361405696\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:25,697 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361405\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:25,707 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:25,712 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:25,712 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:26,505 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.378, [85.53, 413.01, 1517.02, 1372.75])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:26,505 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.378 at location [85.53, 413.01, 1517.02, 1372.75]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:26,508 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:811.08|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361406,55cf6118-92fd-44be-8e4a-f7ccf282bfa0, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:26,509 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:811.08|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:55cf6118-92fd-44be-8e4a-f7ccf282bfa0,timestamp:1728361406\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:26,509 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 814\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:26,509 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361406\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:26,509 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:813101.427|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361406\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:26,509 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:128.99|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361406\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:26,509 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361406\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:26,509 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 813\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:26,509 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361406\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:26,526 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361406\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:26,527 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361406526\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:26,527 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361406\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:26,534 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1000, 711)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:26,535 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 711)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:26,535 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:27,275 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:27,277 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:749.11|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361407,5f9e14e9-e85b-4b92-8aaf-12dad8d4601e, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:27,277 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:749.11|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:5f9e14e9-e85b-4b92-8aaf-12dad8d4601e,timestamp:1728361407\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:27,277 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 751\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:27,278 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361407\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:27,278 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:750497.427|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361407\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:27,278 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:108.867|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361407\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:27,278 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361407\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:27,279 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 750\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:27,279 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361407\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:27,297 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361407\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:27,297 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361407297\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:27,298 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361407\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:27,303 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:27,305 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:27,305 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,034 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.397, [29.09, 29.97, 964.09, 480.84]), ('a photo of a tv', 0.13, [47.68, 503.28, 417.03, 779.15])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,034 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.397 at location [29.09, 29.97, 964.09, 480.84]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,035 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.13 at location [47.68, 503.28, 417.03, 779.15]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,036 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:737.36|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361408,7762c0f8-66ab-4ea6-8226-c7eb4d0719be, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,036 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:737.36|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:7762c0f8-66ab-4ea6-8226-c7eb4d0719be,timestamp:1728361408\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,036 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 739\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,036 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361408\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,036 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:738960.621|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361408\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,037 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:131.479|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361408\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,037 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361408\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,037 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 739\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,037 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361408\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,056 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361408\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,057 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361408057\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,058 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361408\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,089 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,094 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,094 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,837 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.636, [38.32, 344.64, 1524.75, 1289.66])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,837 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.636 at location [38.32, 344.64, 1524.75, 1289.66]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,839 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:781.04|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361408,b8e33652-4e68-4812-af8f-e9ef55cf9cd3, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,839 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 783\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,839 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361408\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,840 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:782677.321|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361408\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,840 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:781.04|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:b8e33652-4e68-4812-af8f-e9ef55cf9cd3,timestamp:1728361408\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,840 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:188.202|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361408\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,840 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361408\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,841 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 782\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,841 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361408\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,857 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361408\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,858 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361408857\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,859 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361408\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,864 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,865 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:28,866 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:29,646 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.623, [32.86, 223.03, 947.48, 806.92])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:29,646 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.623 at location [32.86, 223.03, 947.48, 806.92]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:29,648 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:788.74|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361409,6c3bafd5-3b35-4667-9134-3d26ab199e79, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:29,648 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:788.74|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:6c3bafd5-3b35-4667-9134-3d26ab199e79,timestamp:1728361409\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:29,648 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 791\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:29,648 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361409\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:29,649 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:790780.057|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361409\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:29,649 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:122.911|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361409\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:29,649 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361409\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:29,649 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 790\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:29,649 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361409\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:29,671 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361409\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:29,671 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361409671\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:29,673 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361409\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:29,710 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (2440, 2560)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:29,724 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (2440, 2560)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:29,724 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:30,532 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.198, [77.34, 102.57, 2331.01, 1434.75]), ('a photo of a tv', 0.31, [1009.61, 1514.11, 1509.48, 2162.64])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:30,532 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.198 at location [77.34, 102.57, 2331.01, 1434.75]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:30,533 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.31 at location [1009.61, 1514.11, 1509.48, 2162.64]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:30,534 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:861.61|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361410,cb2c632d-14ce-402f-b5ff-3ebcb8cfadaf, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:30,535 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 864\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:30,535 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361410\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:30,535 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:861.61|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:cb2c632d-14ce-402f-b5ff-3ebcb8cfadaf,timestamp:1728361410\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:30,535 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:863382.302|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361410\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:30,535 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:95.525|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361410\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:30,535 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361410\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:30,535 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 864\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:30,535 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361410\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:30,553 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361410\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:30,553 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361410553\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:30,554 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361410\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:30,562 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:30,564 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:30,564 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:31,287 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.377, [0.67, 337.24, 506.2, 647.93])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:31,287 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.377 at location [0.67, 337.24, 506.2, 647.93]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:31,290 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:736.17|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361411,2080eb8d-e86f-48d6-b73e-415a7f84315c, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:31,290 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:736.17|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:2080eb8d-e86f-48d6-b73e-415a7f84315c,timestamp:1728361411\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:31,290 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 737\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:31,291 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361411\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:31,291 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:737596.996|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361411\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:31,291 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:115.069|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361411\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:31,291 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361411\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:31,291 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 737\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:31,291 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361411\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:31,307 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361411\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:31,308 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361411308\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:31,310 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361411\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:31,331 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:31,336 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:31,336 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,063 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,065 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:755.47|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361412,00ed65a1-c539-443a-94e5-d479d49e2a21, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,066 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:755.47|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:00ed65a1-c539-443a-94e5-d479d49e2a21,timestamp:1728361412\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,066 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 759\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,066 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361412\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,066 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:758222.238|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361412\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,066 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:117.311|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361412\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,066 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361412\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,066 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 758\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,066 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361412\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,084 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361412\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,084 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361412084\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,089 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361412\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,098 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1441, 1128)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,101 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1441, 1128)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,101 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,854 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,859 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:773.37|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361412,a3f36deb-def8-4bf5-ab61-c22b0a684e1e, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,859 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:773.37|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:a3f36deb-def8-4bf5-ab61-c22b0a684e1e,timestamp:1728361412\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,859 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 776\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,859 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361412\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,859 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:775024.122|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361412\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,859 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:139.792|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361412\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,859 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361412\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,859 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 775\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,859 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361412\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,876 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361412\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,876 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361412876\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,877 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361412\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,898 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,903 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:32,903 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:33,641 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:33,643 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:765.8|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361413,e1572972-aa5f-456e-a48a-de304d3880eb, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:33,643 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:765.8|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:e1572972-aa5f-456e-a48a-de304d3880eb,timestamp:1728361413\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:33,643 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 767\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:33,643 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361413\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:33,643 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:767283.407|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361413\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:33,643 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:131.742|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361413\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:33,644 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361413\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:33,644 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 767\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:33,644 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361413\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:33,661 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361413\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:33,662 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361413662\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:33,663 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361413\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:33,668 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1024, 1024)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:33,670 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1024, 1024)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:33,670 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:34,396 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.356, [46.5, 278.39, 1002.0, 860.31])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:34,396 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.356 at location [46.5, 278.39, 1002.0, 860.31]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:34,398 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:735.14|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361414,3fb8d370-277a-4761-83de-7e213bd87373, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:34,398 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:735.14|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:3fb8d370-277a-4761-83de-7e213bd87373,timestamp:1728361414\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:34,398 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 737\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:34,398 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361414\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:34,399 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:736770.874|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361414\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:34,399 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:210.68|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361414\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:34,399 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361414\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:34,399 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 736\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:34,399 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361414\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:34,415 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361414\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:34,416 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361414416\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:34,417 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361414\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:34,426 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1000, 667)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:34,427 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 667)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:34,427 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,141 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.357, [28.08, 40.34, 959.39, 591.82])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,142 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.357 at location [28.08, 40.34, 959.39, 591.82]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,143 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:726.19|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361415,72bd97ae-6a4c-409c-811f-d95bd51b3b18, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,143 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:726.19|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:72bd97ae-6a4c-409c-811f-d95bd51b3b18,timestamp:1728361415\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,143 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 728\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,144 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361415\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,144 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:727775.769|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361415\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,144 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:108.77|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361415\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,144 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361415\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,144 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 727\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,144 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361415\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,161 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361415\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,161 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361415161\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,162 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361415\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,167 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1024, 1024)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,169 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1024, 1024)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,169 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,927 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.569, [61.62, 196.53, 953.77, 808.84])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,927 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.569 at location [61.62, 196.53, 953.77, 808.84]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,929 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:766.55|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361415,092c6369-678e-486e-9fbf-1c355764715e, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,929 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:766.55|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:092c6369-678e-486e-9fbf-1c355764715e,timestamp:1728361415\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,929 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 769\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,929 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361415\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,929 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:768167.909|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361415\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,929 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:126.597|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361415\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,930 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361415\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,930 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 768\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,930 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361415\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,948 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361415\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,948 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361415948\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,949 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361415\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,973 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1500, 1500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,977 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 1500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:35,977 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:36,749 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:36,751 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:802.08|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361416,81a5b863-998e-49db-823f-faaacf321292, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:36,752 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:802.08|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:81a5b863-998e-49db-823f-faaacf321292,timestamp:1728361416\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:36,752 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 805\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:36,752 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361416\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:36,752 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:803747.731|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361416\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:36,752 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:107.121|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361416\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:36,752 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361416\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:36,752 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 804\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:36,752 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361416\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:36,769 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361416\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:36,770 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361416770\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:36,773 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361416\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:36,792 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1602, 1602)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:36,797 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1602, 1602)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:36,797 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:37,540 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.36, [69.08, 396.98, 1527.08, 1245.99])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:37,540 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.36 at location [69.08, 396.98, 1527.08, 1245.99]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:37,542 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:770.85|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361417,8899cb9a-721a-470a-89a5-132d91841c33, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:37,542 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:770.85|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:8899cb9a-721a-470a-89a5-132d91841c33,timestamp:1728361417\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:37,542 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 773\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:37,542 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361417\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:37,543 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:772571.524|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361417\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:37,543 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:181.967|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361417\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:37,543 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361417\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:37,543 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 772\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:37,543 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361417\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:37,562 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361417\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:37,562 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361417562\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:37,563 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361417\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:37,570 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:37,572 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:37,572 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:38,292 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.542, [25.1, 211.09, 955.67, 797.99])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:38,292 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.542 at location [25.1, 211.09, 955.67, 797.99]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:38,294 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:730.75|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361418,a0eed7a6-6503-4e73-a5e3-d9c252191543, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:38,294 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:730.75|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:a0eed7a6-6503-4e73-a5e3-d9c252191543,timestamp:1728361418\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:38,294 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 732\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:38,294 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361418\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:38,294 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:732184.509|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361418\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:38,294 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:97.221|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361418\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:38,295 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361418\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:38,295 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 732\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:38,295 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361418\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:38,312 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361418\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:38,312 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361418312\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:38,313 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361418\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:38,330 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1500, 951)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:38,333 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 951)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:38,333 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,136 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.258, [17.02, 10.59, 1509.16, 895.44])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,136 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.258 at location [17.02, 10.59, 1509.16, 895.44]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,139 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:825.57|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361419,6649c3e5-5889-48ff-805f-237e6d4da328, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,139 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:825.57|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:6649c3e5-5889-48ff-805f-237e6d4da328,timestamp:1728361419\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,140 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 828\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,140 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361419\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,140 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:827380.53|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361419\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,140 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:83.024|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361419\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,140 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361419\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,140 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 826\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,140 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361419\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,157 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361419\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,158 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361419158\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,159 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361419\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,162 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (500, 375)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,162 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 375)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,162 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,879 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.512, [55.18, 65.91, 451.87, 298.88])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,880 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.512 at location [55.18, 65.91, 451.87, 298.88]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,882 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:722.87|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361419,823e5e12-ad3e-4b18-b581-e43bd2e949aa, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,882 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:722.87|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:823e5e12-ad3e-4b18-b581-e43bd2e949aa,timestamp:1728361419\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,882 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 725\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,882 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361419\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,882 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:724509.003|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361419\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,882 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:88.352|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361419\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,882 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361419\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,882 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 724\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,882 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361419\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,914 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361419\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,914 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361419914\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,916 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361419\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,952 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (2560, 1524)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,960 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1524)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:39,960 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:40,703 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.101, [1.77, -29.88, 2547.67, 1481.27])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:40,703 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.101 at location [1.77, -29.88, 2547.67, 1481.27]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:40,705 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:788.78|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361420,3fccf851-c235-4e32-b868-0e70975d547c, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:40,705 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:788.78|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:3fccf851-c235-4e32-b868-0e70975d547c,timestamp:1728361420\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:40,706 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 800\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:40,706 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361420\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:40,706 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:791492.893|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361420\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:40,706 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:98.698|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361420\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:40,706 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361420\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:40,706 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 792\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:40,706 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361420\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:40,723 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361420\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:40,723 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361420723\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:40,724 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361420\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:40,725 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (300, 300)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:40,726 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (300, 300)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:40,726 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:41,454 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.159, [0.74, 81.23, 299.47, 222.11])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:41,455 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.159 at location [0.74, 81.23, 299.47, 222.11]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:41,456 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:732.26|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361421,d2c59a8e-83b4-4e66-a558-c8537a1b491f, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:41,457 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 734\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:41,457 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361421\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:41,457 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:733608.254|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361421\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:41,457 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:90.969|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361421\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:41,457 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361421\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:41,457 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 733\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:41,457 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361421\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:41,459 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:732.26|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:d2c59a8e-83b4-4e66-a558-c8537a1b491f,timestamp:1728361421\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:41,475 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361421\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:41,476 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361421476\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:41,477 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361421\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:41,528 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (2560, 1707)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:41,536 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1707)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:41,536 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:42,272 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.169, [120.47, 124.63, 2479.86, 1498.4])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:42,273 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.169 at location [120.47, 124.63, 2479.86, 1498.4]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:42,277 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:800.15|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361422,f545cfb1-a6f4-40e3-800f-67c919365df9, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:42,278 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:800.15|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:f545cfb1-a6f4-40e3-800f-67c919365df9,timestamp:1728361422\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:42,278 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 803\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:42,278 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361422\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:42,278 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:801810.435|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361422\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:42,278 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:98.968|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361422\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:42,279 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361422\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:42,279 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 801\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:42,279 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361422\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:42,297 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361422\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:42,298 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361422298\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:42,299 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361422\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:42,343 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (2560, 1707)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:42,351 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1707)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:42,351 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,092 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.268, [93.82, 118.82, 2446.0, 1498.6])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,092 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.268 at location [93.82, 118.82, 2446.0, 1498.6]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,094 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:794.9|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361423,e9ec4af8-165f-4037-818a-0075f2e5cafe, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,094 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:794.9|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:e9ec4af8-165f-4037-818a-0075f2e5cafe,timestamp:1728361423\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,094 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 797\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,094 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361423\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,095 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:796954.127|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361423\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,095 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:78.491|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361423\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,095 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361423\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,095 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 796\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,095 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361423\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,114 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361423\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,115 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361423115\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,116 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361423\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,131 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,137 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,137 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,881 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,884 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:768.42|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361423,8e762b34-edcc-41ed-98d7-290dea841504, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,885 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:768.42|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:8e762b34-edcc-41ed-98d7-290dea841504,timestamp:1728361423\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,885 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 771\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,885 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361423\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,885 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:770229.781|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361423\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,885 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:88.778|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361423\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,885 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361423\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,885 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 770\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,885 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361423\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,908 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361423\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,909 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361423909\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,911 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361423\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,950 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (2560, 2560)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,962 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 2560)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:43,963 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:44,749 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.408, [84.33, 533.45, 2463.1, 1987.2])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:44,749 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.408 at location [84.33, 533.45, 2463.1, 1987.2]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:44,752 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:841.47|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361424,591df0cc-1ded-4fdd-974c-56b2d70929ee, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:44,752 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:841.47|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:591df0cc-1ded-4fdd-974c-56b2d70929ee,timestamp:1728361424\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:44,753 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 845\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:44,753 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361424\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:44,753 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:844229.584|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361424\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:44,753 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:174.088|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361424\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:44,753 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361424\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:44,753 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 844\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:44,753 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361424\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:44,772 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361424\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:44,772 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361424772\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:44,775 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361424\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:44,815 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (2000, 1945)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:44,822 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (2000, 1945)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:44,823 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:45,570 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.474, [93.96, 330.91, 1919.39, 1457.04])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:45,570 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.474 at location [93.96, 330.91, 1919.39, 1457.04]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:45,572 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:796.53|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361425,97155a43-d2b4-4c4c-b267-ecb7c9f08151, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:45,572 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:796.53|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:97155a43-d2b4-4c4c-b267-ecb7c9f08151,timestamp:1728361425\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:45,572 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 800\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:45,572 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361425\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:45,572 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:799730.231|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361425\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:45,572 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:96.099|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361425\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:45,572 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361425\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:45,573 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 800\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:45,573 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361425\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:45,592 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361425\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:45,592 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361425592\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:45,593 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361425\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:45,612 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:45,617 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:45,618 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:46,571 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:46,574 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:980.67|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361426,9c97181e-6e62-4e93-8281-878b1efa836f, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:46,574 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 982\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:46,575 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361426\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:46,575 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:982205.086|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361426\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:46,575 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:86.085|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361426\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:46,575 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361426\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:46,575 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 982\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:46,575 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361426\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:46,575 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:980.67|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:9c97181e-6e62-4e93-8281-878b1efa836f,timestamp:1728361426\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:46,593 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361426\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:46,593 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361426593\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:46,598 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361426\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:46,610 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:46,615 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:46,615 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:47,627 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.528, [50.02, 341.17, 1543.5, 1230.9])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:47,627 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.528 at location [50.02, 341.17, 1543.5, 1230.9]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:47,629 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1031.44|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361427,f77f951b-a851-46f7-a4d6-ea699838facd, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:47,630 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:1031.44|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:f77f951b-a851-46f7-a4d6-ea699838facd,timestamp:1728361427\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:47,630 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 1038\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:47,630 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361427\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:47,630 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1036972.601|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361427\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:47,630 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:103.592|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361427\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:47,630 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361427\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:47,630 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1037\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:47,631 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361427\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:47,651 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361427\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:47,651 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361427651\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:47,652 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361427\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:47,660 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:47,662 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:47,663 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:48,989 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.505, [22.25, 354.42, 479.1, 631.62])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:48,989 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.505 at location [22.25, 354.42, 479.1, 631.62]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:48,991 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1338.71|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361428,d216bd4c-1128-4686-ac9e-ebae13307d1e, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:48,991 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:1338.71|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:d216bd4c-1128-4686-ac9e-ebae13307d1e,timestamp:1728361428\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:48,992 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 1340\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:48,992 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361428\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:48,992 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1340661.557|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361428\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:48,992 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:74.828|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361428\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:48,992 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361428\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:48,992 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1340\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:48,992 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361428\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:49,013 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361429\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:49,013 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361429013\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:49,017 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361429\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:49,021 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:49,021 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:49,021 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:50,031 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.574, [5.36, 102.36, 487.99, 385.75])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:50,031 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.574 at location [5.36, 102.36, 487.99, 385.75]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:50,033 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1015.76|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361430,da67b1b0-5948-43fa-a1a6-a3a3aff8cdf6, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:50,033 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:1015.76|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:da67b1b0-5948-43fa-a1a6-a3a3aff8cdf6,timestamp:1728361430\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:50,034 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 1021\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:50,034 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361430\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:50,034 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1020272.53|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361430\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:50,034 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:115.557|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361430\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:50,034 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361430\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:50,034 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1020\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:50,034 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361430\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:50,055 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361430\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:50,057 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361430057\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:50,058 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361430\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:50,069 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:50,071 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:50,071 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:51,092 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.512, [54.11, 225.53, 934.67, 780.64])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:51,092 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.512 at location [54.11, 225.53, 934.67, 780.64]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:51,095 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1036.79|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361431,2fa7ee31-360d-4048-8a2f-0151574b187b, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:51,095 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:1036.79|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:2fa7ee31-360d-4048-8a2f-0151574b187b,timestamp:1728361431\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:51,095 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 1040\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:51,096 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361431\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:51,096 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1040173.41|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361431\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:51,096 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1762.159|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361431\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:51,096 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361431\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:51,096 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1038\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:51,096 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361431\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:51,117 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361431\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:51,117 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361431117\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:51,121 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361431\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:51,127 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:51,129 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:51,129 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,006 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.138, [61.43, 253.68, 952.98, 754.55])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,006 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.138 at location [61.43, 253.68, 952.98, 754.55]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,008 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:886.12|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361432,38055858-02dc-4557-be53-2d49b818b48f, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,008 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:886.12|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:38055858-02dc-4557-be53-2d49b818b48f,timestamp:1728361432\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,008 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 891\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,008 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361432\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,008 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:891033.169|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361432\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,008 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:198.661|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361432\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,009 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361432\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,009 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 891\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,009 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361432\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,026 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361432\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,026 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361432026\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,027 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361432\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,030 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (945, 613)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,031 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (945, 613)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,031 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,839 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.357, [148.55, 61.15, 908.37, 514.79])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,839 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.357 at location [148.55, 61.15, 908.37, 514.79]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,845 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:817.55|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361432,91881695-002e-4da5-bae2-801c53104336, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,845 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:817.55|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:91881695-002e-4da5-bae2-801c53104336,timestamp:1728361432\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,845 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 820\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,845 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361432\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,845 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:819107.043|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361432\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,845 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:79.721|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361432\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,845 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361432\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,845 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 819\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,845 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361432\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,866 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361432\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,867 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361432867\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,869 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361432\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,936 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (2560, 1624)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,944 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1624)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:52,944 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:53,682 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.133, [1.32, -2.27, 2556.96, 1577.13])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:53,682 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.133 at location [1.32, -2.27, 2556.96, 1577.13]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:53,684 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:815.4|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361433,320df0b4-ee4e-4b00-ab4f-3aaf0b632944, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:53,684 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:815.4|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:320df0b4-ee4e-4b00-ab4f-3aaf0b632944,timestamp:1728361433\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:53,684 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 819\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:53,684 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361433\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:53,684 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:817788.376|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361433\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:53,684 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:229.623|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361433\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:53,685 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361433\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:53,685 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 817\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:53,685 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361433\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:53,703 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361433\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:53,704 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361433704\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:53,705 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361433\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:53,718 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:53,720 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:53,720 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:54,456 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.523, [5.76, 88.75, 990.47, 688.03]), ('a photo of a tv', 0.113, [433.26, 741.16, 567.31, 913.57])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:54,456 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.523 at location [5.76, 88.75, 990.47, 688.03]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:54,456 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.113 at location [433.26, 741.16, 567.31, 913.57]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:54,458 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:753.15|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361434,4b1a6d9f-8fae-4fd2-a79e-e53ce0ec9ca1, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:54,458 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:753.15|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:4b1a6d9f-8fae-4fd2-a79e-e53ce0ec9ca1,timestamp:1728361434\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:54,459 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 756\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:54,459 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361434\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:54,459 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:755459.132|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361434\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:54,460 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:93.605|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361434\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:54,460 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361434\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:54,460 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 755\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:54,460 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361434\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:54,481 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361434\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:54,482 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361434482\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:54,483 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361434\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:54,492 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:54,494 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:54,494 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:55,269 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.458, [48.11, 141.39, 957.78, 831.55])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:55,269 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.458 at location [48.11, 141.39, 957.78, 831.55]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:55,271 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:787.83|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361435,1a4f200e-ce82-43e7-bc77-ecd26a3a3043, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:55,271 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:787.83|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:1a4f200e-ce82-43e7-bc77-ecd26a3a3043,timestamp:1728361435\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:55,271 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 790\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:55,272 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361435\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:55,272 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:789511.957|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361435\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:55,272 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:111.477|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361435\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:55,272 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361435\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:55,272 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 789\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:55,272 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361435\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:55,289 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361435\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:55,289 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361435289\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:55,290 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361435\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:55,310 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1242, 1304)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:55,313 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1242, 1304)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:55,313 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,088 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.648, [70.53, 268.79, 1162.62, 969.8])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,088 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.648 at location [70.53, 268.79, 1162.62, 969.8]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,090 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:799.11|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361436,1de69745-7c4d-4735-b026-a43718862d94, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,090 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:799.11|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:1de69745-7c4d-4735-b026-a43718862d94,timestamp:1728361436\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,090 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 801\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,090 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361436\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,090 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:800842.445|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361436\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,090 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:179.732|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361436\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,090 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361436\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,090 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 801\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,090 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361436\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,108 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361436\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,109 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361436109\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,110 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361436\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,119 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1100, 1211)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,122 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1100, 1211)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,122 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,903 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.487, [34.29, 48.3, 1048.72, 663.38]), ('a photo of a tv', 0.131, [462.71, 693.63, 642.68, 1046.74])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,903 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.487 at location [34.29, 48.3, 1048.72, 663.38]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,903 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.131 at location [462.71, 693.63, 642.68, 1046.74]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,905 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:795.24|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361436,8587c95b-f790-4a15-acb0-d49424a9ee44, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,905 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:795.24|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:8587c95b-f790-4a15-acb0-d49424a9ee44,timestamp:1728361436\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,905 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 797\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,905 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361436\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,905 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:796685.038|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361436\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,905 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:99.695|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361436\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,906 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361436\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,906 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 796\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,906 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361436\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,922 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361436\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,922 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361436922\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,923 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361436\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,928 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1072, 596)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,929 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1072, 596)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:56,930 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:57,650 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:57,651 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:728.01|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361437,f907f6ca-e5ac-4f48-b6b2-9c18615c6e57, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:57,652 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:728.01|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:f907f6ca-e5ac-4f48-b6b2-9c18615c6e57,timestamp:1728361437\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:57,652 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 730\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:57,652 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361437\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:57,652 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:729324.955|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361437\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:57,652 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:101.55|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361437\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:57,652 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361437\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:57,652 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 729\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:57,652 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361437\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:57,669 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361437\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:57,669 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361437669\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:57,670 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361437\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:57,671 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (60, 40)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:57,671 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (60, 40)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:57,671 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:58,431 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:58,433 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:762.89|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361438,1afb35f6-10f5-49c8-9e2d-fd4b4f3b9c37, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:58,433 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:762.89|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:1afb35f6-10f5-49c8-9e2d-fd4b4f3b9c37,timestamp:1728361438\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:58,433 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 764\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:58,433 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361438\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:58,433 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:764027.788|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361438\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:58,433 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:73.032|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361438\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:58,433 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361438\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:58,434 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 764\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:58,434 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361438\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:58,450 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361438\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:58,451 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361438451\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:58,452 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361438\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:58,464 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:58,466 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:58,466 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:59,199 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.292, [9.34, 104.99, 1000.63, 683.06]), ('a photo of a tv', 0.153, [1.54, 55.78, 998.41, 984.89])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:59,199 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.292 at location [9.34, 104.99, 1000.63, 683.06]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:59,199 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.153 at location [1.54, 55.78, 998.41, 984.89]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:59,201 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:749.34|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361439,d057b9c8-71e9-42e2-b106-8d021cc8a375, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:59,201 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 751\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:59,201 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361439\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:59,202 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:750895.736|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361439\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:59,202 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:102.723|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361439\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:59,202 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361439\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:59,202 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 750\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:59,202 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361439\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:59,203 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:749.34|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:d057b9c8-71e9-42e2-b106-8d021cc8a375,timestamp:1728361439\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:59,219 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361439\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:59,220 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361439220\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:59,221 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361439\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:59,232 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:59,234 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:23:59,234 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,023 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.209, [13.36, 226.04, 979.46, 797.66])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,023 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.209 at location [13.36, 226.04, 979.46, 797.66]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,025 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:804.57|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361440,acc799c4-fc91-4779-82c2-e23a7bac20e8, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,026 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:804.57|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:acc799c4-fc91-4779-82c2-e23a7bac20e8,timestamp:1728361440\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,026 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 807\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,026 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361440\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,026 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:806167.64|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361440\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,026 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:112.484|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361440\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,026 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361440\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,026 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 806\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,026 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361440\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,046 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361440\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,046 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361440046\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,047 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361440\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,052 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,053 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,053 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,779 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,781 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:734.21|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361440,d7e59582-61c7-478a-812e-5cdfa469d70b, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,782 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:734.21|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:d7e59582-61c7-478a-812e-5cdfa469d70b,timestamp:1728361440\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,782 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 737\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,782 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361440\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,782 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:735726.854|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361440\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,782 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:108.283|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361440\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,782 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361440\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,782 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 735\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,783 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361440\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,802 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361440\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,802 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361440802\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,803 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361440\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,824 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (2560, 1707)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,832 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1707)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:00,833 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:01,603 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.391, [93.69, 120.1, 2473.29, 1486.83])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:01,604 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.391 at location [93.69, 120.1, 2473.29, 1486.83]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:01,606 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:801.91|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361441,6002c85c-2f09-48c8-9fd6-c193544a6a54, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:01,606 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:801.91|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:6002c85c-2f09-48c8-9fd6-c193544a6a54,timestamp:1728361441\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:01,606 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 804\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:01,606 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361441\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:01,606 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:803627.364|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361441\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:01,606 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:130.52|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361441\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:01,606 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361441\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:01,606 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 804\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:01,606 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361441\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:01,625 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361441\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:01,626 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361441626\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:01,626 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361441\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:01,628 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (500, 375)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:01,629 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 375)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:01,629 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:02,401 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.643, [27.57, 45.05, 471.74, 326.46])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:02,401 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.643 at location [27.57, 45.05, 471.74, 326.46]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:02,403 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:776.86|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361442,a9ddf496-7c17-4e35-a343-21344346a8a1, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:02,404 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:776.86|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:a9ddf496-7c17-4e35-a343-21344346a8a1,timestamp:1728361442\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:02,404 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 779\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:02,404 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361442\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:02,404 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:778301.46|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361442\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:02,404 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:87.484|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361442\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:02,405 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361442\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:02,405 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 778\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:02,405 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361442\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:02,421 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361442\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:02,421 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361442421\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:02,422 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361442\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:02,427 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:02,429 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:02,429 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,155 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.621, [12.62, 354.69, 488.59, 638.06]), ('a photo of a tv', 0.112, [21.17, 362.05, 480.11, 626.78])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,156 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.621 at location [12.62, 354.69, 488.59, 638.06]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,156 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.112 at location [21.17, 362.05, 480.11, 626.78]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,157 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:734.69|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361443,bfb85298-c01e-4664-9c00-5336afa02251, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,157 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:734.69|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:bfb85298-c01e-4664-9c00-5336afa02251,timestamp:1728361443\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,158 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 737\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,158 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361443\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,158 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:736920.545|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361443\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,158 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:240.551|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361443\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,158 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361443\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,159 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 736\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,159 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361443\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,176 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361443\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,176 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361443176\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,178 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361443\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,186 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1200, 1200)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,189 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1200, 1200)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,189 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,968 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.137, [190.76, 351.93, 1035.75, 889.91])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,968 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.137 at location [190.76, 351.93, 1035.75, 889.91]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,970 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:792.27|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361443,8313bd4c-4e38-4617-968c-ce0c7326167b, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,970 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:792.27|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:8313bd4c-4e38-4617-968c-ce0c7326167b,timestamp:1728361443\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,970 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 794\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,970 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361443\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,971 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:794091.603|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361443\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,971 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:227.07|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361443\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,971 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361443\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,971 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 793\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,971 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361443\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,989 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361443\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,989 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361443989\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:03,991 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361443\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:04,007 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1500, 1500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:04,012 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 1500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:04,012 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:04,769 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.19, [41.41, 327.4, 1455.96, 1220.82])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:04,769 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.19 at location [41.41, 327.4, 1455.96, 1220.82]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:04,773 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:781.3|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361444,897e05cb-1183-4ed6-8706-1392a6f18437, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:04,773 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:781.3|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:897e05cb-1183-4ed6-8706-1392a6f18437,timestamp:1728361444\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:04,773 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 785\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:04,773 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361444\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:04,773 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:783879.119|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361444\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:04,773 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:86.107|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361444\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:04,773 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361444\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:04,773 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 784\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:04,773 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361444\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:04,795 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361444\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:04,795 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361444795\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:04,801 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361444\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:04,815 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1500, 1500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:04,820 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 1500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:04,820 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:05,568 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.595, [5.08, -2.26, 1479.95, 980.23])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:05,570 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.595 at location [5.08, -2.26, 1479.95, 980.23]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:05,571 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:773.67|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361445,17c0be8c-5797-4d1f-87e9-0e5bc4448397, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:05,571 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:773.67|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:17c0be8c-5797-4d1f-87e9-0e5bc4448397,timestamp:1728361445\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:05,571 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 777\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:05,572 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361445\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:05,572 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:776333.481|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361445\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:05,573 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:173.161|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361445\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:05,573 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361445\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:05,574 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 775\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:05,574 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:4.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361445\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:05,593 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361445\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:05,593 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361445593\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:05,595 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361445\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:05,604 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1920, 1080)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:05,609 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1920, 1080)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:05,609 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:06,378 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a dog', 0.108, [774.68, 53.89, 1100.01, 554.97])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:06,378 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a dog with confidence 0.108 at location [774.68, 53.89, 1100.01, 554.97]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:06,381 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:786.8|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361446,46e635b2-7267-4074-a874-35b7b48fab7d, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:06,382 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:786.8|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:46e635b2-7267-4074-a874-35b7b48fab7d,timestamp:1728361446\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:06,382 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 790\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:06,383 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361446\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:06,383 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:789271.495|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361446\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:06,383 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:134.644|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361446\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:06,383 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361446\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:06,383 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 789\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:06,384 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361446\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:06,404 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361446\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:06,404 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361446404\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:06,406 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361446\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:06,440 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (2560, 1920)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:06,450 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1920)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:06,450 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,199 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,201 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:794.89|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361447,584ff4d3-b06b-42eb-963e-bdc4b67998b6, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,201 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:794.89|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:584ff4d3-b06b-42eb-963e-bdc4b67998b6,timestamp:1728361447\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,201 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 798\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,202 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361447\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,202 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:797615.179|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361447\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,202 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:92.388|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361447\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,202 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361447\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,202 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 797\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,202 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361447\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,219 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361447\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,219 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361447219\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,220 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361447\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,233 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,237 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,237 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,988 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.196, [7.88, 346.95, 1584.16, 1326.18])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,988 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.196 at location [7.88, 346.95, 1584.16, 1326.18]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,992 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:771.7|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361447,833acd78-7a51-477e-91d8-5691ee976956, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,992 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:771.7|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:833acd78-7a51-477e-91d8-5691ee976956,timestamp:1728361447\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,992 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 774\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,992 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361447\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,993 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:773315.423|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361447\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,993 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:107.582|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361447\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,993 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361447\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,993 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 773\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:07,993 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361447\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,009 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361448\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,009 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361448009\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,010 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361448\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,016 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (800, 800)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,017 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (800, 800)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,017 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,742 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,744 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:733.01|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361448,d71c2219-d9d8-499b-9177-4e210b0dcc95, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,744 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:733.01|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:d71c2219-d9d8-499b-9177-4e210b0dcc95,timestamp:1728361448\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,744 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 735\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,745 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361448\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,745 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:735137.537|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361448\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,745 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:99.307|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361448\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,745 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361448\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,745 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 735\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,745 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361448\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,765 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361448\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,765 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361448765\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,766 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361448\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,772 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,774 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:08,774 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:09,550 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.142, [36.82, 233.44, 982.13, 826.39])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:09,550 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.142 at location [36.82, 233.44, 982.13, 826.39]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:09,551 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:785.48|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361449,e3ba64d6-11b1-4545-a08b-b7ce682a81e2, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:09,552 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:785.48|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:e3ba64d6-11b1-4545-a08b-b7ce682a81e2,timestamp:1728361449\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:09,552 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 788\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:09,552 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361449\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:09,552 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:787008.28|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361449\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:09,552 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:69.518|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361449\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:09,552 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361449\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:09,552 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 787\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:09,552 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361449\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:09,569 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361449\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:09,569 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361449569\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:09,570 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361449\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:09,575 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1024, 1024)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:09,577 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1024, 1024)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:09,577 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:10,299 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:10,301 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:730.33|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361450,39316c37-aaf1-4cb1-b5fa-b3a7ee1bada6, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:10,301 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:730.33|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:39316c37-aaf1-4cb1-b5fa-b3a7ee1bada6,timestamp:1728361450\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:10,301 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 732\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:10,301 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361450\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:10,301 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:731725.34|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361450\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:10,301 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:113.908|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361450\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:10,301 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361450\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:10,301 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 732\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:10,301 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361450\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:10,318 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361450\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:10,319 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361450319\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:10,319 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361450\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:10,332 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1500, 951)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:10,334 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 951)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:10,335 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,117 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.258, [17.02, 10.59, 1509.16, 895.44])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,117 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.258 at location [17.02, 10.59, 1509.16, 895.44]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,121 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:801.35|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361451,f0a8e381-c557-4cd9-90cb-5a6765e39c7e, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,121 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:801.35|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:f0a8e381-c557-4cd9-90cb-5a6765e39c7e,timestamp:1728361451\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,121 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 803\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,121 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361451\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,122 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:802768.247|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361451\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,122 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:109.838|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361451\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,122 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361451\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,122 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 802\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,122 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361451\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,141 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361451\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,141 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361451141\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,142 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361451\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,153 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,157 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,158 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,896 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.392, [46.49, 80.79, 1547.59, 1439.22])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,896 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.392 at location [46.49, 80.79, 1547.59, 1439.22]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,898 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:755.68|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361451,efc8a4a4-1291-43a4-ad42-e4ef9df05107, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,898 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:755.68|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:efc8a4a4-1291-43a4-ad42-e4ef9df05107,timestamp:1728361451\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,898 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 758\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,898 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361451\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,898 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:757190.23|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361451\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,898 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.289|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361451\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,898 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361451\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,898 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 757\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,898 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361451\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,918 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361451\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,918 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361451918\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,919 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361451\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,933 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1615, 1637)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,938 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1615, 1637)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:11,938 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:12,687 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:12,691 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:771.97|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361452,20596464-cff2-4f94-bd61-77bcff511784, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:12,691 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:771.97|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:20596464-cff2-4f94-bd61-77bcff511784,timestamp:1728361452\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:12,691 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 774\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:12,692 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361452\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:12,692 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:773662.4|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361452\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:12,692 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:102.137|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361452\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:12,692 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361452\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:12,692 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 773\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:12,692 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361452\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:12,710 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361452\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:12,710 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361452710\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:12,711 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361452\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:12,715 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:12,716 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:12,716 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:13,429 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.461, [2.16, 87.97, 499.48, 397.29])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:13,429 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.461 at location [2.16, 87.97, 499.48, 397.29]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:13,430 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:719.38|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361453,1f558dd3-0c69-4662-87ef-c9b83e418a20, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:13,431 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:719.38|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:1f558dd3-0c69-4662-87ef-c9b83e418a20,timestamp:1728361453\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:13,431 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 722\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:13,431 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361453\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:13,431 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:720844.682|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361453\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:13,431 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:182.807|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361453\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:13,431 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361453\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:13,431 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 721\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:13,431 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361453\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:13,448 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361453\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:13,449 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361453449\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:13,450 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361453\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:13,457 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:13,459 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:13,459 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:14,246 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.341, [23.25, 355.15, 477.96, 628.33]), ('a photo of a tv', 0.373, [17.97, 358.35, 481.88, 634.66])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:14,247 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.341 at location [23.25, 355.15, 477.96, 628.33]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:14,247 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.373 at location [17.97, 358.35, 481.88, 634.66]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:14,248 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:798.19|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361454,a1acb01e-1f16-4a32-bc15-c9354e1eb588, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:14,248 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:798.19|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:a1acb01e-1f16-4a32-bc15-c9354e1eb588,timestamp:1728361454\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:14,248 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 800\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:14,249 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361454\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:14,249 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:799850.827|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361454\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:14,249 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:92.622|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361454\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:14,249 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361454\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:14,249 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 799\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:14,249 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361454\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:14,268 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361454\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:14,268 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361454268\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:14,269 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361454\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:14,298 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:14,303 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:14,303 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,100 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.133, [109.03, 383.61, 1479.03, 1210.32])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,100 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.133 at location [109.03, 383.61, 1479.03, 1210.32]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,101 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:832.24|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361455,a0592511-6fd1-418e-8514-8dca0cfe8798, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,102 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:832.24|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:a0592511-6fd1-418e-8514-8dca0cfe8798,timestamp:1728361455\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,102 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 835\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,102 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361455\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,102 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:833943.972|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361455\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,102 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:140.057|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361455\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,102 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361455\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,102 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 834\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,102 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361455\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,120 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361455\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,121 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361455121\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,122 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361455\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,149 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,154 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,155 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,928 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,930 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:808.37|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361455,10023a69-765d-4c6a-88b1-b10e0abb3e0d, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,930 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:808.37|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:10023a69-765d-4c6a-88b1-b10e0abb3e0d,timestamp:1728361455\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,931 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 812\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,931 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361455\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,931 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:810977.416|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361455\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,931 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:1202.934|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361455\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,931 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361455\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,931 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 810\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,931 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361455\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,950 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361455\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,950 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361455950\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,952 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361455\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,988 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (2000, 2000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,995 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (2000, 2000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:15,995 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,714 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361456\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,715 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:86.60366821289062|#Level:Host|#hostname:58781440e71c,timestamp:1728361456\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,715 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:6.627708435058594|#Level:Host|#hostname:58781440e71c,timestamp:1728361456\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,716 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:7.1|#Level:Host|#hostname:58781440e71c,timestamp:1728361456\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,716 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:8710.44140625|#Level:Host|#hostname:58781440e71c,timestamp:1728361456\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,719 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:6652.34375|#Level:Host|#hostname:58781440e71c,timestamp:1728361456\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,720 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:44.5|#Level:Host|#hostname:58781440e71c,timestamp:1728361456\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,808 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,810 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:858.19|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361456,8d06ca74-b80a-448e-9ce7-c0bf1a1dc33b, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,810 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:858.19|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:8d06ca74-b80a-448e-9ce7-c0bf1a1dc33b,timestamp:1728361456\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,810 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 860\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,811 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361456\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,811 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:860071.374|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361456\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,811 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:91.287|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361456\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,811 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361456\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,813 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 860\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,813 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361456\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,828 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361456\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,828 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361456828\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,829 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361456\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,831 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,832 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:16,832 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:17,558 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.589, [2.87, 76.06, 499.37, 413.3])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:17,558 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.589 at location [2.87, 76.06, 499.37, 413.3]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:17,562 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:732.96|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361457,1053e1b9-92a7-43e5-abf5-a5dff918753b, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:17,562 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:732.96|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:1053e1b9-92a7-43e5-abf5-a5dff918753b,timestamp:1728361457\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:17,563 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 735\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:17,563 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361457\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:17,563 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:734624.388|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361457\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:17,563 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.9|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361457\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:17,564 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361457\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:17,564 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 735\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:17,564 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361457\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:17,580 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361457\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:17,580 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361457580\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:17,581 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361457\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:17,608 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:17,613 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:17,613 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:18,382 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:18,386 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:805.06|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361458,08da6ea2-8f83-49b2-a820-1e314c5f812b, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:18,387 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:805.06|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:08da6ea2-8f83-49b2-a820-1e314c5f812b,timestamp:1728361458\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:18,387 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 807\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:18,387 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361458\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:18,387 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:806886.297|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361458\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:18,387 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:114.053|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361458\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:18,387 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361458\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:18,387 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 807\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:18,387 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361458\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:18,407 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361458\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:18,407 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361458407\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:18,409 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361458\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:18,436 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (2482, 2336)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:18,447 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (2482, 2336)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:18,448 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:19,218 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.447, [65.72, 40.65, 2430.13, 2094.19])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:19,218 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.447 at location [65.72, 40.65, 2430.13, 2094.19]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:19,222 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:812.58|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361459,ef4a634a-66e9-49c2-ba8d-4d9e321227df, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:19,222 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:812.58|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:ef4a634a-66e9-49c2-ba8d-4d9e321227df,timestamp:1728361459\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:19,222 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 816\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:19,222 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361459\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:19,222 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:814840.396|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361459\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:19,222 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:153.328|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361459\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:19,222 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361459\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:19,222 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 815\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:19,222 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361459\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:19,240 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361459\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:19,240 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361459240\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:19,241 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361459\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:19,254 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:19,258 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:19,258 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,045 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.22, [59.4, 277.11, 1484.36, 1375.83])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,045 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.22 at location [59.4, 277.11, 1484.36, 1375.83]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,047 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:805.77|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361460,a99a351d-efa4-4238-bbaf-6632f2a95947, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,047 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:805.77|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:a99a351d-efa4-4238-bbaf-6632f2a95947,timestamp:1728361460\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,047 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 808\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,047 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361460\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,047 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:807271.625|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361460\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,047 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:66.598|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361460\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,047 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361460\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,047 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 807\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,047 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361460\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,067 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361460\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,067 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361460067\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,068 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361460\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,078 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,079 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,080 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,813 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,815 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:747.08|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361460,5d182a94-6c93-47b4-a8bb-c37a8cf03b64, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,815 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:747.08|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:5d182a94-6c93-47b4-a8bb-c37a8cf03b64,timestamp:1728361460\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,816 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 749\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,816 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361460\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,816 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:748595.817|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361460\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,816 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:113.278|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361460\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,817 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361460\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,817 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 748\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,817 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361460\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,834 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361460\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,834 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361460834\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,836 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361460\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,902 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (2048, 2560)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,913 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (2048, 2560)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:20,914 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:21,686 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:21,688 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:851.85|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361461,9c0f7bdb-704c-41e3-bfed-d703948eb3f7, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:21,688 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:851.85|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:9c0f7bdb-704c-41e3-bfed-d703948eb3f7,timestamp:1728361461\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:21,688 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 854\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:21,688 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361461\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:21,689 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:853903.962|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361461\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:21,689 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:76.956|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361461\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:21,689 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361461\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:21,689 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 853\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:21,690 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361461\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:21,712 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361461\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:21,712 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361461712\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:21,713 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361461\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:21,737 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1920, 1080)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:21,741 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1920, 1080)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:21,741 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:22,542 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.395, [424.72, -0.02, 1473.83, 603.42])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:22,542 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.395 at location [424.72, -0.02, 1473.83, 603.42]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:22,547 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:833.57|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361462,28d8a2be-3bef-4ad6-8ac3-1ccdb5ac92e6, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:22,547 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:833.57|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:28d8a2be-3bef-4ad6-8ac3-1ccdb5ac92e6,timestamp:1728361462\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:22,547 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 835\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:22,547 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361462\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:22,548 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:835355.799|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361462\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:22,548 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:80.824|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361462\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:22,548 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361462\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:22,548 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 835\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:22,548 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361462\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:22,564 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361462\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:22,564 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361462564\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:22,565 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361462\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:22,577 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1500, 951)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:22,580 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 951)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:22,580 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:23,306 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.258, [17.02, 10.59, 1509.16, 895.44])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:23,306 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.258 at location [17.02, 10.59, 1509.16, 895.44]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:23,308 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:742.56|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361463,6f5863a3-ca47-4a69-a3e6-9e867526b017, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:23,308 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 744\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:23,308 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:742.56|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:6f5863a3-ca47-4a69-a3e6-9e867526b017,timestamp:1728361463\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:23,309 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361463\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:23,309 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:744037.597|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361463\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:23,309 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:116.793|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361463\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:23,309 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361463\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:23,309 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 743\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:23,309 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361463\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:23,325 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361463\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:23,326 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361463326\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:23,327 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361463\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:23,344 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1500, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:23,347 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:23,347 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,086 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.259, [14.12, 8.18, 1505.61, 897.58])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,086 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.259 at location [14.12, 8.18, 1505.61, 897.58]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,090 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:763.15|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361464,574c0a81-7659-487f-aaff-bfe335b623e0, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,090 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:763.15|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:574c0a81-7659-487f-aaff-bfe335b623e0,timestamp:1728361464\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,090 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 765\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,090 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361464\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,090 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:764589.475|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361464\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,090 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:111.248|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361464\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,090 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361464\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,090 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 764\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,091 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361464\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,108 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361464\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,108 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361464108\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,109 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361464\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,138 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,144 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,144 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,917 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.511, [123.98, 363.12, 1461.04, 1296.61]), ('a photo of a dog', 0.109, [1016.63, 707.02, 1447.28, 1185.62]), ('a photo of a dog', 0.131, [180.96, 801.68, 410.57, 1177.71])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,917 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.511 at location [123.98, 363.12, 1461.04, 1296.61]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,918 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a dog with confidence 0.109 at location [1016.63, 707.02, 1447.28, 1185.62]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,918 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a dog with confidence 0.131 at location [180.96, 801.68, 410.57, 1177.71]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,921 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:811.98|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361464,25dff737-c732-410a-8daa-50eb6a7792d9, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,921 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:811.98|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:25dff737-c732-410a-8daa-50eb6a7792d9,timestamp:1728361464\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,922 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 815\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,922 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361464\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,922 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:813865.998|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361464\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,922 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:109.677|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361464\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,922 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361464\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,922 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 813\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,922 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361464\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,939 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361464\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,939 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361464939\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,940 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361464\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,958 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,963 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:24,963 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:25,696 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:25,697 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:757.08|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361465,abc3763f-b380-49c7-8cfc-16dffd8ac6bc, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:25,698 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:757.08|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:abc3763f-b380-49c7-8cfc-16dffd8ac6bc,timestamp:1728361465\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:25,698 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 759\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:25,698 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361465\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:25,698 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:758421.393|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361465\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:25,698 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:148.331|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361465\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:25,698 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361465\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:25,698 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 759\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:25,698 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361465\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:25,715 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361465\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:25,716 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361465716\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:25,717 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361465\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:25,744 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:25,749 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:25,749 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:26,489 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.528, [20.64, 329.81, 1574.15, 1347.15])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:26,489 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.528 at location [20.64, 329.81, 1574.15, 1347.15]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:26,491 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:774.48|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361466,35aabf3d-4172-4ba7-8721-27c89b35931c, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:26,492 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:774.48|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:35aabf3d-4172-4ba7-8721-27c89b35931c,timestamp:1728361466\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:26,492 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 777\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:26,492 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361466\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:26,492 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:776164.718|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361466\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:26,492 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:184.641|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361466\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:26,492 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361466\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:26,492 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 775\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:26,492 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361466\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:26,508 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361466\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:26,508 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361466508\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:26,510 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361466\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:26,529 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:26,534 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:26,535 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:27,295 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:27,299 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:788.63|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361467,d2b3b62b-f9c4-4625-b53a-4e0f7dba0c61, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:27,299 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:788.63|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:d2b3b62b-f9c4-4625-b53a-4e0f7dba0c61,timestamp:1728361467\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:27,299 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 791\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:27,299 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361467\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:27,299 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:790791.651|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361467\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:27,299 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:72.57|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361467\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:27,299 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361467\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:27,299 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 791\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:27,299 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361467\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:27,316 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361467\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:27,316 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361467316\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:27,317 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361467\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:27,325 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1024, 1024)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:27,327 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1024, 1024)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:27,327 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,066 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,068 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:750.51|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361468,505d928b-ce19-4fe9-9322-889ffdc69f8c, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,068 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:750.51|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:505d928b-ce19-4fe9-9322-889ffdc69f8c,timestamp:1728361468\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,068 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 752\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,068 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361468\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,068 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:752197.629|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361468\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,068 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:90.707|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361468\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,069 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361468\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,069 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 752\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,069 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361468\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,088 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361468\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,088 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361468088\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,089 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361468\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,100 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,102 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,102 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,887 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,890 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:800.72|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361468,f155b25a-706f-48ac-94b5-e6ee0d4daebe, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,890 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 802\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,890 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:800.72|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:f155b25a-706f-48ac-94b5-e6ee0d4daebe,timestamp:1728361468\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,890 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361468\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,891 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:802288.513|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361468\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,891 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:178.155|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361468\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,891 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361468\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,891 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 802\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,891 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361468\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,908 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361468\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,908 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361468908\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,909 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361468\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,924 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1263, 1242)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,927 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1263, 1242)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:28,927 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:29,664 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.473, [221.29, 42.68, 1103.06, 592.44])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:29,664 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.473 at location [221.29, 42.68, 1103.06, 592.44]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:29,666 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:757.06|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361469,66017967-e956-41ae-a62c-05544659192d, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:29,667 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:757.06|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:66017967-e956-41ae-a62c-05544659192d,timestamp:1728361469\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:29,667 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 759\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:29,667 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361469\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:29,667 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:758504.734|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361469\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:29,667 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:74.467|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361469\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:29,667 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361469\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:29,667 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 759\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:29,667 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361469\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:29,683 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361469\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:29,684 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361469684\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:29,684 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361469\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:29,689 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (600, 450)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:29,689 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (600, 450)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:29,689 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:30,411 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:30,413 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:728.77|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361470,37459549-0c09-435e-92d9-5ecc4fc66a43, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:30,414 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:728.77|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:37459549-0c09-435e-92d9-5ecc4fc66a43,timestamp:1728361470\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:30,414 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 731\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:30,414 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361470\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:30,414 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:730026.418|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361470\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:30,414 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:78.951|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361470\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:30,414 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361470\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:30,414 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 729\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:30,414 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361470\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:30,431 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361470\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:30,431 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361470431\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:30,432 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361470\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:30,437 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:30,439 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:30,439 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,163 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.462, [5.57, 104.7, 995.68, 733.64])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,163 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.462 at location [5.57, 104.7, 995.68, 733.64]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,166 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:733.92|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361471,1688b59c-0f9a-4bc0-8c28-e002bc929428, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,166 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:733.92|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:1688b59c-0f9a-4bc0-8c28-e002bc929428,timestamp:1728361471\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,166 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 736\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,167 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361471\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,167 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:735683.385|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361471\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,167 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:98.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361471\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,167 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361471\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,167 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 735\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,167 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361471\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,186 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361471\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,186 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361471186\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,187 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361471\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,193 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1008, 662)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,194 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1008, 662)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,194 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,924 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.429, [45.33, 43.29, 963.79, 615.49])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,925 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.429 at location [45.33, 43.29, 963.79, 615.49]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,926 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:739.35|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361471,bb467575-3dce-45c8-b2c2-2acc208d7524, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,927 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 741\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,927 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361471\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,927 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:740714.555|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361471\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,927 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:75.161|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361471\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,927 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361471\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,928 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 741\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,928 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361471\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,928 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:739.35|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:bb467575-3dce-45c8-b2c2-2acc208d7524,timestamp:1728361471\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,946 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361471\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,946 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361471946\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,947 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361471\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,984 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (2560, 1938)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,994 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1938)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:31,994 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:32,752 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.355, [478.67, 298.01, 2063.03, 1225.09])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:32,752 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.355 at location [478.67, 298.01, 2063.03, 1225.09]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:32,754 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:806.23|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361472,803bc074-e69d-4620-8302-caebb782fb75, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:32,754 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:806.23|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:803bc074-e69d-4620-8302-caebb782fb75,timestamp:1728361472\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:32,754 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 808\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:32,754 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361472\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:32,754 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:807839.234|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361472\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:32,754 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:89.225|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361472\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:32,755 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361472\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:32,755 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 808\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:32,755 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361472\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:32,771 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361472\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:32,772 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361472772\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:32,777 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361472\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:32,782 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1000, 667)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:32,783 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 667)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:32,783 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:33,512 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.214, [36.35, 37.85, 968.01, 582.09])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:33,513 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.214 at location [36.35, 37.85, 968.01, 582.09]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:33,514 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:741.51|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361473,cd2a5c45-bcab-41db-bc17-5ee2dfa5d7f4, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:33,515 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:741.51|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:cd2a5c45-bcab-41db-bc17-5ee2dfa5d7f4,timestamp:1728361473\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:33,515 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 744\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:33,515 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361473\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:33,515 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:743327.725|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361473\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:33,515 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:98.316|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361473\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:33,515 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361473\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:33,515 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 743\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:33,515 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361473\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:33,531 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361473\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:33,531 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361473531\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:33,532 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361473\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:33,544 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:33,546 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:33,546 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:34,272 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.162, [28.2, 158.22, 968.96, 822.51])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:34,272 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.162 at location [28.2, 158.22, 968.96, 822.51]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:34,274 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:741.8|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361474,7a2c836f-2dcc-4e35-b52b-bcef7ed4c002, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:34,274 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:741.8|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:7a2c836f-2dcc-4e35-b52b-bcef7ed4c002,timestamp:1728361474\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:34,274 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 743\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:34,275 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361474\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:34,275 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:743181.519|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361474\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:34,275 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:88.579|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361474\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:34,275 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361474\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:34,275 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 743\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:34,275 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361474\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:34,293 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361474\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:34,293 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361474293\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:34,294 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361474\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:34,307 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:34,309 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:34,309 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,048 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.487, [18.19, 216.46, 790.47, 740.34])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,048 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.487 at location [18.19, 216.46, 790.47, 740.34]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,050 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 757\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,050 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361475\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,051 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:757255.558|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361475\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,051 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:72.048|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361475\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,051 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361475\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,051 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 757\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,051 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361475\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,051 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:755.69|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361475,2c50b9ac-0a74-4943-9c79-880c8e7f9134, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,051 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:755.69|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:2c50b9ac-0a74-4943-9c79-880c8e7f9134,timestamp:1728361475\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,068 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361475\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,068 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361475068\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,069 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361475\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,089 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,093 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,094 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,866 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,868 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:798.99|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361475,64617d95-d66c-4306-9b4a-3f966f1272ff, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,868 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:798.99|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:64617d95-d66c-4306-9b4a-3f966f1272ff,timestamp:1728361475\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,869 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 801\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,869 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361475\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,869 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:800692.571|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361475\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,871 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:112.819|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361475\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,871 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361475\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,871 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 801\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,871 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361475\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,887 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361475\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,887 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361475887\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,888 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361475\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,902 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,908 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:35,908 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:36,695 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.309, [35.42, 379.89, 1594.17, 1335.12])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:36,695 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.309 at location [35.42, 379.89, 1594.17, 1335.12]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:36,697 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:809.14|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361476,3ba3a089-dbaa-48a1-b001-9849101e985f, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:36,697 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:809.14|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:3ba3a089-dbaa-48a1-b001-9849101e985f,timestamp:1728361476\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:36,697 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 811\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:36,697 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361476\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:36,697 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:810517.129|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361476\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:36,697 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:79.194|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361476\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:36,698 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361476\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:36,698 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 810\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:36,698 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361476\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:36,718 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361476\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:36,718 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361476718\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:36,720 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361476\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:36,752 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (2422, 2560)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:36,764 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (2422, 2560)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:36,764 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:37,550 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.194, [1035.31, 1513.63, 1406.04, 2240.57]), ('a photo of a tv', 0.13, [-32.83, -22.85, 2375.5, 2479.28])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:37,551 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.194 at location [1035.31, 1513.63, 1406.04, 2240.57]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:37,551 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.13 at location [-32.83, -22.85, 2375.5, 2479.28]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:37,553 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:832.54|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361477,55846d10-e70a-4c10-accc-878a756f2672, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:37,553 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:832.54|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:55846d10-e70a-4c10-accc-878a756f2672,timestamp:1728361477\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:37,553 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 835\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:37,553 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361477\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:37,553 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:834414.3|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361477\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:37,553 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:92.384|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361477\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:37,553 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361477\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:37,554 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 834\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:37,554 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361477\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:37,574 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361477\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:37,574 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361477574\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:37,575 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361477\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:37,594 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1180, 1269)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:37,597 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1180, 1269)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:37,598 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:38,331 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.484, [26.51, 38.39, 1142.57, 700.7]), ('a photo of a tv', 0.115, [450.36, 661.27, 717.66, 728.22]), ('a photo of a tv', 0.151, [481.55, 760.41, 680.13, 1127.94])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:38,331 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.484 at location [26.51, 38.39, 1142.57, 700.7]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:38,331 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.115 at location [450.36, 661.27, 717.66, 728.22]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:38,331 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.151 at location [481.55, 760.41, 680.13, 1127.94]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:38,333 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:758.3|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361478,4a842002-e4b2-4e4b-aa3e-72d313ece464, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:38,333 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:758.3|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:4a842002-e4b2-4e4b-aa3e-72d313ece464,timestamp:1728361478\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:38,334 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 761\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:38,334 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361478\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:38,334 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:759841.266|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361478\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:38,334 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:94.28|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361478\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:38,334 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361478\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:38,334 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 759\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:38,334 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361478\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:38,353 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361478\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:38,354 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361478354\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:38,355 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361478\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:38,398 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (2457, 2560)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:38,411 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (2457, 2560)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:38,411 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:39,199 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.113, [90.3, 132.16, 2358.85, 1487.3]), ('a photo of a tv', 0.156, [45.18, 50.79, 2403.72, 2488.81]), ('a photo of a tv', 0.208, [1050.73, 1529.16, 1424.31, 2267.75])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:39,199 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.113 at location [90.3, 132.16, 2358.85, 1487.3]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:39,199 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.156 at location [45.18, 50.79, 2403.72, 2488.81]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:39,199 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.208 at location [1050.73, 1529.16, 1424.31, 2267.75]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:39,201 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:845.73|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361479,5c4af6d0-3807-43bb-966c-5d40d920f2b2, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:39,201 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:845.73|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:5c4af6d0-3807-43bb-966c-5d40d920f2b2,timestamp:1728361479\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:39,202 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 849\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:39,202 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361479\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:39,202 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:848101.409|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361479\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:39,202 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:134.921|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361479\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:39,202 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361479\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:39,202 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 848\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:39,202 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361479\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:39,219 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361479\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:39,220 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361479220\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:39,221 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361479\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:39,255 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (2560, 1584)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:39,262 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1584)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:39,263 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,035 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.108, [578.45, 96.89, 1985.42, 929.82])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,035 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.108 at location [578.45, 96.89, 1985.42, 929.82]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,037 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:816.55|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361480,c4b786d3-fdde-43d7-b7f3-e0b66191ddd6, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,037 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:816.55|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:c4b786d3-fdde-43d7-b7f3-e0b66191ddd6,timestamp:1728361480\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,038 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 818\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,038 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361480\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,038 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:818004.88|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361480\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,038 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:64.755|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361480\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,038 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361480\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,038 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 817\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,038 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361480\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,054 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361480\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,054 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361480054\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,057 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361480\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,062 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1000, 586)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,063 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 586)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,063 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,833 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,835 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:779.73|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361480,8665710e-11be-4130-948d-23025556b703, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,835 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:779.73|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:8665710e-11be-4130-948d-23025556b703,timestamp:1728361480\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,835 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 781\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,835 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361480\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,836 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:781147.889|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361480\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,836 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:83.401|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361480\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,836 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361480\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,836 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 781\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,836 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361480\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,854 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361480\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,854 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361480854\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,855 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361480\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,866 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1500, 1500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,870 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 1500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:40,870 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:41,613 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.43, [71.23, 333.76, 1457.08, 1191.44])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:41,614 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.43 at location [71.23, 333.76, 1457.08, 1191.44]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:41,615 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:760.09|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361481,9b0fe0e4-ce17-47fe-9531-abb73adbba01, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:41,616 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:760.09|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:9b0fe0e4-ce17-47fe-9531-abb73adbba01,timestamp:1728361481\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:41,616 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 762\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:41,616 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361481\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:41,616 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:761513.465|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361481\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:41,616 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:78.889|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361481\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:41,616 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361481\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:41,616 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 762\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:41,616 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361481\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:41,633 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361481\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:41,633 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361481633\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:41,634 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361481\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:41,640 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:41,642 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:41,642 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:42,404 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.504, [109.36, 235.46, 969.62, 794.25])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:42,404 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.504 at location [109.36, 235.46, 969.62, 794.25]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:42,406 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:771.32|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361482,53f80e99-0158-484c-bbf7-4b2d2a46fdd0, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:42,406 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:771.32|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:53f80e99-0158-484c-bbf7-4b2d2a46fdd0,timestamp:1728361482\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:42,406 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 773\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:42,406 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361482\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:42,406 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:773124.903|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361482\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:42,406 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:123.43|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361482\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:42,406 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361482\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:42,406 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 773\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:42,407 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361482\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:42,424 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361482\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:42,424 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361482424\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:42,425 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361482\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:42,430 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1024, 1024)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:42,432 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1024, 1024)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:42,432 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:43,198 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.191, [29.79, 102.0, 959.14, 912.4])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:43,198 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.191 at location [29.79, 102.0, 959.14, 912.4]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:43,200 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:774.68|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361483,adf725cd-08dc-43d0-843f-6c2050c545d3, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:43,200 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:774.68|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:adf725cd-08dc-43d0-843f-6c2050c545d3,timestamp:1728361483\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:43,200 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 776\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:43,200 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361483\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:43,201 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:776387.995|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361483\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:43,201 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:97.86|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361483\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:43,201 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361483\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:43,201 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 776\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:43,201 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361483\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:43,218 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361483\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:43,218 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361483218\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:43,221 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361483\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:43,225 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (800, 800)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:43,226 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (800, 800)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:43,226 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,003 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,005 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:785.4|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361484,27a08fdb-6a5f-4760-85bd-b42e17e7e31a, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,005 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 787\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,005 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361484\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,006 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:786925.354|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361484\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,006 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:77.021|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361484\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,006 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361484\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,006 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 787\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,006 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361484\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,006 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:785.4|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:27a08fdb-6a5f-4760-85bd-b42e17e7e31a,timestamp:1728361484\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,023 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361484\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,024 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361484024\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,026 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361484\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,077 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (2560, 1938)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,087 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1938)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,087 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,859 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.262, [485.79, 296.56, 2059.97, 1215.47]), ('a photo of a tv', 0.106, [1097.2, 1181.33, 1455.07, 1279.13])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,859 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.262 at location [485.79, 296.56, 2059.97, 1215.47]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,859 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.106 at location [1097.2, 1181.33, 1455.07, 1279.13]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,861 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:834.98|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361484,764802f9-45b3-4b75-b64d-0a14d0ffb26f, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,861 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:834.98|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:764802f9-45b3-4b75-b64d-0a14d0ffb26f,timestamp:1728361484\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,861 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 838\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,862 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361484\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,862 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:837856.424|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361484\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,862 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:110.199|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361484\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,862 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361484\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,862 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 837\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,862 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361484\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,879 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361484\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,879 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361484879\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,880 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361484\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,882 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,883 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:44,883 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:45,603 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.745, [48.79, 106.12, 456.31, 376.16])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:45,603 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.745 at location [48.79, 106.12, 456.31, 376.16]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:45,605 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:725.27|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361485,ccb947e0-7a2a-4da0-ac93-0481bf63801d, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:45,605 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:725.27|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:ccb947e0-7a2a-4da0-ac93-0481bf63801d,timestamp:1728361485\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:45,606 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 727\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:45,606 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361485\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:45,606 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:726713.693|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361485\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:45,606 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.084|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361485\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:45,606 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361485\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:45,606 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 726\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:45,606 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361485\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:45,623 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361485\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:45,624 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361485624\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:45,624 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361485\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:45,638 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:45,643 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:45,643 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:46,424 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.707, [116.36, 283.19, 1416.58, 1361.44]), ('a photo of a tv', 0.108, [123.26, 280.09, 1483.01, 1353.56])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:46,424 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.707 at location [116.36, 283.19, 1416.58, 1361.44]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:46,425 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.108 at location [123.26, 280.09, 1483.01, 1353.56]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:46,426 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:801.67|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361486,62f53db0-f9ac-4657-a918-572e09feb523, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:46,426 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:801.67|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:62f53db0-f9ac-4657-a918-572e09feb523,timestamp:1728361486\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:46,427 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 804\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:46,427 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361486\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:46,427 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:803150.685|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361486\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:46,427 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:74.471|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361486\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:46,427 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361486\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:46,427 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 803\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:46,427 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361486\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:46,444 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361486\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:46,444 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361486444\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:46,445 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361486\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:46,450 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1024, 1024)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:46,452 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1024, 1024)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:46,452 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:47,172 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:47,174 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:728.62|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361487,603921d6-52ac-474d-accb-9f8932ab1e2a, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:47,174 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 731\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:47,174 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361487\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:47,174 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:730133.106|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361487\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:47,174 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:728.62|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:603921d6-52ac-474d-accb-9f8932ab1e2a,timestamp:1728361487\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:47,174 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:95.28|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361487\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:47,175 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361487\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:47,175 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 730\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:47,175 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361487\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:47,193 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361487\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:47,193 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361487193\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:47,194 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361487\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:47,239 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (2000, 2000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:47,246 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (2000, 2000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:47,246 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,035 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.474, [271.23, 479.85, 1759.71, 1434.07])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,035 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.474 at location [271.23, 479.85, 1759.71, 1434.07]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,037 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:842.17|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361488,7874d536-b99f-4d8e-a7ad-febf1c1ea552, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,037 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:842.17|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:7874d536-b99f-4d8e-a7ad-febf1c1ea552,timestamp:1728361488\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,037 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 844\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,037 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361488\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,037 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:844052.692|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361488\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,038 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:106.494|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361488\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,038 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361488\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,038 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 844\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,038 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361488\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,055 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361488\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,055 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361488055\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,056 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361488\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,068 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,071 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,071 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,816 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,820 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:763.15|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361488,82b45fca-20fd-4a54-b76e-44f73a5d3466, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,820 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:763.15|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:82b45fca-20fd-4a54-b76e-44f73a5d3466,timestamp:1728361488\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,820 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 765\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,820 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361488\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,820 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:764790.984|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361488\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,820 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:95.389|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361488\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,820 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361488\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,820 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 765\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,820 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361488\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,837 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361488\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,837 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361488837\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,838 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361488\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,857 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,862 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:48,862 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:49,634 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:49,636 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:797.69|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361489,c91a5abb-544f-4ca8-873f-310360d4c987, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:49,636 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:797.69|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:c91a5abb-544f-4ca8-873f-310360d4c987,timestamp:1728361489\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:49,636 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 799\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:49,636 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361489\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:49,637 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:799297.855|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361489\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:49,637 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:101.858|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361489\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:49,637 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361489\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:49,637 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 799\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:49,637 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361489\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:49,654 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361489\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:49,654 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361489654\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:49,657 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361489\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:49,682 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (2000, 2000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:49,689 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (2000, 2000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:49,689 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:50,442 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.571, [10.63, 316.9, 2003.36, 1679.75])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:50,442 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.571 at location [10.63, 316.9, 2003.36, 1679.75]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:50,445 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:790.53|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361490,f4ecdf24-f7fc-4989-b332-75bf31a3a644, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:50,446 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:790.53|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:f4ecdf24-f7fc-4989-b332-75bf31a3a644,timestamp:1728361490\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:50,446 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 793\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:50,446 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361490\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:50,446 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:791918.529|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361490\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:50,446 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:85.175|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361490\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:50,446 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361490\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:50,446 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 792\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:50,446 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361490\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:50,463 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361490\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:50,463 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361490463\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:50,464 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361490\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:50,479 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:50,484 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:50,484 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:51,258 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.51, [58.24, 363.17, 1582.79, 1252.01])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:51,258 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.51 at location [58.24, 363.17, 1582.79, 1252.01]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:51,263 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:798.47|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361491,087f2304-699d-46ba-80bd-e7a4d9ab9a9c, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:51,263 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 800\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:51,263 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361491\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:51,263 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:799881.259|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361491\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:51,264 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:82.326|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361491\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:51,264 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361491\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:51,264 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 800\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:51,264 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361491\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:51,265 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:798.47|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:087f2304-699d-46ba-80bd-e7a4d9ab9a9c,timestamp:1728361491\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:51,280 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361491\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:51,281 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361491281\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:51,281 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361491\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:51,292 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:51,294 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:51,294 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,024 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,026 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:744.28|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361492,b0d3b230-b378-4f31-83f2-02ecbc05c81d, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,026 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:744.28|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:b0d3b230-b378-4f31-83f2-02ecbc05c81d,timestamp:1728361492\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,026 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 746\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,026 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361492\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,026 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:745735.39|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361492\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,026 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:171.312|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361492\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,027 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361492\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,027 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 745\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,027 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361492\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,043 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361492\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,043 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361492043\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,044 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361492\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,061 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1500, 951)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,064 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 951)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,064 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,796 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.258, [17.02, 10.59, 1509.16, 895.44])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,796 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.258 at location [17.02, 10.59, 1509.16, 895.44]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,798 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:753.58|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361492,99f106e4-b7c9-4b6f-b94e-a69bd044fcce, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,798 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:753.58|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:99f106e4-b7c9-4b6f-b94e-a69bd044fcce,timestamp:1728361492\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,798 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 755\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,798 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361492\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,798 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:754908.87|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361492\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,798 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:74.032|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361492\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,798 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361492\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,798 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 755\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,798 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361492\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,819 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361492\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,819 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361492819\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,821 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361492\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,883 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (2445, 2560)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,895 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (2445, 2560)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:52,895 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:53,652 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.301, [118.08, 135.76, 2330.99, 1412.29])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:53,652 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.301 at location [118.08, 135.76, 2330.99, 1412.29]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:53,654 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:832.76|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361493,a2a0b8aa-e210-4bc4-b61f-44ee8304e09a, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:53,654 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:832.76|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:a2a0b8aa-e210-4bc4-b61f-44ee8304e09a,timestamp:1728361493\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:53,654 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 836\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:53,655 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361493\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:53,655 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:835347.89|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361493\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:53,655 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:146.15|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361493\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:53,655 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361493\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:53,655 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 834\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:53,655 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361493\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:53,671 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361493\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:53,671 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361493671\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:53,672 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361493\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:53,676 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:53,677 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:53,677 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:54,407 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:54,409 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:736.67|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361494,e26bcaf6-2c47-4e08-b6fe-0c48d9204863, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:54,409 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:736.67|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:e26bcaf6-2c47-4e08-b6fe-0c48d9204863,timestamp:1728361494\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:54,410 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 739\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:54,413 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361494\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:54,413 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:738346.035|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361494\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:54,413 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:112.277|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361494\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:54,413 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361494\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:54,413 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 738\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:54,413 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:4.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361494\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:54,432 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361494\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:54,433 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361494433\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:54,434 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361494\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:54,446 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1650, 1650)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:54,451 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1650, 1650)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:54,451 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:55,231 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.666, [100.78, 386.78, 1591.8, 1296.79])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:55,231 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.666 at location [100.78, 386.78, 1591.8, 1296.79]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:55,233 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:799.53|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361495,5b87e369-7721-408d-bf61-c03311c70a17, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:55,234 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:799.53|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:5b87e369-7721-408d-bf61-c03311c70a17,timestamp:1728361495\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:55,234 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 802\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:55,234 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361495\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:55,234 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:801195.806|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361495\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:55,235 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:79.442|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361495\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:55,235 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361495\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:55,235 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 801\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:55,235 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361495\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:55,252 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361495\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:55,252 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361495252\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:55,257 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361495\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:55,259 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:55,261 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:55,261 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,047 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.503, [64.08, 120.06, 960.79, 882.46])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,047 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.503 at location [64.08, 120.06, 960.79, 882.46]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,049 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:795.79|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361496,c03aec4c-6107-45ee-b681-47c49d83ea44, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,049 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:795.79|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:c03aec4c-6107-45ee-b681-47c49d83ea44,timestamp:1728361496\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,050 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 799\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,050 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361496\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,050 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:797554.486|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361496\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,050 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:121.503|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361496\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,050 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361496\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,050 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 797\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,050 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361496\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,069 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361496\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,069 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361496069\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,070 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361496\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,105 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,111 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,111 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,853 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,855 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:785.02|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361496,9b6d3f3d-ab15-4aa8-b9bd-7d8a0f775ab0, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,855 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:785.02|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:9b6d3f3d-ab15-4aa8-b9bd-7d8a0f775ab0,timestamp:1728361496\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,856 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 787\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,856 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361496\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,856 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:786509.247|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361496\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,856 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:99.546|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361496\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,856 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361496\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,856 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 786\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,856 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361496\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,873 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361496\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,873 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361496873\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,875 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361496\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,881 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1100, 1100)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,883 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1100, 1100)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:56,883 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:57,655 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:57,659 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:783.91|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361497,b8f327bb-9664-4b8a-8cce-56ef745d6469, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:57,659 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:783.91|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:b8f327bb-9664-4b8a-8cce-56ef745d6469,timestamp:1728361497\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:57,659 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 786\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:57,660 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361497\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:57,660 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:786082.792|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361497\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:57,660 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:78.55|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361497\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:57,660 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361497\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:57,660 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 786\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:57,660 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361497\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:57,678 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361497\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:57,678 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361497678\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:57,679 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361497\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:57,743 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (2560, 2521)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:57,755 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 2521)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:57,756 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:58,512 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.142, [198.83, 170.61, 2465.23, 1464.31])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:58,512 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.142 at location [198.83, 170.61, 2465.23, 1464.31]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:58,514 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:835.26|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361498,a565df90-2407-4dc9-b338-a0856c3abdd0, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:58,515 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:835.26|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:a565df90-2407-4dc9-b338-a0856c3abdd0,timestamp:1728361498\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:58,515 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 838\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:58,515 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361498\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:58,515 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:836815.682|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361498\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:58,515 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:103.608|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361498\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:58,515 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361498\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:58,515 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 836\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:58,515 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361498\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:58,532 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361498\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:58,532 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361498532\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:58,533 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361498\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:58,545 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:58,549 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:58,549 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:59,329 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.51, [58.24, 363.17, 1582.79, 1252.01])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:59,329 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.51 at location [58.24, 363.17, 1582.79, 1252.01]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:59,332 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:798.68|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361499,efc81206-56c7-401e-a9f4-df34c8b9c58e, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:59,333 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:798.68|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:efc81206-56c7-401e-a9f4-df34c8b9c58e,timestamp:1728361499\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:59,333 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 801\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:59,333 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361499\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:59,333 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:800195.675|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361499\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:59,333 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:79.156|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361499\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:59,333 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361499\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:59,333 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 800\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:59,333 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361499\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:59,354 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361499\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:59,354 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361499354\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:59,355 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361499\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:59,366 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:59,371 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:24:59,371 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,121 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.371, [54.52, 226.74, 1483.86, 1495.43])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,121 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.371 at location [54.52, 226.74, 1483.86, 1495.43]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,123 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:767.71|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361500,ef6bd54a-6051-4545-a0a5-e9743b61fade, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,123 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:767.71|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:ef6bd54a-6051-4545-a0a5-e9743b61fade,timestamp:1728361500\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,123 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 773\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,123 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361500\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,123 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:769048.94|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361500\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,123 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:90.214|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361500\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,123 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361500\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,123 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 768\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,123 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361500\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,141 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361500\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,141 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361500141\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,142 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361500\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,159 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1500, 1009)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,162 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 1009)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,162 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,952 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.137, [18.09, -4.86, 1511.74, 991.96])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,952 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.137 at location [18.09, -4.86, 1511.74, 991.96]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,956 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:813.81|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361500,d60e32ff-e593-4af7-a8fa-72de033bc3c6, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,957 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 816\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,957 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:813.81|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:d60e32ff-e593-4af7-a8fa-72de033bc3c6,timestamp:1728361500\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,957 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361500\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,957 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:815256.968|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361500\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,957 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:91.567|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361500\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,957 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361500\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,957 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 815\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,957 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361500\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,975 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361500\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,976 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361500976\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:00,977 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361500\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:01,005 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (2115, 1522)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:01,011 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (2115, 1522)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:01,011 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:01,745 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.436, [297.41, 116.67, 1806.35, 1003.06])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:01,745 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.436 at location [297.41, 116.67, 1806.35, 1003.06]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:01,747 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:770.03|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361501,0e764098-77cf-4c88-a547-9ce7c7468927, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:01,747 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:770.03|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:0e764098-77cf-4c88-a547-9ce7c7468927,timestamp:1728361501\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:01,747 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 772\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:01,747 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361501\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:01,747 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:771464.727|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361501\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:01,747 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:94.549|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361501\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:01,747 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361501\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:01,747 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 771\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:01,747 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361501\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:01,764 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361501\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:01,764 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361501764\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:01,765 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361501\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:01,772 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:01,774 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:01,774 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:02,554 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.236, [23.71, 230.65, 983.65, 803.16])]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:02,554 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.236 at location [23.71, 230.65, 983.65, 803.16]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:02,556 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:791.11|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361502,9c4425f6-72ce-4fa0-9b31-b893ebd9fb0a, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:02,556 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:791.11|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:9c4425f6-72ce-4fa0-9b31-b893ebd9fb0a,timestamp:1728361502\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:02,557 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 793\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:02,557 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361502\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:02,557 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:792609.122|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361502\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:02,557 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:116.004|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361502\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:02,557 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361502\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:02,557 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 793\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:02,557 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361502\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:02,574 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361502\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:02,574 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1728361502574\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:02,575 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1728361502\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:02,578 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (500, 375)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:02,578 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 375)\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:02,578 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:03,315 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:03,320 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:744.68|#ModelName:model,Level:Model|#type:GAUGE|#hostname:58781440e71c,1728361503,7e6c6e89-9e0f-4aa3-ad3e-2fed28cdf24a, pattern=[METRICS]\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:03,320 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:744.68|#ModelName:model,Level:Model|#hostname:58781440e71c,requestID:7e6c6e89-9e0f-4aa3-ad3e-2fed28cdf24a,timestamp:1728361503\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:03,320 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:57780 \"POST /invocations HTTP/1.1\" 200 746\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:03,320 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361503\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:03,320 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:745921.236|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361503\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:03,320 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:88.633|#model_name:model,model_version:default|#hostname:58781440e71c,timestamp:1728361503\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:03,320 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361503\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:03,320 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 746\n",
      "awyhp9kkim-algo-1-h60p9  | 2024-10-08T04:25:03,320 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:58781440e71c,timestamp:1728361503\n",
      "Gracefully stopping... (press Ctrl+C again to force)\n"
     ]
    }
   ],
   "source": [
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=sm_model_name, \n",
    "    ExecutionRoleArn=role, \n",
    "    PrimaryContainer=container,\n",
    ")\n",
    "\n",
    "import json\n",
    "texts = json.dumps([[\"a photo of a tv\", \"a photo of a dog\"]])\n",
    "\n",
    "env = {\"threshold\" : \"0.1\",\n",
    "       \"texts\" : texts}\n",
    "\n",
    "\n",
    "response = sm_client.create_transform_job(\n",
    "    TransformJobName=job_name,\n",
    "    ModelName=sm_model_name,\n",
    "    MaxConcurrentTransforms=2,\n",
    "    MaxPayloadInMB=2,\n",
    "    BatchStrategy=\"SingleRecord\", ##'MultiRecord',\n",
    "    Environment=env,\n",
    "    TransformInput={\n",
    "        'DataSource': {\n",
    "            'S3DataSource': {\n",
    "                'S3DataType': 'S3Prefix',\n",
    "                'S3Uri': input_image_path \n",
    "            }\n",
    "        },\n",
    "        'ContentType': \"application/x-image\",\n",
    "    },\n",
    "    TransformOutput={\n",
    "        'S3OutputPath': output_path,\n",
    "        'Accept': 'application/json',\n",
    "    },\n",
    "    TransformResources={\n",
    "        'InstanceType': 'ml.m5.2xlarge',\n",
    "        'InstanceCount': 1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error response from daemon: Cannot kill container: 295673d1428f: No such container: 295673d1428f\n"
     ]
    }
   ],
   "source": [
    "!docker kill 295673d1428f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating the container in SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-714932599119/240929-deploy-owl-vit/compressed_model/model.tar.gz'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "# Set to True to enable SageMaker to run locally\n",
    "# local_mode = True\n",
    "local_mode = False\n",
    "\n",
    "if local_mode:\n",
    "    from sagemaker.local import LocalSession\n",
    "    instance_type = \"local_gpu\"\n",
    "    sm_session = LocalSession()\n",
    "    sm_session.config = {'local': {'local_code': True}}\n",
    "    sm_client = sagemaker.local.LocalSagemakerClient()\n",
    "    smr_client = sagemaker.local.LocalSagemakerRuntimeClient()\n",
    "    model_data=f\"file://{Path.cwd()}/{local_model_weight}\"\n",
    "    input_image_path = f\"file://{Path.cwd()}/ecommerce-products/tv\"\n",
    "    output_path = f\"{Path.cwd()}/batchtransform-output\"\n",
    "else:\n",
    "    instance_type = \"ml.m5.2xlarge\"\n",
    "    sm_session = sagemaker.Session()\n",
    "    sm_client = boto3.client(\"sagemaker\")\n",
    "    smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "    model_data = f\"{model_data_url}/model.tar.gz\"\n",
    "    input_image_path = f\"{s3_input_data_path}/tv\"\n",
    "    output_path = f\"s3://{bucket}/{prefix}/batchtransform-output\"\n",
    "\n",
    "instance_count = 1\n",
    "ts = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "sm_model_name = f\"{local_model_weight}-model-{ts}\"\n",
    "endpoint_config_name = f\"{local_model_weight}-endpoint-config-{ts}\"\n",
    "job_name = f\"{local_model_weight}-batchtranform-{ts}\"\n",
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "container = {\n",
    "    \"Image\": image_uri,\n",
    "    \"ModelDataUrl\": model_data,\n",
    "    \"Environment\": {}\n",
    "}\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=sm_model_name, \n",
    "    ExecutionRoleArn=role, \n",
    "    PrimaryContainer=container,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "texts = json.dumps([[\"a photo of a tv\", \"a photo of a dog\"]])\n",
    "\n",
    "env = {\"threshold\" : \"0.1\",\n",
    "       \"texts\" : texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = sm_client.create_transform_job(\n",
    "    TransformJobName=job_name,\n",
    "    ModelName=sm_model_name,\n",
    "    MaxConcurrentTransforms=2,\n",
    "    MaxPayloadInMB=2,\n",
    "    BatchStrategy=\"SingleRecord\", ##'MultiRecord',\n",
    "    Environment=env,\n",
    "    TransformInput={\n",
    "        'DataSource': {\n",
    "            'S3DataSource': {\n",
    "                'S3DataType': 'S3Prefix',\n",
    "                'S3Uri': input_image_path \n",
    "            }\n",
    "        },\n",
    "        'ContentType': \"application/x-image\",\n",
    "    },\n",
    "    TransformOutput={\n",
    "        'S3OutputPath': output_path,\n",
    "        'Accept': 'application/json',\n",
    "    },\n",
    "    TransformResources={\n",
    "        'InstanceType': 'ml.m5.2xlarge',\n",
    "        'InstanceCount': 1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: Completed\n",
      "Batch Transform job completed successfully.\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/1.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/10.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/100.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/101.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/102.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/103.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/104.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/105.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/106.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/107.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/108.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/109.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/11.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/110.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/111.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/112.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/113.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/114.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/115.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/116.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/117.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/118.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/119.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/12.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/120.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/121.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/122.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/123.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/124.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/125.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/126.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/127.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/128.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/129.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/13.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/130.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/131.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/132.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/133.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/134.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/135.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/136.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/137.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/138.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/139.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/14.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/140.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/141.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/142.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/143.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/144.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/145.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/146.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/147.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/148.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/149.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/15.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/150.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/151.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/152.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/153.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/154.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/155.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/156.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/157.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/158.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/159.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/16.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/160.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/161.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/162.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/163.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/164.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/165.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/166.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/167.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/168.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/169.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/17.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/170.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/171.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/172.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/173.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/174.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/175.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/176.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/177.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/178.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/179.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/18.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/180.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/181.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/182.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/183.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/184.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/185.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/186.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/187.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/188.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/189.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/19.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/190.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/191.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/192.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/193.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/194.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/195.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/196.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/197.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/198.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/199.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/2.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/20.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/21.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/22.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/23.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/24.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/25.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/26.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/27.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/28.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/29.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/3.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/30.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/31.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/32.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/33.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/34.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/35.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/36.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/37.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/38.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/39.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/4.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/40.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/41.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/42.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/43.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/44.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/45.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/46.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/47.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/48.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/49.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/5.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/50.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/51.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/52.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/53.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/54.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/55.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/56.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/57.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/58.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/59.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/6.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/60.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/61.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/62.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/63.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/64.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/65.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/66.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/67.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/68.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/69.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/7.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/70.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/71.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/72.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/73.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/74.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/75.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/76.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/77.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/78.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/79.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/8.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/80.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/81.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/82.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/83.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/84.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/85.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/86.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/87.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/88.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/89.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/9.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/90.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/91.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/92.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/93.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/94.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/95.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/96.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/97.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/98.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/99.jpg.out\n"
     ]
    }
   ],
   "source": [
    "# 작업 상태 확인\n",
    "while True:\n",
    "    response = sm_client.describe_transform_job(TransformJobName=job_name)\n",
    "    status = response['TransformJobStatus']\n",
    "    print(f\"Job status: {status}\")\n",
    "    \n",
    "    if status == 'Completed':\n",
    "        print(\"Batch Transform job completed successfully.\")\n",
    "        break\n",
    "    elif status == 'Failed':\n",
    "        print(\"Batch Transform job failed.\")\n",
    "        print(response['FailureReason'])\n",
    "        break\n",
    "    \n",
    "    time.sleep(30)  # 30초마다 상태 확인\n",
    "\n",
    "# 결과 확인 (선택사항)\n",
    "s3_client = boto3.client(\"s3\")\n",
    "response = s3_client.list_objects_v2(Bucket=bucket, Prefix=f\"{prefix}/batchtransform-output\")\n",
    "for obj in response.get('Contents', []):\n",
    "    print(f\"Output file: {obj['Key']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dirname = \"./batchtransform-output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf {output_dirname}\n",
    "!aws s3 sync {output_path} {output_dirname} --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "    filename             label  confidence        x       y    width   height\n",
      "0    132.jpg   a photo of a tv       0.403    42.61  131.83   460.11   395.16\n",
      "1    136.jpg   a photo of a tv       0.623    32.86  223.03   947.48   806.92\n",
      "2    153.jpg   a photo of a tv       0.666   100.78  386.78  1591.80  1296.79\n",
      "3    128.jpg   a photo of a tv       0.511   123.98  363.12  1461.04  1296.61\n",
      "4    128.jpg  a photo of a dog       0.109  1016.63  707.02  1447.28  1185.62\n",
      "..       ...               ...         ...      ...     ...      ...      ...\n",
      "160  196.jpg   a photo of a tv       0.122    19.54  360.72   482.30   629.16\n",
      "161   84.jpg   a photo of a tv       0.258    17.02   10.59  1509.16   895.44\n",
      "162  135.jpg   a photo of a tv       0.220    59.40  277.11  1484.36  1375.83\n",
      "163  172.jpg   a photo of a tv       0.341    23.25  355.15   477.96   628.33\n",
      "164  172.jpg   a photo of a tv       0.373    17.97  358.35   481.88   634.66\n",
      "\n",
      "[165 rows x 7 columns]\n",
      "\n",
      "총 탐지된 객체 수: 165\n",
      "\n",
      "컬럼: ['filename', 'label', 'confidence', 'x', 'y', 'width', 'height']\n",
      "\n",
      "처음 5행 (또는 전체):\n",
      "  filename             label  confidence        x       y    width   height\n",
      "0  132.jpg   a photo of a tv       0.403    42.61  131.83   460.11   395.16\n",
      "1  136.jpg   a photo of a tv       0.623    32.86  223.03   947.48   806.92\n",
      "2  153.jpg   a photo of a tv       0.666   100.78  386.78  1591.80  1296.79\n",
      "3  128.jpg   a photo of a tv       0.511   123.98  363.12  1461.04  1296.61\n",
      "4  128.jpg  a photo of a dog       0.109  1016.63  707.02  1447.28  1185.62\n",
      "\n",
      "기본 통계:\n",
      "       confidence            x            y        width       height\n",
      "count  165.000000   165.000000   165.000000   165.000000   165.000000\n",
      "mean     0.338648   124.315697   246.404121  1252.059879  1002.633333\n",
      "std      0.166206   211.865324   267.941195   597.037530   437.542108\n",
      "min      0.101000   -32.830000   -29.880000   154.340000   222.110000\n",
      "25%      0.191000    18.190000    77.600000   934.670000   683.060000\n",
      "50%      0.341000    48.790000   168.830000  1093.300000   895.440000\n",
      "75%      0.474000   109.030000   344.640000  1536.210000  1296.790000\n",
      "max      0.745000  1097.200000  1529.160000  2556.960000  2488.810000\n",
      "\n",
      "라벨별 개수:\n",
      "a photo of a tv     161\n",
      "a photo of a dog      4\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 데이터 처리 및 DataFrame 생성\n",
    "rows = []\n",
    "\n",
    "for file_path in glob.glob(output_dirname + \"/*\"):\n",
    "    # 파일 읽기\n",
    "    filename = file_path.replace(\".out\", \"\").split(\"/\")[-1]\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # JSON 파싱\n",
    "    data = json.loads(content)\n",
    "\n",
    "    for item in data:\n",
    "        label, confidence, bbox = item\n",
    "        x, y, width, height = bbox\n",
    "        rows.append({\n",
    "            'filename' : filename,\n",
    "            'label': label,\n",
    "            'confidence': confidence,\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# 추가 정보 출력\n",
    "print(f\"\\n총 탐지된 객체 수: {len(df)}\")\n",
    "print(f\"\\n컬럼: {df.columns.tolist()}\")\n",
    "\n",
    "# 처음 5행 보기 (5개 이상의 객체가 탐지된 경우)\n",
    "print(\"\\n처음 5행 (또는 전체):\")\n",
    "print(df.head())\n",
    "\n",
    "# 통계 정보\n",
    "print(\"\\n기본 통계:\")\n",
    "print(df.describe())\n",
    "\n",
    "# 라벨별 개수\n",
    "print(\"\\n라벨별 개수:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 정보:\n",
      "    filename             label  confidence        x       y    width   height\n",
      "0    132.jpg   a photo of a tv       0.403    42.61  131.83   460.11   395.16\n",
      "1    136.jpg   a photo of a tv       0.623    32.86  223.03   947.48   806.92\n",
      "2    153.jpg   a photo of a tv       0.666   100.78  386.78  1591.80  1296.79\n",
      "3    128.jpg   a photo of a tv       0.511   123.98  363.12  1461.04  1296.61\n",
      "4    128.jpg  a photo of a dog       0.109  1016.63  707.02  1447.28  1185.62\n",
      "..       ...               ...         ...      ...     ...      ...      ...\n",
      "160  196.jpg   a photo of a tv       0.122    19.54  360.72   482.30   629.16\n",
      "161   84.jpg   a photo of a tv       0.258    17.02   10.59  1509.16   895.44\n",
      "162  135.jpg   a photo of a tv       0.220    59.40  277.11  1484.36  1375.83\n",
      "163  172.jpg   a photo of a tv       0.341    23.25  355.15   477.96   628.33\n",
      "164  172.jpg   a photo of a tv       0.373    17.97  358.35   481.88   634.66\n",
      "\n",
      "[165 rows x 7 columns]\n",
      "\n",
      "총 탐지된 객체 수: 165\n",
      "고유한 이미지 파일 수: 140\n",
      "\n",
      "컬럼: ['filename', 'label', 'confidence', 'x', 'y', 'width', 'height']\n",
      "\n",
      "처음 5행:\n",
      "  filename             label  confidence        x       y    width   height\n",
      "0  132.jpg   a photo of a tv       0.403    42.61  131.83   460.11   395.16\n",
      "1  136.jpg   a photo of a tv       0.623    32.86  223.03   947.48   806.92\n",
      "2  153.jpg   a photo of a tv       0.666   100.78  386.78  1591.80  1296.79\n",
      "3  128.jpg   a photo of a tv       0.511   123.98  363.12  1461.04  1296.61\n",
      "4  128.jpg  a photo of a dog       0.109  1016.63  707.02  1447.28  1185.62\n",
      "\n",
      "라벨별 개수:\n",
      "a photo of a tv     161\n",
      "a photo of a dog      4\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "이미지별 탐지된 객체 수 (상위 10개):\n",
      "filename\n",
      "128.jpg    3\n",
      "101.jpg    3\n",
      "28.jpg     3\n",
      "5.jpg      2\n",
      "26.jpg     2\n",
      "199.jpg    2\n",
      "44.jpg     2\n",
      "196.jpg    2\n",
      "158.jpg    2\n",
      "12.jpg     2\n",
      "dtype: int64\n",
      "\n",
      "상위 5개 라벨의 평균 신뢰도:\n",
      "label\n",
      "a photo of a tv     0.343609\n",
      "a photo of a dog    0.139000\n",
      "Name: confidence, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 데이터 처리 및 DataFrame 생성\n",
    "rows = []\n",
    "\n",
    "for file_path in glob.glob(output_dirname + \"/*.out\"):\n",
    "    # 파일 읽기\n",
    "    filename = file_path.split(\"/\")[-1].replace(\".out\", \"\")\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # JSON 파싱\n",
    "    try:\n",
    "        data = json.loads(content)\n",
    "        for item in data:\n",
    "            label, confidence, bbox = item\n",
    "            x, y, width, height = bbox\n",
    "            rows.append({\n",
    "                'filename': filename,\n",
    "                'label': label,\n",
    "                'confidence': confidence,\n",
    "                'x': x,\n",
    "                'y': y,\n",
    "                'width': width,\n",
    "                'height': height\n",
    "            })\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error decoding JSON in file: {filename}\")\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"DataFrame 정보:\")\n",
    "print(df)\n",
    "\n",
    "# 추가 정보 출력\n",
    "print(f\"\\n총 탐지된 객체 수: {len(df)}\")\n",
    "print(f\"고유한 이미지 파일 수: {df['filename'].nunique()}\")\n",
    "print(f\"\\n컬럼: {df.columns.tolist()}\")\n",
    "\n",
    "# 처음 5행 보기\n",
    "print(\"\\n처음 5행:\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# 라벨별 개수\n",
    "print(\"\\n라벨별 개수:\")\n",
    "label_counts = df['label'].value_counts()\n",
    "print(label_counts)\n",
    "\n",
    "# 시각화: 라벨별 개수 막대 그래프\n",
    "plt.figure(figsize=(12, 6))\n",
    "label_counts.plot(kind='bar')\n",
    "plt.title('Object Detection Results: Label Counts')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 신뢰도 분포 히스토그램\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['confidence'], bins=20, kde=True)\n",
    "plt.title('Distribution of Confidence Scores')\n",
    "plt.xlabel('Confidence')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# 이미지별 탐지된 객체 수\n",
    "objects_per_image = df.groupby('filename').size().sort_values(ascending=False)\n",
    "print(\"\\n이미지별 탐지된 객체 수 (상위 10개):\")\n",
    "print(objects_per_image.head(10))\n",
    "\n",
    "# 상위 5개 라벨의 평균 신뢰도\n",
    "top_5_labels = label_counts.head().index\n",
    "avg_confidence = df[df['label'].isin(top_5_labels)].groupby('label')['confidence'].mean().sort_values(ascending=False)\n",
    "print(\"\\n상위 5개 라벨의 평균 신뢰도:\")\n",
    "print(avg_confidence)\n",
    "\n",
    "# 시각화: 바운딩 박스 크기 vs 신뢰도 산점도\n",
    "df['bbox_area'] = df['width'] * df['height']\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='bbox_area', y='confidence', data=df, alpha=0.5)\n",
    "plt.title('Bounding Box Area vs Confidence')\n",
    "plt.xlabel('Bounding Box Area')\n",
    "plt.ylabel('Confidence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
