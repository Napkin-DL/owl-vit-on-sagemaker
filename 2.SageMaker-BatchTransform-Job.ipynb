{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SageMaker BatchTransform Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "install_needed = True\n",
    "# install_needed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add data-root and default-shm-size=10G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Redirecting to /bin/systemctl restart docker.service\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docker Restart\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 24.5M  100 24.5M    0     0  93.6M      0 --:--:-- --:--:-- --:--:-- 93.6M\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "\n",
    "DAEMON_PATH=\"/etc/docker\"\n",
    "MEMORY_SIZE=10G\n",
    "\n",
    "FLAG=$(cat $DAEMON_PATH/daemon.json | jq 'has(\"data-root\")')\n",
    "# echo $FLAG\n",
    "\n",
    "if [ \"$FLAG\" == true ]; then\n",
    "    echo \"Already revised\"\n",
    "else\n",
    "    echo \"Add data-root and default-shm-size=$MEMORY_SIZE\"\n",
    "    sudo cp $DAEMON_PATH/daemon.json $DAEMON_PATH/daemon.json.bak\n",
    "    sudo cat $DAEMON_PATH/daemon.json.bak | jq '. += {\"data-root\":\"/home/ec2-user/SageMaker/.container/docker\",\"default-shm-size\":\"'$MEMORY_SIZE'\"}' | sudo tee $DAEMON_PATH/daemon.json > /dev/null\n",
    "    sudo service docker restart\n",
    "    echo \"Docker Restart\"\n",
    "fi\n",
    "\n",
    "sudo curl -L \"https://github.com/docker/compose/releases/download/v2.7.0/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n",
    "sudo chmod +x /usr/local/bin/docker-compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installing deps and restarting kernel\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install --upgrade pip --quiet\n",
    "    !{sys.executable} -m pip install -U sagemaker --quiet\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import huggingface_hub\n",
    "from pathlib import Path\n",
    "from time import strftime\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer\n",
    ")\n",
    "import torch\n",
    "\n",
    "\n",
    "source_dir = f\"{Path.cwd()}/src\"\n",
    "os.makedirs(source_dir, exist_ok=True)\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"240929-deploy-owl-vit\"\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['HF_DATASETS_CACHE'] = '/home/ec2-user/SageMaker/.cache'\n",
    "os.environ['HF_CACHE_HOME'] = '/home/ec2-user/SageMaker/.cache'\n",
    "os.environ['HUGGINGFACE_HUB_CACHE'] = '/home/ec2-user/SageMaker/.cache'\n",
    "# os.environ['TRANSFORMERS_HOME'] = '/home/ec2-user/SageMaker/.cache'\n",
    "# os.environ['HF_HOME'] = '/home/ec2-user/SageMaker/.cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_model_id = 'google/owlvit-base-patch32'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## [**Step 1**] Storing model artifacts and serving/scoring logic\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Downloading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registered_model : owlvit-base-patch32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff7964327f34bf3996f795d58334b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/2024/inference-code/owl-vit-on-sagemaker/owlvit-base-patch32'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registered_model = test_model_id.split(\"/\")[-1].lower().replace(\".\", \"-\")\n",
    "print(f\"registered_model : {registered_model}\")\n",
    "os.makedirs(registered_model, exist_ok=True)\n",
    "\n",
    "huggingface_hub.snapshot_download(\n",
    "    repo_id=test_model_id,\n",
    "    revision=\"main\",\n",
    "    local_dir=registered_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'owlvit-base-patch32'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model_weight = test_model_id.split(\"/\")[-1].lower().replace(\".\", \"-\")\n",
    "local_model_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weight spec (in this case, just an S3 path): s3://sagemaker-us-west-2-322537213286/240929-deploy-owl-vit/owlvit-base-patch32\n"
     ]
    }
   ],
   "source": [
    "s3_model_weight_path = sagemaker_session.upload_data(path=f'./{local_model_weight}', bucket=bucket, key_prefix=f\"{prefix}/{local_model_weight}\")\n",
    "print('Model weight spec (in this case, just an S3 path): {}'.format(s3_model_weight_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://sagemaker-us-west-2-322537213286/240929-deploy-owl-vit/ecommerce-products\n"
     ]
    }
   ],
   "source": [
    "s3_input_data_path = sagemaker_session.upload_data(path=f'./ecommerce-products', bucket=bucket, key_prefix=f\"{prefix}/ecommerce-products\")\n",
    "print('input spec (in this case, just an S3 path): {}'.format(s3_input_data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드 셀은 src 디렉토리에 SageMaker 추론 스크립트를 저장합니다.\n",
    "\n",
    "#### Option 1.\n",
    "- `model_fn(model_dir)`: S3의 `model_dir`에 저장된 모델 아티팩트를 로드합니다.\n",
    "- `input_fn(request_body, content_type)`: 입력 데이터를 전처리합니다. `content_type`은 입력 데이터 종류에 따라 다양하게 처리 가능합니다. (예: `application/x-npy`, `application/json`, `application/csv`등)\n",
    "- `predict_fn(input_object, model)`: `input_fn(...)`을 통해 들어온 데이터에 대해 추론을 수행합니다.\n",
    "- `output_fn(prediction, accept_type)`: `predict_fn(...)`에서 받은 추론 결과를 후처리를 거쳐 프론트엔드로 전송합니다.\n",
    "\n",
    "#### Option 2.\n",
    "- `model_fn(model_dir)`: S3의 model_dir에 저장된 모델 아티팩트를 로드합니다.\n",
    "- `transform_fn(model, request_body, content_type, accept_type)`: `input_fn(...), predict_fn(...), output_fn(...)`을 `transform_fn(...)`으로 통합할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'owlvit-base-patch32'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(f\"{local_model_weight}/code\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting owlvit-base-patch32/code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {local_model_weight}/code/requirements.txt\n",
    "transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting owlvit-base-patch32/code/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {local_model_weight}/code/inference.py\n",
    "import logging\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from typing import Union, Tuple, List, Any\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "try:\n",
    "    threshold = float(os.environ.get(\"threshold\", \"0.1\"))\n",
    "except ValueError:\n",
    "    logging.warning(\"Invalid threshold value in environment variable. Using default value 0.1\")\n",
    "    threshold = 0.1\n",
    "\n",
    "try:\n",
    "    texts = json.loads(os.environ.get(\"texts\", \"[]\"))\n",
    "except json.JSONDecodeError:\n",
    "    logging.error(\"Invalid JSON in texts environment variable\")\n",
    "    texts = []\n",
    "\n",
    "from transformers import OwlViTProcessor, OwlViTForObjectDetection\n",
    "\n",
    "def decode_input(encoded_image: Union[str, bytearray, bytes]) -> Image.Image:\n",
    "    try:\n",
    "        # Try base64 decoding first\n",
    "        image_data = base64.b64decode(encoded_image)\n",
    "        image = Image.open(BytesIO(image_data)).convert(\"RGB\")\n",
    "    except:\n",
    "        # If base64 decoding fails, assume it's already in bytes format\n",
    "        image = Image.open(BytesIO(encoded_image)).convert(\"RGB\")\n",
    "    return image\n",
    "\n",
    "\n",
    "def model_fn(model_dir: str) -> Tuple[OwlViTProcessor, OwlViTForObjectDetection]:\n",
    "    try:\n",
    "        processor = OwlViTProcessor.from_pretrained(model_dir)\n",
    "        model = OwlViTForObjectDetection.from_pretrained(model_dir)\n",
    "        logging.info(\"Model loaded successfully\")\n",
    "        return (processor, model)\n",
    "    except Exception:\n",
    "        logging.exception(f\"Failed to load model from: {model_dir}\")\n",
    "        raise\n",
    "\n",
    "def input_fn(input_data: Union[str, bytearray, bytes], content_type: str) -> Tuple[np.ndarray, Tuple[int, int]]:\n",
    "    if content_type == \"application/x-image\":\n",
    "        try:\n",
    "            image = decode_input(input_data)\n",
    "            image_size = image.size\n",
    "            logging.info(f\"Image size: {image_size}\")\n",
    "            image_array = np.array(image)\n",
    "\n",
    "            if image_array.ndim == 2:\n",
    "                image_array = np.stack((image_array,)*3, axis=-1)\n",
    "            return (image_array, image_size)\n",
    "        except Exception as e:\n",
    "            logging.exception(f\"Error occurred when loading/decoding: {str(e)}\")\n",
    "            raise\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported content type: {content_type}\")\n",
    "\n",
    "def predict_fn(input_data: Tuple[np.ndarray, Tuple[int, int]], model_dict: Tuple[OwlViTProcessor, OwlViTForObjectDetection]) -> List[Tuple[str, float, List[float]]]:\n",
    "    processor, model = model_dict\n",
    "    image_array, image_size = input_data\n",
    "    \n",
    "    logging.info(f\"Processing image of size: {image_size}\")\n",
    "    logging.info(f\"texts: {texts}\")\n",
    "    \n",
    "    inputs = processor(text=texts, images=image_array, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    target_sizes = torch.Tensor([image_size[::-1]])\n",
    "    \n",
    "    results = processor.post_process_object_detection(outputs=outputs, target_sizes=target_sizes, threshold=threshold)[0]\n",
    "    \n",
    "    boxes, scores, labels = results[\"boxes\"], results[\"scores\"], results[\"labels\"]\n",
    "    detections = [\n",
    "        (texts[0][label], round(score.item(), 3), [round(i, 2) for i in box.tolist()])\n",
    "        for box, score, label in zip(boxes, scores, labels)\n",
    "    ]\n",
    "    logging.info(f\"detections: {detections}\")\n",
    "    for detection in detections:\n",
    "        logging.info(f\"Detected {detection[0]} with confidence {detection[1]} at location {detection[2]}\")\n",
    "    \n",
    "    return detections\n",
    "\n",
    "def output_fn(prediction: List[Tuple[str, float, List[float]]], accept: str) -> Tuple[str, str]:\n",
    "    if accept == \"application/json\":\n",
    "        return json.dumps(prediction), accept\n",
    "    raise ValueError(f\"Unsupported accept type: {accept}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## [**Step 3**] Validating the container for hosting your model on SageMaker\n",
    "---\n",
    "\n",
    "SageMaker 호스팅 엔드포인트로 배포하기 전에 로컬 모드 엔드포인트로 배포할 수 있습니다. 로컬 모드는 현재 개발 중인 환경에서 도커 컨테이너를 실행하여 SageMaker 프로세싱/훈련/추론 작업을 에뮬레이트할 수 있습니다. 추론 작업의 경우는 Amazon ECR의 딥러닝 프레임워크 기반 추론 컨테이너를 로컬로 가져오고(docker pull) 컨테이너를 실행하여(docker run) 모델 서버를 시작합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!sudo rm -rf {local_model_weight}/.ipynb_checkpoints/\n",
    "!sudo rm -rf {local_model_weight}/__pycache__/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('shell', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting shell/model_compression_upload.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile shell/model_compression_upload.sh\n",
    "\n",
    "cd owlvit-base-patch32\n",
    "tar cvf - * | pigz > model.tar.gz\n",
    "\n",
    "mv model.tar.gz ../model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code/\n",
      "code/inference.py\n",
      "code/requirements.txt\n",
      "config.json\n",
      "merges.txt\n",
      "model.safetensors\n",
      "preprocessor_config.json\n",
      "pytorch_model.bin\n",
      "README.md\n",
      "special_tokens_map.json\n",
      "tokenizer_config.json\n",
      "vocab.json\n",
      "CPU times: user 96.1 ms, sys: 46 ms, total: 142 ms\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!sh ./shell/model_compression_upload.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-322537213286/240929-deploy-owl-vit/compressed_model\n",
      "upload: ./model.tar.gz to s3://sagemaker-us-west-2-322537213286/240929-deploy-owl-vit/compressed_model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_data_url = f's3://{bucket}/{prefix}/compressed_model'\n",
    "print(model_data_url)\n",
    "\n",
    "!aws s3 cp ./model.tar.gz {model_data_url}/model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SageMaker Endpoint (Local Mode)\n",
    "\n",
    "로컬 모드는 필수로 수행할 필요는 없지만, 디버깅에 많은 도움이 됩니다. 또한, 로컬 모드 사용 시에는 모델을 S3에 반드시 업로드할 필요 없이 로컬 디렉터리에서도 로드할 수 있습니다. (`container` 변수 참조)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_uri: 763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-inference:2.3-cpu-py311 \n",
      "docker_account_id : 763104351884\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework='pytorch',\n",
    "    region=region,\n",
    "    image_scope='inference',\n",
    "    version='2.3',\n",
    "    instance_type='ml.m5.2xlarge'\n",
    ")\n",
    "docker_account_id = image_uri.split('.')[0]\n",
    "print(f'image_uri: {image_uri} \\ndocker_account_id : {docker_account_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///home/ec2-user/SageMaker/2024/inference-code/owl-vit-on-sagemaker/owlvit-base-patch32'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "# Set to True to enable SageMaker to run locally\n",
    "local_mode = True\n",
    "# local_mode = False\n",
    "if local_mode:\n",
    "    from sagemaker.local import LocalSession\n",
    "    instance_type = \"local_gpu\"\n",
    "    sm_session = LocalSession()\n",
    "    sm_session.config = {'local': {'local_code': True}}\n",
    "    sm_client = sagemaker.local.LocalSagemakerClient()\n",
    "    smr_client = sagemaker.local.LocalSagemakerRuntimeClient()\n",
    "    model_data=f\"file://{Path.cwd()}/{local_model_weight}\"\n",
    "    input_image_path = f\"file://{Path.cwd()}/ecommerce-products/tv\"\n",
    "    output_path = f\"file://{Path.cwd()}/batchtransform-output\"\n",
    "else:\n",
    "    instance_type = \"ml.m5.2xlarge\"\n",
    "    sm_session = sagemaker.Session()\n",
    "    sm_client = boto3.client(\"sagemaker\")\n",
    "    smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "    model_data = f\"{model_data_url}/model.tar.gz\"\n",
    "    input_image_path = f\"{s3_input_data_path}/tv\"\n",
    "    output_path = f\"s3://{bucket}/{prefix}/batchtransform-output\"\n",
    "\n",
    "instance_count = 1\n",
    "ts = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "sm_model_name = f\"{local_model_weight}-model-{ts}\"\n",
    "endpoint_config_name = f\"{local_model_weight}-endpoint-config-{ts}\"\n",
    "job_name = f\"{local_model_weight}-batchtranform-{ts}\"\n",
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "container = {\n",
    "    \"Image\": image_uri,\n",
    "    \"ModelDataUrl\": model_data,\n",
    "    \"Environment\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local Mode only supports 1 ConcurrentTransform. Setting MaxConcurrentTransforms to 1\n",
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/local/image.py\", line 955, in run\n",
      "    _stream_output(self.process)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/local/image.py\", line 1021, in _stream_output\n",
      "    raise RuntimeError(f\"Failed to run: {process.args}. Process exited with code: {exit_code}\")\n",
      "RuntimeError: Failed to run: ['docker-compose', '-f', '/tmp/tmp287w9lg1/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit']. Process exited with code: 1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/local/image.py\", line 960, in run\n",
      "    raise RuntimeError(msg)\n",
      "RuntimeError: Failed to run: ['docker-compose', '-f', '/tmp/tmp287w9lg1/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Failed to run: ['docker-compose', '-f', '/tmp/tmp287w9lg1/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit']. Process exited with code: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:58,677 [INFO ] pool-2-thread-10 ACCESS_LOG - /172.18.0.1:44538 \"GET /ping HTTP/1.1\" 200 1\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:58,677 [INFO ] pool-2-thread-10 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777518\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:58,703 [INFO ] epollEventLoopGroup-3-5 ACCESS_LOG - /172.18.0.1:44540 \"GET /execution-parameters HTTP/1.1\" 404 0\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:58,704 [INFO ] epollEventLoopGroup-3-5 TS_METRICS - Requests4XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777518\n",
      "Attaching to sj5rc0ejrd-algo-1-qqy9m\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:58,732 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777518\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:58,733 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777518733\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:58,734 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777518\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:58,744 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (1500, 1500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:58,747 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 1500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:58,747 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:59,479 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.19, [41.41, 327.4, 1455.96, 1220.82])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:59,479 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.19 at location [41.41, 327.4, 1455.96, 1220.82]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:59,480 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:746.29|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777519,28204ee2-9d46-42d2-bdca-0e0f31d2bc55, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:59,481 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:746.29|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:28204ee2-9d46-42d2-bdca-0e0f31d2bc55,timestamp:1727777519\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:59,481 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 749\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:59,481 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777519\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:59,481 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:747864.487|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777519\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:59,481 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:60.741|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777519\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:59,481 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777519\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:59,481 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 748\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:59,481 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777519\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:59,498 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777519\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:59,499 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777519499\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:59,500 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777519\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:59,505 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:59,506 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:11:59,506 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:00,233 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.562, [101.67, 12.02, 947.19, 809.19])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:00,233 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.562 at location [101.67, 12.02, 947.19, 809.19]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:00,234 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:734.66|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777520,d697829b-a755-459a-8f1a-b7c14870ae8e, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:00,234 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:734.66|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:d697829b-a755-459a-8f1a-b7c14870ae8e,timestamp:1727777520\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:00,235 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 737\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:00,235 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777520\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:00,235 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:736025.27|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777520\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:00,235 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:83.272|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777520\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:00,235 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777520\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:00,235 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 736\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:00,235 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777520\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:00,253 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777520\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:00,253 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777520253\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:00,254 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777520\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:00,261 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:00,263 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:00,263 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:00,994 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.505, [22.25, 354.42, 479.1, 631.62])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:00,994 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.505 at location [22.25, 354.42, 479.1, 631.62]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,001 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:747.19|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777521,0dba2a6e-efba-43df-95aa-10e633c73f90, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,001 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:747.19|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:0dba2a6e-efba-43df-95aa-10e633c73f90,timestamp:1727777521\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,002 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 748\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,002 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777521\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,002 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:748522.71|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777521\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,002 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:101.262|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777521\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,002 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777521\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,002 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 748\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,002 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777521\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,021 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777521\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,022 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777521022\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,023 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777521\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,057 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (2000, 1945)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,062 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (2000, 1945)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,062 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,784 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.474, [93.96, 330.91, 1919.39, 1457.04])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,784 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.474 at location [93.96, 330.91, 1919.39, 1457.04]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,788 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:765.56|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777521,514105e8-6aa8-49d4-ae4c-5cd9f03eabaf, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,789 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:765.56|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:514105e8-6aa8-49d4-ae4c-5cd9f03eabaf,timestamp:1727777521\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,789 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 768\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,789 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777521\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,789 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:767215.269|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777521\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,789 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:110.082|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777521\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,789 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777521\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,789 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 767\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,789 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777521\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,808 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777521\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,808 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777521808\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,809 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777521\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,822 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,826 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:01,826 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:02,532 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:02,533 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:724.21|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777522,ab178b82-12c8-4d7a-a12e-8795c6b2f96f, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:02,533 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:724.21|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:ab178b82-12c8-4d7a-a12e-8795c6b2f96f,timestamp:1727777522\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:02,533 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 726\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:02,533 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777522\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:02,533 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:725497.737|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777522\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:02,534 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:82.001|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777522\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:02,534 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777522\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:02,534 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 725\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:02,534 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777522\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:02,551 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777522\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:02,552 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777522552\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:02,552 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777522\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:02,557 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:02,559 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:02,559 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:03,242 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.397, [29.09, 29.97, 964.09, 480.84]), ('a photo of a tv', 0.13, [47.68, 503.28, 417.03, 779.15])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:03,242 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.397 at location [29.09, 29.97, 964.09, 480.84]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:03,242 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.13 at location [47.68, 503.28, 417.03, 779.15]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:03,247 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:694.45|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777523,3254d144-a87a-4236-a4fd-cdd50ac3739b, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:03,247 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:694.45|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:3254d144-a87a-4236-a4fd-cdd50ac3739b,timestamp:1727777523\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:03,247 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 696\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:03,247 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777523\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:03,247 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:695702.155|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777523\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:03,247 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:82.932|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777523\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:03,247 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777523\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:03,247 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 695\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:03,248 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777523\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:03,266 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777523\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:03,266 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777523266\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:03,267 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777523\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:03,276 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:03,280 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:03,280 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,023 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.378, [85.53, 413.01, 1517.02, 1372.75])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,023 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.378 at location [85.53, 413.01, 1517.02, 1372.75]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,024 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:757.24|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777524,9ad6368b-02b5-42ec-8942-d20cbc197c5a, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,025 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:757.24|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:9ad6368b-02b5-42ec-8942-d20cbc197c5a,timestamp:1727777524\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,025 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 759\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,025 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777524\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,025 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:758686.126|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777524\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,026 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:88.422|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777524\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,026 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777524\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,026 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 759\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,026 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777524\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,043 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777524\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,043 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777524043\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,044 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777524\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,049 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1024, 1024)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,051 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1024, 1024)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,051 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,749 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.401, [110.43, 101.04, 886.38, 946.76])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,749 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.401 at location [110.43, 101.04, 886.38, 946.76]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,751 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:706.19|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777524,7585ce5a-4d1b-41f0-92be-1000b57cb1cd, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,751 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:706.19|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:7585ce5a-4d1b-41f0-92be-1000b57cb1cd,timestamp:1727777524\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,751 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 708\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,751 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777524\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,751 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:707570.663|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777524\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,751 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:87.322|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777524\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,751 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777524\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,751 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 707\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,751 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777524\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,770 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777524\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,770 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777524770\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,771 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777524\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,815 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (2560, 2560)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,823 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 2560)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:04,823 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:05,567 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.412, [89.11, 579.47, 2484.97, 2042.52])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:05,567 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.412 at location [89.11, 579.47, 2484.97, 2042.52]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:05,568 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:797.02|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777525,b358fb79-c3a1-4d70-b2ab-b5c76852b4aa, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:05,568 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:797.02|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:b358fb79-c3a1-4d70-b2ab-b5c76852b4aa,timestamp:1727777525\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:05,568 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 799\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:05,568 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777525\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:05,568 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:798507.421|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777525\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:05,568 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:91.062|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777525\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:05,568 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777525\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:05,569 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 798\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:05,569 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777525\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:05,585 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777525\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:05,585 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777525585\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:05,586 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777525\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:05,599 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1500, 951)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:05,601 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 951)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:05,601 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:06,286 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.258, [17.02, 10.59, 1509.16, 895.44])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:06,286 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.258 at location [17.02, 10.59, 1509.16, 895.44]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:06,288 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:701.11|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777526,1d3a8185-0fab-4263-8455-87c23a2ade86, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:06,288 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:701.11|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:1d3a8185-0fab-4263-8455-87c23a2ade86,timestamp:1727777526\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:06,288 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 703\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:06,288 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777526\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:06,288 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:702410.194|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777526\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:06,288 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:86.412|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777526\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:06,288 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777526\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:06,288 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 703\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:06,288 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777526\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:06,304 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777526\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:06,305 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777526305\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:06,305 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777526\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:06,307 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (500, 375)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:06,308 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 375)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:06,308 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:06,999 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.512, [55.18, 65.91, 451.87, 298.88])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:06,999 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.512 at location [55.18, 65.91, 451.87, 298.88]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,004 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:698.14|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777527,67805de9-ae32-4b16-80b6-24175ef02c45, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,004 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:698.14|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:67805de9-ae32-4b16-80b6-24175ef02c45,timestamp:1727777527\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,004 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 700\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,004 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777527\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,004 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:699357.265|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777527\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,004 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:86.842|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777527\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,004 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777527\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,004 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 699\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,004 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777527\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,021 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777527\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,021 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777527021\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,022 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777527\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,029 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (1000, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,031 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,031 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,711 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,712 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:690.05|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777527,659229d1-4cd5-458d-8f63-92a8d02ba317, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,712 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:690.05|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:659229d1-4cd5-458d-8f63-92a8d02ba317,timestamp:1727777527\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,712 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 691\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,712 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777527\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,712 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:691332.329|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777527\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,713 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:109.802|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777527\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,713 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777527\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,713 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 691\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,713 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777527\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,731 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777527\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,731 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777527731\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,732 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777527\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,768 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (2560, 1938)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,774 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1938)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:07,774 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:08,481 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.355, [478.67, 298.01, 2063.03, 1225.09])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:08,481 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.355 at location [478.67, 298.01, 2063.03, 1225.09]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:08,482 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:750.2|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777528,ba0e083a-d2ee-45e5-a06e-08adb6b87dfc, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:08,482 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 752\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:08,482 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777528\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:08,482 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:750.2|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:ba0e083a-d2ee-45e5-a06e-08adb6b87dfc,timestamp:1727777528\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:08,482 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:751524.246|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777528\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:08,483 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:85.852|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777528\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:08,483 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777528\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:08,483 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 751\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:08,483 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777528\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:08,500 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777528\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:08,500 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777528500\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:08,501 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777528\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:08,505 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:08,507 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:08,507 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,191 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.362, [5.55, 164.72, 994.73, 764.57])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,192 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.362 at location [5.55, 164.72, 994.73, 764.57]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,196 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:694.91|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777529,b6a93032-31fa-44f1-aa73-71af6d5a8933, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,196 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:694.91|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:b6a93032-31fa-44f1-aa73-71af6d5a8933,timestamp:1727777529\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,196 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 697\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,196 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777529\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,196 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:696301.844|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777529\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,196 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:89.051|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777529\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,197 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777529\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,197 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 696\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,197 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777529\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,214 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777529\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,215 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777529215\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,216 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777529\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,221 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,223 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,223 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,922 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.503, [64.08, 120.06, 960.79, 882.46])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,922 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.503 at location [64.08, 120.06, 960.79, 882.46]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,927 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:710.95|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777529,c7597f15-e299-428b-8177-1f80365e58e6, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,927 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:710.95|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:c7597f15-e299-428b-8177-1f80365e58e6,timestamp:1727777529\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,927 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 713\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,927 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777529\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,927 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:712303.693|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777529\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,927 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:87.662|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777529\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,927 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777529\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,927 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 712\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,927 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777529\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,945 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777529\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,946 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777529946\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,947 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777529\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,962 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1200, 1200)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,964 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1200, 1200)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:09,964 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:10,651 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.354, [123.21, 113.43, 1095.53, 660.21])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:10,651 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.354 at location [123.21, 113.43, 1095.53, 660.21]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:10,652 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:705.8|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777530,61bb2229-7c8e-4de7-92ee-4bf4036fcc32, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:10,653 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 708\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:10,653 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:705.8|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:61bb2229-7c8e-4de7-92ee-4bf4036fcc32,timestamp:1727777530\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:10,653 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777530\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:10,653 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:707050.281|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777530\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:10,653 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:78.441|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777530\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:10,653 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777530\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:10,653 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 707\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:10,653 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777530\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:10,674 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777530\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:10,674 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777530674\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:10,675 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777530\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:10,703 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (2457, 2560)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:10,712 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (2457, 2560)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:10,712 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:11,452 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.113, [90.3, 132.16, 2358.85, 1487.3]), ('a photo of a tv', 0.156, [45.18, 50.79, 2403.72, 2488.81]), ('a photo of a tv', 0.208, [1050.73, 1529.16, 1424.31, 2267.75])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:11,452 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.113 at location [90.3, 132.16, 2358.85, 1487.3]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:11,452 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.156 at location [45.18, 50.79, 2403.72, 2488.81]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:11,452 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.208 at location [1050.73, 1529.16, 1424.31, 2267.75]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:11,456 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:781.44|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777531,98c32c34-45f9-4435-8ea0-93b61570e4bb, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:11,457 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:781.44|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:98c32c34-45f9-4435-8ea0-93b61570e4bb,timestamp:1727777531\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:11,457 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 784\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:11,457 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777531\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:11,457 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:782960.48|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777531\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:11,457 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:72.881|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777531\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:11,457 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777531\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:11,457 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 783\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:11,457 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777531\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:11,477 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777531\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:11,477 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777531477\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:11,478 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777531\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:11,514 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (2560, 1707)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:11,520 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1707)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:11,520 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:12,243 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.268, [93.82, 118.82, 2446.0, 1498.6])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:12,243 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.268 at location [93.82, 118.82, 2446.0, 1498.6]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:12,244 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:765.84|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777532,c7e03af2-9838-4fcd-b59e-165149a776d3, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:12,244 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:765.84|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:c7e03af2-9838-4fcd-b59e-165149a776d3,timestamp:1727777532\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:12,244 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 768\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:12,244 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777532\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:12,245 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:767369.84|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777532\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:12,245 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:118.102|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777532\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:12,245 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777532\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:12,245 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 767\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:12,245 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777532\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:12,263 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777532\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:12,263 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777532263\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:12,264 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777532\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:12,274 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (1080, 1080)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:12,276 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (1080, 1080)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:12,276 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,007 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,012 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:747.72|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777533,7ab58258-257c-4fe6-811d-0aa948ecf84d, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,012 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:747.72|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:7ab58258-257c-4fe6-811d-0aa948ecf84d,timestamp:1727777533\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,012 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 749\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,012 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777533\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,012 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:749006.197|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777533\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,013 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:88.201|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777533\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,013 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777533\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,013 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 749\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,013 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777533\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,031 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777533\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,032 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777533032\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,032 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777533\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,052 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,056 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,056 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,760 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.324, [13.32, 331.42, 1571.82, 1349.36])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,760 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.324 at location [13.32, 331.42, 1571.82, 1349.36]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,765 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:732.11|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777533,91d4750c-049f-4eca-9efe-a80adb8d987a, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,765 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:732.11|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:91d4750c-049f-4eca-9efe-a80adb8d987a,timestamp:1727777533\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,765 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 734\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,765 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777533\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,765 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:733530.18|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777533\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,765 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:83.931|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777533\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,765 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777533\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,765 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 733\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,765 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777533\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,784 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777533\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,784 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777533784\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,785 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777533\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,795 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (1500, 951)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,796 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 951)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:13,796 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:14,475 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.258, [17.02, 10.59, 1509.16, 895.44])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:14,475 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.258 at location [17.02, 10.59, 1509.16, 895.44]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:14,476 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:691.49|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777534,06dfd675-bab9-4ce7-99be-1fe38f2c70bd, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:14,476 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:691.49|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:06dfd675-bab9-4ce7-99be-1fe38f2c70bd,timestamp:1727777534\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:14,477 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 694\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:14,477 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777534\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:14,477 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:692842.497|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777534\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:14,477 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:82.181|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777534\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:14,477 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777534\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:14,477 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 692\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:14,477 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777534\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:14,495 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777534\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:14,495 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777534495\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:14,496 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777534\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:14,501 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:14,503 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:14,503 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,229 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.504, [109.36, 235.46, 969.62, 794.25])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,229 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.504 at location [109.36, 235.46, 969.62, 794.25]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,231 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:734.31|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777535,ce9cf1d4-2a43-421c-aeec-be4321437f0e, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,231 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:734.31|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:ce9cf1d4-2a43-421c-aeec-be4321437f0e,timestamp:1727777535\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,231 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 736\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,231 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777535\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,231 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:735855.955|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777535\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,231 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:205.014|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777535\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,231 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777535\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,231 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 736\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,231 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777535\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,248 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777535\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,248 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777535248\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,249 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777535\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,254 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1072, 596)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,255 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1072, 596)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,255 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,949 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,951 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:701.46|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777535,96e8095f-a9e7-49a7-9d52-7fac95e230d6, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,951 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:701.46|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:96e8095f-a9e7-49a7-9d52-7fac95e230d6,timestamp:1727777535\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,951 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 703\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,951 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777535\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,951 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:702765.548|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777535\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,951 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:99.752|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777535\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,951 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777535\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,951 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 703\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,951 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777535\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,969 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777535\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,969 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777535969\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,970 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777535\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,974 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,975 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:15,975 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:16,677 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.458, [48.11, 141.39, 957.78, 831.55])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:16,678 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.458 at location [48.11, 141.39, 957.78, 831.55]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:16,679 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:709.09|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777536,f2e95adc-97fb-4d58-8482-b1dc11887522, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:16,679 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:709.09|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:f2e95adc-97fb-4d58-8482-b1dc11887522,timestamp:1727777536\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:16,679 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 710\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:16,679 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777536\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:16,679 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:710307.344|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777536\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:16,679 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:85.072|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777536\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:16,680 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777536\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:16,680 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 710\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:16,680 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777536\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:16,698 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777536\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:16,698 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777536698\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:16,699 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777536\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:16,704 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:16,705 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:16,705 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:17,383 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.517, [25.44, 200.68, 976.99, 813.84])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:17,383 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.517 at location [25.44, 200.68, 976.99, 813.84]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:17,384 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:685.68|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777537,9eedee69-e3e0-493d-b955-41e318b1fad6, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:17,385 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:685.68|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:9eedee69-e3e0-493d-b955-41e318b1fad6,timestamp:1727777537\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:17,385 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 688\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:17,385 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777537\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:17,385 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:687045.917|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777537\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:17,385 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:98.662|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777537\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:17,385 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777537\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:17,385 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 687\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:17,385 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777537\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:17,402 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777537\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:17,403 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777537403\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:17,403 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777537\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:17,410 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:17,411 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:17,411 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,167 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.404, [70.43, 121.1, 917.44, 872.43])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,167 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.404 at location [70.43, 121.1, 917.44, 872.43]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,169 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:765.24|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777538,99b182bc-78fc-4d99-aba4-246c6d865297, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,169 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:765.24|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:99b182bc-78fc-4d99-aba4-246c6d865297,timestamp:1727777538\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,169 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 767\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,169 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777538\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,169 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:766602.286|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777538\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,169 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:86.341|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777538\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,169 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777538\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,170 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 766\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,170 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777538\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,187 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777538\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,188 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777538188\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,189 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777538\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,199 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (1615, 1637)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,203 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (1615, 1637)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,203 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,919 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,921 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:731.95|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777538,9a89f6d8-1777-4976-bb28-e1159c531c60, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,921 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:731.95|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:9a89f6d8-1777-4976-bb28-e1159c531c60,timestamp:1727777538\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,921 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 734\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,921 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777538\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,921 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:733362.276|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777538\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,921 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:113.232|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777538\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,921 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777538\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,921 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 733\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,921 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777538\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,939 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777538\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,940 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777538940\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,941 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777538\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,958 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (2560, 1707)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,963 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1707)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:18,964 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:19,708 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.18, [107.36, 124.48, 2475.23, 1506.52])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:19,710 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.18 at location [107.36, 124.48, 2475.23, 1506.52]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:19,710 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:768.92|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777539,f6473f38-bf1e-41b8-8ef1-4e7e6100a547, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:19,710 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:768.92|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:f6473f38-bf1e-41b8-8ef1-4e7e6100a547,timestamp:1727777539\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:19,710 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 771\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:19,710 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777539\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:19,710 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:770298.276|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777539\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:19,710 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:71.341|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777539\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:19,710 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777539\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:19,710 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 770\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:19,710 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777539\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:19,727 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777539\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:19,727 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777539727\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:19,728 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777539\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:19,736 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (1500, 1500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:19,739 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 1500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:19,739 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:20,428 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:20,430 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:701.43|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777540,c5236ca0-9380-4452-8a9a-e0dfc1df12a7, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:20,430 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:701.43|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:c5236ca0-9380-4452-8a9a-e0dfc1df12a7,timestamp:1727777540\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:20,430 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 703\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:20,430 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777540\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:20,430 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:702715.578|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777540\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:20,430 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:84.722|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777540\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:20,430 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777540\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:20,430 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 703\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:20,430 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777540\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:20,447 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777540\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:20,447 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777540447\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:20,448 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777540\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:20,465 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1602, 1602)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:20,468 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1602, 1602)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:20,468 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,158 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.36, [69.08, 396.98, 1527.08, 1245.99])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,158 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.36 at location [69.08, 396.98, 1527.08, 1245.99]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,159 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:711.13|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777541,a4915304-23fa-46b1-93db-a47bffb88f26, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,159 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:711.13|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:a4915304-23fa-46b1-93db-a47bffb88f26,timestamp:1727777541\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,159 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 712\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,160 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777541\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,160 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:712381.383|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777541\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,160 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:87.602|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777541\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,160 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777541\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,160 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 712\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,160 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777541\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,177 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777541\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,177 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777541177\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,178 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777541\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,184 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,186 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,186 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,910 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,911 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:732.56|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777541,55738d1a-0ea7-48f2-8ed6-04da06a58000, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,911 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:732.56|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:55738d1a-0ea7-48f2-8ed6-04da06a58000,timestamp:1727777541\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,911 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 734\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,911 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777541\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,911 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:733838.366|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777541\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,911 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:93.662|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777541\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,911 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777541\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,911 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 734\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,911 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777541\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,929 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777541\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,929 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777541929\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,930 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777541\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,945 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,948 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:21,948 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:22,644 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:22,646 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:715.37|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777542,5e234ff1-7273-4528-994c-7e93a2f9d625, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:22,646 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:715.37|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:5e234ff1-7273-4528-994c-7e93a2f9d625,timestamp:1727777542\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:22,646 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 717\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:22,646 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777542\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:22,646 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:716619.415|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777542\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:22,646 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:70.481|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777542\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:22,646 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777542\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:22,648 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 717\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:22,649 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777542\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:22,670 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777542\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:22,670 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777542670\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:22,671 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777542\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:22,682 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:22,686 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:22,686 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:23,424 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.309, [35.42, 379.89, 1594.17, 1335.12])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:23,424 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.309 at location [35.42, 379.89, 1594.17, 1335.12]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:23,425 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:753.95|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777543,51164e4b-9a0d-4e7d-b98b-9579560f8656, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:23,425 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:753.95|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:51164e4b-9a0d-4e7d-b98b-9579560f8656,timestamp:1727777543\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:23,425 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 755\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:23,425 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777543\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:23,426 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:755314.039|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777543\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:23,426 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:87.712|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777543\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:23,426 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777543\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:23,426 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 755\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:23,426 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777543\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:23,443 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777543\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:23,443 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777543443\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:23,444 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777543\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:23,447 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (400, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:23,447 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (400, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:23,447 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,121 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,122 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:677.74|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777544,7b24d943-e6c9-4228-b9b4-92bb0be74317, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,122 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:677.74|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:7b24d943-e6c9-4228-b9b4-92bb0be74317,timestamp:1727777544\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,122 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 679\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,122 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777544\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,123 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:679083.504|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777544\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,123 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:87.321|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777544\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,123 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777544\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,123 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 679\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,123 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777544\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,139 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777544\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,139 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777544139\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,140 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777544\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,142 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (500, 498)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,143 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 498)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,143 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,834 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.556, [94.76, 151.3, 404.75, 346.96])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,834 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.556 at location [94.76, 151.3, 404.75, 346.96]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,835 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:695.17|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777544,1fc94ea1-0176-4dfd-8ea4-8178b5fd1cc3, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,835 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:695.17|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:1fc94ea1-0176-4dfd-8ea4-8178b5fd1cc3,timestamp:1727777544\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,835 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 696\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,835 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777544\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,835 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:696382.607|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777544\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,836 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:101.432|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777544\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,836 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777544\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,836 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 696\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,836 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777544\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,853 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777544\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,854 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777544854\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,855 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777544\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,877 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,881 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:24,881 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:25,592 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.409, [127.87, 408.65, 1480.81, 1241.77])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:25,592 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.409 at location [127.87, 408.65, 1480.81, 1241.77]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:25,593 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:738.4|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777545,48e5d9f0-fccb-4d8b-bbdf-5e636e408cac, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:25,593 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:738.4|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:48e5d9f0-fccb-4d8b-bbdf-5e636e408cac,timestamp:1727777545\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:25,593 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 740\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:25,593 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777545\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:25,593 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:739695.03|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777545\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:25,593 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:82.192|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777545\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:25,594 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777545\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:25,594 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 739\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:25,594 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777545\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:25,611 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777545\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:25,611 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777545611\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:25,612 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777545\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:25,633 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:25,636 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:25,636 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:26,348 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:26,350 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:737.83|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777546,98afade4-f97f-454d-a6bf-b7dcd93a96dd, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:26,350 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:737.83|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:98afade4-f97f-454d-a6bf-b7dcd93a96dd,timestamp:1727777546\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:26,350 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 739\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:26,350 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777546\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:26,350 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:739239.97|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777546\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:26,350 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:87.471|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777546\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:26,350 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777546\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:26,350 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 739\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:26,350 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777546\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:26,368 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777546\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:26,368 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777546368\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:26,369 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777546\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:26,385 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (2560, 1707)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:26,391 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1707)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:26,391 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,105 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.391, [93.69, 120.1, 2473.29, 1486.83])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,106 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.391 at location [93.69, 120.1, 2473.29, 1486.83]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,113 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:744.35|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777547,58d84bdb-a082-4fd7-9768-485fe7946df1, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,114 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:744.35|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:58d84bdb-a082-4fd7-9768-485fe7946df1,timestamp:1727777547\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,114 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 747\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,114 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777547\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,114 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:745671.324|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777547\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,114 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:105.812|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777547\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,114 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777547\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,114 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 746\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,114 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777547\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,132 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777547\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,132 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777547132\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,133 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777547\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,150 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,153 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,154 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,859 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.511, [123.98, 363.12, 1461.04, 1296.61]), ('a photo of a dog', 0.109, [1016.64, 707.02, 1447.28, 1185.62]), ('a photo of a dog', 0.131, [180.96, 801.68, 410.57, 1177.71])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,859 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.511 at location [123.98, 363.12, 1461.04, 1296.61]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,859 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a dog with confidence 0.109 at location [1016.64, 707.02, 1447.28, 1185.62]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,859 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a dog with confidence 0.131 at location [180.96, 801.68, 410.57, 1177.71]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,860 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:726.72|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777547,016b1910-aa9d-48b6-868e-ea41f6a6c3cb, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,860 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:726.72|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:016b1910-aa9d-48b6-868e-ea41f6a6c3cb,timestamp:1727777547\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,861 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 729\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,861 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777547\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,861 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:728429.433|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777547\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,861 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:90.212|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777547\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,861 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777547\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,861 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 729\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,861 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777547\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,880 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777547\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,880 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777547880\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,881 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777547\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,896 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,899 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:27,899 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:28,588 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:28,589 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:708.2|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777548,69335977-38f2-4789-b5c2-82a985ce88be, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:28,589 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:708.2|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:69335977-38f2-4789-b5c2-82a985ce88be,timestamp:1727777548\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:28,590 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 710\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:28,590 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777548\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:28,590 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:709673.163|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777548\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:28,590 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:74.462|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777548\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:28,590 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777548\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:28,590 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 710\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:28,590 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777548\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:28,607 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777548\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:28,607 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777548607\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:28,608 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777548\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:28,613 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:28,614 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:28,614 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:29,319 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.142, [36.82, 233.44, 982.13, 826.39])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:29,319 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.142 at location [36.82, 233.44, 982.13, 826.39]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:29,320 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:711.63|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777549,2f3891e5-7bac-4473-b367-8d8f7491b133, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:29,320 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:711.63|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:2f3891e5-7bac-4473-b367-8d8f7491b133,timestamp:1727777549\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:29,320 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 713\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:29,320 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777549\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:29,321 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:713039.678|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777549\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:29,321 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:87.582|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777549\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:29,321 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777549\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:29,321 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 713\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:29,321 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777549\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:29,338 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777549\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:29,338 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777549338\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:29,339 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777549\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:29,351 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:29,353 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:29,353 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,079 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,080 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:741.17|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777550,28833463-c514-46aa-8bfd-5305b92c411c, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,080 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:741.17|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:28833463-c514-46aa-8bfd-5305b92c411c,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,080 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 743\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,080 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,081 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:742444.663|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,081 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:87.902|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,081 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,081 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 742\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,081 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,098 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,099 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777550099\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,099 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,101 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (500, 375)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,101 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 375)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,101 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,256 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,257 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:2157.0380096435547|#Level:Host|#hostname:295673d1428f,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,257 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:3950.728115081787|#Level:Host|#hostname:295673d1428f,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,257 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:64.7|#Level:Host|#hostname:295673d1428f,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,257 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12966.546875|#Level:Host|#hostname:295673d1428f,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,257 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:18254.03125|#Level:Host|#hostname:295673d1428f,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,257 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:59.1|#Level:Host|#hostname:295673d1428f,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,795 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.643, [27.57, 45.05, 471.74, 326.46])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,795 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.643 at location [27.57, 45.05, 471.74, 326.46]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,796 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:696.62|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777550,12c3eb71-af26-4771-a79a-b29e617d5e06, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,796 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:696.62|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:12c3eb71-af26-4771-a79a-b29e617d5e06,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,796 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 698\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,797 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,797 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:697833.015|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,797 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:96.122|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,797 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,797 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 697\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,797 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,814 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,814 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777550814\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,815 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777550\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,817 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (476, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,817 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (476, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:30,817 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:31,493 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a dog', 0.208, [158.87, 147.68, 285.43, 267.75]), ('a photo of a tv', 0.521, [5.83, 16.25, 468.78, 496.23])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:31,493 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a dog with confidence 0.208 at location [158.87, 147.68, 285.43, 267.75]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:31,493 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.521 at location [5.83, 16.25, 468.78, 496.23]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:31,494 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:678.68|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777551,65667eb0-80f3-4441-8782-bea74260454c, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:31,494 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:678.68|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:65667eb0-80f3-4441-8782-bea74260454c,timestamp:1727777551\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:31,494 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 680\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:31,494 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777551\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:31,494 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:679965.202|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777551\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:31,495 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:109.822|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777551\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:31,495 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777551\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:31,495 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 680\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:31,495 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777551\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:31,512 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777551\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:31,512 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777551512\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:31,513 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777551\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:31,517 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (800, 800)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:31,518 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (800, 800)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:31,518 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,210 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,211 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:697.83|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777552,2ffdca2e-8266-4343-9174-aa135019c43d, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,211 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:697.83|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:2ffdca2e-8266-4343-9174-aa135019c43d,timestamp:1727777552\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,211 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 699\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,211 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777552\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,211 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:699126.26|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777552\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,211 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:88.522|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777552\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,212 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777552\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,212 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 699\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,212 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777552\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,230 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777552\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,230 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777552230\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,231 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777552\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,249 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1350, 1080)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,251 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1350, 1080)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,251 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,982 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,987 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:755.72|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777552,6958c06c-e228-4659-bd48-d867bbd3e6dc, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,987 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:755.72|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:6958c06c-e228-4659-bd48-d867bbd3e6dc,timestamp:1727777552\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,987 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 758\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,987 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777552\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,987 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:757116.855|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777552\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,987 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:113.102|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777552\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,987 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777552\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,987 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 757\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:32,987 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777552\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,005 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777553\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,005 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777553005\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,009 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777553\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,009 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,011 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,011 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,703 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.635, [12.91, 355.0, 489.6, 639.63]), ('a photo of a tv', 0.122, [19.54, 360.72, 482.3, 629.16])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,703 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.635 at location [12.91, 355.0, 489.6, 639.63]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,703 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.122 at location [19.54, 360.72, 482.3, 629.16]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,704 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:698.1|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777553,616a7ef7-4d5d-465c-999a-e87983121c16, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,704 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:698.1|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:616a7ef7-4d5d-465c-999a-e87983121c16,timestamp:1727777553\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,704 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 699\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,704 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777553\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,704 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:699335.435|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777553\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,704 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:111.912|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777553\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,705 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777553\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,705 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 699\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,705 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777553\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,724 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777553\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,725 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777553725\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,726 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777553\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,768 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (2560, 1707)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,773 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1707)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:33,773 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:34,476 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.124, [100.25, 84.51, 2465.71, 1467.33])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:34,477 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.124 at location [100.25, 84.51, 2465.71, 1467.33]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:34,478 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:752.07|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777554,9afc2d80-ab12-450b-a66a-5de21b7662e9, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:34,478 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:752.07|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:9afc2d80-ab12-450b-a66a-5de21b7662e9,timestamp:1727777554\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:34,478 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 754\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:34,478 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777554\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:34,478 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:753628.798|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777554\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:34,478 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:88.922|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777554\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:34,478 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777554\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:34,478 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 753\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:34,479 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777554\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:34,497 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777554\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:34,497 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777554497\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:34,498 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777554\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:34,511 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (1500, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:34,513 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:34,513 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,200 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.259, [14.12, 8.18, 1505.61, 897.58])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,200 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.259 at location [14.12, 8.18, 1505.61, 897.58]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,201 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:703.4|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777555,44bc808c-9b3d-4069-8d74-eff881e3caa5, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,201 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:703.4|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:44bc808c-9b3d-4069-8d74-eff881e3caa5,timestamp:1727777555\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,202 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 706\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,202 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777555\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,202 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:704995.623|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777555\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,202 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:91.611|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777555\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,202 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777555\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,203 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 705\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,203 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777555\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,219 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777555\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,219 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777555219\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,220 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777555\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,234 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,238 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,238 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,975 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,976 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:755.71|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777555,7b1274c4-39a2-451b-b40e-f725f6eca339, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,976 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:755.71|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:7b1274c4-39a2-451b-b40e-f725f6eca339,timestamp:1727777555\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,976 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 757\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,976 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777555\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,977 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:757061.654|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777555\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,977 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:168.434|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777555\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,977 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777555\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,977 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 757\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,977 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777555\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,994 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777555\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,994 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777555994\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,995 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777555\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:35,999 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:36,001 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:36,001 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:36,698 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.138, [61.43, 253.68, 952.98, 754.55])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:36,698 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.138 at location [61.43, 253.68, 952.98, 754.55]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:36,700 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:704.36|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777556,be24c6d0-c170-44e0-8b7b-4c5529f06161, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:36,700 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:704.36|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:be24c6d0-c170-44e0-8b7b-4c5529f06161,timestamp:1727777556\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:36,700 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 706\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:36,700 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777556\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:36,700 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:705684.926|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777556\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:36,700 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:104.442|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777556\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:36,700 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777556\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:36,700 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 706\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:36,700 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777556\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:36,718 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777556\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:36,718 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777556718\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:36,719 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777556\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:36,721 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:36,721 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:36,721 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:37,411 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.574, [5.36, 102.36, 487.99, 385.75])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:37,411 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.574 at location [5.36, 102.36, 487.99, 385.75]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:37,413 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:693.46|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777557,c55fd5ae-88db-4515-b306-135917786641, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:37,413 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:693.46|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:c55fd5ae-88db-4515-b306-135917786641,timestamp:1727777557\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:37,413 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 695\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:37,413 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777557\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:37,413 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:694684.945|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777557\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:37,413 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:85.672|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777557\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:37,413 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777557\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:37,413 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 695\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:37,413 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777557\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:37,431 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777557\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:37,431 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777557431\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:37,432 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777557\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:37,442 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:37,444 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:37,444 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,195 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,197 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:764.75|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777558,84d46b9b-b753-487b-a830-0feccfd16da1, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,197 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:764.75|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:84d46b9b-b753-487b-a830-0feccfd16da1,timestamp:1727777558\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,197 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 766\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,197 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777558\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,197 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:766051.307|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777558\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,197 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:75.041|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777558\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,197 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777558\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,197 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 766\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,197 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777558\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,215 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777558\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,215 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777558215\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,216 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777558\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,220 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1024, 1024)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,221 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1024, 1024)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,221 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,908 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,910 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:693.37|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777558,f73bede5-2e47-4e4d-8409-85026a6445e1, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,910 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:693.37|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:f73bede5-2e47-4e4d-8409-85026a6445e1,timestamp:1727777558\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,910 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 695\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,910 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777558\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,910 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:694513.212|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777558\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,910 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:83.471|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777558\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,910 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777558\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,910 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 694\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,910 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777558\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,928 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777558\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,928 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777558928\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,929 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777558\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,940 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,941 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:38,941 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:39,623 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.234, [27.36, 77.6, 971.64, 636.3]), ('a photo of a tv', 0.102, [432.53, 749.15, 569.08, 924.91])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:39,623 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.234 at location [27.36, 77.6, 971.64, 636.3]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:39,623 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.102 at location [432.53, 749.15, 569.08, 924.91]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:39,624 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:694.8|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777559,394411db-7bec-4022-8b6b-255f1e177678, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:39,624 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:694.8|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:394411db-7bec-4022-8b6b-255f1e177678,timestamp:1727777559\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:39,624 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 696\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:39,625 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777559\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:39,625 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:696059.361|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777559\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:39,625 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:91.422|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777559\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:39,625 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777559\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:39,625 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 695\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:39,625 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777559\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:39,642 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777559\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:39,643 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777559642\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:39,643 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777559\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:39,645 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:39,645 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:39,646 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:40,384 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.589, [2.87, 76.06, 499.37, 413.3])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:40,384 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.589 at location [2.87, 76.06, 499.37, 413.3]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:40,389 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:745.2|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777560,3c4c1411-5353-4151-afdc-7807ea3fa00a, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:40,389 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:745.2|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:3c4c1411-5353-4151-afdc-7807ea3fa00a,timestamp:1727777560\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:40,389 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 747\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:40,389 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777560\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:40,389 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:746412.509|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777560\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:40,389 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:80.881|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777560\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:40,389 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777560\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:40,389 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 746\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:40,389 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777560\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:40,407 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777560\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:40,407 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777560407\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:40,408 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777560\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:40,418 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:40,421 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:40,421 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,134 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.51, [58.24, 363.17, 1582.79, 1252.01])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,134 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.51 at location [58.24, 363.17, 1582.79, 1252.01]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,136 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:727.52|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777561,0bb72a73-94ec-42f4-9ea6-26b67d1a8a1f, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,136 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:727.52|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:0bb72a73-94ec-42f4-9ea6-26b67d1a8a1f,timestamp:1727777561\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,136 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 729\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,136 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777561\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,136 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:728969.775|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777561\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,136 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:74.171|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777561\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,137 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777561\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,137 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 729\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,137 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777561\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,154 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777561\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,154 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777561154\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,155 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777561\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,155 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (60, 40)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,155 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (60, 40)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,155 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,824 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,825 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:670.58|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777561,a8839f65-5ba3-4e26-acb6-789bd5093a75, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,826 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 672\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,826 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:670.58|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:a8839f65-5ba3-4e26-acb6-789bd5093a75,timestamp:1727777561\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,826 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777561\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,826 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:671889.148|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777561\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,826 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:84.442|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777561\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,826 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777561\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,826 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 672\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,826 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777561\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,844 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777561\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,844 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777561844\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,845 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777561\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,853 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,856 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:41,856 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:42,556 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.455, [41.37, 235.08, 1536.21, 1434.54])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:42,556 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.455 at location [41.37, 235.08, 1536.21, 1434.54]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:42,558 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:712.86|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777562,e13cd767-21a5-4a88-a0f5-a4f6f8a23eda, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:42,558 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:712.86|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:e13cd767-21a5-4a88-a0f5-a4f6f8a23eda,timestamp:1727777562\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:42,559 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 716\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:42,560 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777562\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:42,560 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:715663.009|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777562\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:42,560 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:80.082|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777562\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:42,560 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777562\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:42,560 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 715\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:42,560 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777562\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:42,578 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777562\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:42,578 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777562578\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:42,579 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777562\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:42,588 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (1000, 892)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:42,589 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 892)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:42,589 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:43,287 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.192, [0.79, -2.61, 992.68, 571.46])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:43,287 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.192 at location [0.79, -2.61, 992.68, 571.46]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:43,289 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:709.89|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777563,6590f7ed-f306-41fc-a8dc-533869d408f7, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:43,289 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:709.89|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:6590f7ed-f306-41fc-a8dc-533869d408f7,timestamp:1727777563\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:43,289 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 712\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:43,289 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777563\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:43,289 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:711144.682|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777563\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:43,289 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.102|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777563\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:43,289 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777563\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:43,289 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 711\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:43,289 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777563\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:43,307 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777563\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:43,307 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777563307\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:43,308 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777563\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:43,338 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:43,341 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:43,341 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,049 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.133, [109.03, 383.61, 1479.03, 1210.32])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,049 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.133 at location [109.03, 383.61, 1479.03, 1210.32]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,051 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:742.14|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777564,2ac57217-71cc-4a0b-8460-1fc32d851bca, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,051 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:742.14|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:2ac57217-71cc-4a0b-8460-1fc32d851bca,timestamp:1727777564\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,051 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 744\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,051 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777564\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,051 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:743512.185|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777564\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,051 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:114.512|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777564\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,051 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777564\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,051 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 744\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,051 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777564\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,070 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777564\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,070 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777564070\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,071 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777564\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,080 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1650, 1650)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,084 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1650, 1650)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,084 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,825 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.666, [100.78, 386.78, 1591.8, 1296.79])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,825 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.666 at location [100.78, 386.78, 1591.8, 1296.79]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,826 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:755.5|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777564,d1af6902-eb4c-419c-998d-b645c7b4bdb6, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,826 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:755.5|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:d1af6902-eb4c-419c-998d-b645c7b4bdb6,timestamp:1727777564\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,827 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 758\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,827 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777564\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,827 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:756823.009|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777564\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,827 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:69.581|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777564\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,827 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777564\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,827 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 756\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,827 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777564\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,844 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777564\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,845 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777564845\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,846 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777564\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,859 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1096, 1350)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,861 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1096, 1350)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:44,861 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:45,590 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.124, [107.81, 7.3, 1010.18, 595.34])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:45,590 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.124 at location [107.81, 7.3, 1010.18, 595.34]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:45,592 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:746.1|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777565,45c127a6-25c9-4f15-90ca-785c9e58defd, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:45,592 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:746.1|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:45c127a6-25c9-4f15-90ca-785c9e58defd,timestamp:1727777565\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:45,592 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 748\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:45,592 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777565\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:45,592 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:747419.17|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777565\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:45,592 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:80.162|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777565\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:45,592 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777565\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:45,592 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 747\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:45,592 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777565\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:45,609 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777565\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:45,610 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777565610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:45,610 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777565\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:45,614 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1024, 1024)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:45,615 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1024, 1024)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:45,615 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:46,345 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.191, [29.79, 102.0, 959.14, 912.4])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:46,345 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.191 at location [29.79, 102.0, 959.14, 912.4]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:46,347 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:736.32|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777566,6efc0113-8978-4497-95b5-dc8398b214e2, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:46,347 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:736.32|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:6efc0113-8978-4497-95b5-dc8398b214e2,timestamp:1727777566\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:46,347 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 738\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:46,347 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777566\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:46,347 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:737473.648|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777566\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:46,347 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:89.022|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777566\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:46,347 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777566\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:46,347 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 737\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:46,347 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777566\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:46,365 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777566\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:46,366 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777566366\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:46,367 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777566\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:46,393 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:46,396 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:46,396 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,135 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,136 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:769.5|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777567,bb35ca62-d90d-4942-a5f1-01ac3fe5f89e, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,136 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:769.5|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:bb35ca62-d90d-4942-a5f1-01ac3fe5f89e,timestamp:1727777567\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,137 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 772\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,137 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777567\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,137 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:770942.732|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777567\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,137 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:82.702|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777567\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,137 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777567\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,137 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 770\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,137 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777567\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,154 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777567\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,155 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777567154\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,155 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777567\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,159 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1100, 1100)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,161 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1100, 1100)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,161 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,892 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,899 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:743.93|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777567,dd0cef86-03f1-41de-ad76-03f3bb40af65, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,899 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:743.93|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:dd0cef86-03f1-41de-ad76-03f3bb40af65,timestamp:1727777567\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,900 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 746\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,900 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777567\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,900 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:745097.435|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777567\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,900 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.122|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777567\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,900 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777567\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,900 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 744\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,900 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777567\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,918 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777567\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,918 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777567918\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,919 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777567\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,922 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (1024, 1024)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,924 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (1024, 1024)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:47,924 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:48,602 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.569, [61.62, 196.53, 953.77, 808.84])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:48,602 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.569 at location [61.62, 196.53, 953.77, 808.84]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:48,603 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:684.47|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777568,4444d415-6398-4c71-abcf-67bd0b295a85, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:48,603 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:684.47|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:4444d415-6398-4c71-abcf-67bd0b295a85,timestamp:1727777568\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:48,604 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 686\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:48,604 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777568\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:48,604 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:685726.263|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777568\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:48,604 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:69.641|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777568\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:48,604 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777568\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:48,604 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 685\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:48,604 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777568\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:48,622 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777568\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:48,622 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777568622\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:48,623 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777568\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:48,630 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:48,631 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:48,631 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:49,334 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.2, [1.11, 7.11, 989.58, 621.2]), ('a photo of a tv', 0.11, [395.66, 779.22, 568.99, 998.96])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:49,334 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.2 at location [1.11, 7.11, 989.58, 621.2]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:49,334 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.11 at location [395.66, 779.22, 568.99, 998.96]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:49,335 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:711.82|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777569,ec09ef98-0a17-44dd-ad0c-0bb64eebb146, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:49,335 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:711.82|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:ec09ef98-0a17-44dd-ad0c-0bb64eebb146,timestamp:1727777569\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:49,335 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 713\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:49,335 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777569\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:49,336 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:713129.621|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777569\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:49,336 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:78.582|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777569\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:49,336 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777569\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:49,336 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 713\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:49,336 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777569\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:49,353 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777569\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:49,353 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777569353\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:49,354 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777569\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:49,363 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:49,367 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:49,367 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,108 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.707, [116.36, 283.19, 1416.58, 1361.44]), ('a photo of a tv', 0.108, [123.26, 280.09, 1483.01, 1353.56])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,108 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.707 at location [116.36, 283.19, 1416.58, 1361.44]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,108 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.108 at location [123.26, 280.09, 1483.01, 1353.56]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,114 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:759.41|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777570,42816d18-458f-46a1-a8c4-3abe462e5cd1, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,114 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:759.41|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:42816d18-458f-46a1-a8c4-3abe462e5cd1,timestamp:1727777570\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,114 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 761\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,114 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777570\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,114 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:760596.562|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777570\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,114 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:79.571|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777570\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,114 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777570\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,114 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 760\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,114 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777570\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,132 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777570\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,132 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777570132\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,133 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777570\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,137 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (945, 613)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,137 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (945, 613)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,137 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,859 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.357, [148.55, 61.15, 908.37, 514.79])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,861 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.357 at location [148.55, 61.15, 908.37, 514.79]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,867 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:733.96|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777570,f2bd72f3-725b-47ba-8ba5-aead0b2d95c7, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,867 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:733.96|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:f2bd72f3-725b-47ba-8ba5-aead0b2d95c7,timestamp:1727777570\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,867 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 735\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,867 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777570\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,867 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:735200.795|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777570\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,867 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:75.802|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777570\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,868 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777570\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,868 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 735\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,868 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777570\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,886 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777570\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,886 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777570886\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,887 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777570\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,911 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,915 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:50,915 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:51,676 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.636, [38.32, 344.64, 1524.75, 1289.66])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:51,676 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.636 at location [38.32, 344.64, 1524.75, 1289.66]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:51,677 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:789.67|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777571,4ae0bc6d-8b89-478d-88b5-bd4a3f41bb88, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:51,677 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:789.67|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:4ae0bc6d-8b89-478d-88b5-bd4a3f41bb88,timestamp:1727777571\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:51,677 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 791\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:51,677 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777571\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:51,678 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:790928.236|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777571\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:51,678 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:64.001|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777571\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:51,678 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777571\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:51,678 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 790\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:51,678 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777571\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:51,696 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777571\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:51,696 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777571696\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:51,697 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777571\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:51,733 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (2000, 2000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:51,738 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (2000, 2000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:51,739 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:52,475 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.474, [271.23, 479.85, 1759.71, 1434.07])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:52,475 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.474 at location [271.23, 479.85, 1759.71, 1434.07]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:52,476 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:779.16|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777572,ca74c542-ab31-4590-9f6f-d05a6a1adb7c, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:52,476 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:779.16|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:ca74c542-ab31-4590-9f6f-d05a6a1adb7c,timestamp:1727777572\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:52,477 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 781\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:52,477 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777572\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:52,477 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:780537.946|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777572\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:52,477 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.481|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777572\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:52,477 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777572\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:52,477 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 780\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:52,477 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777572\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:52,495 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777572\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:52,495 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777572495\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:52,496 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777572\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:52,521 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (2000, 2000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:52,526 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (2000, 2000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:52,526 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:53,229 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.318, [448.39, 323.89, 1541.11, 968.84])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:53,229 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.318 at location [448.39, 323.89, 1541.11, 968.84]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:53,231 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:734.41|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777573,5e7be67b-7b7a-47f5-8452-39726825ef82, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:53,231 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:734.41|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:5e7be67b-7b7a-47f5-8452-39726825ef82,timestamp:1727777573\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:53,231 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 736\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:53,231 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777573\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:53,231 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:735609.132|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777573\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:53,231 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:79.921|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777573\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:53,231 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777573\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:53,231 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 736\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:53,231 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777573\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:53,249 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777573\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:53,249 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777573249\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:53,250 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777573\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:53,261 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:53,265 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:53,265 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:53,998 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.528, [50.02, 341.17, 1543.5, 1230.9])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:53,998 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.528 at location [50.02, 341.17, 1543.5, 1230.9]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,000 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:749.21|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777573,0d40a42c-755b-454c-9e20-396679916a9e, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,000 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:749.21|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:0d40a42c-755b-454c-9e20-396679916a9e,timestamp:1727777574\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,000 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 751\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,000 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777574\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,000 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:750662.752|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777574\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,000 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:68.401|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777574\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,000 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777574\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,000 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 751\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,000 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777574\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,018 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777574\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,018 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777574018\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,019 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777574\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,024 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (1024, 1024)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,025 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (1024, 1024)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,025 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,750 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,754 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:735.28|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777574,f617efcc-0d39-405d-a43c-345e20a151f1, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,754 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:735.28|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:f617efcc-0d39-405d-a43c-345e20a151f1,timestamp:1727777574\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,754 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 736\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,755 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777574\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,755 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:736506.729|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777574\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,755 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:79.501|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777574\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,755 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777574\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,755 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 736\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,755 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777574\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,773 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777574\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,773 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777574773\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,774 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777574\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,780 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (1100, 1211)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,781 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (1100, 1211)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:54,781 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:55,487 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.487, [34.29, 48.3, 1048.72, 663.38]), ('a photo of a tv', 0.131, [462.72, 693.63, 642.68, 1046.74])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:55,487 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.487 at location [34.29, 48.3, 1048.72, 663.38]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:55,487 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.131 at location [462.72, 693.63, 642.68, 1046.74]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:55,489 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:715.12|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777575,d713d6fe-53fe-42f3-9da9-5a71b104a7b3, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:55,489 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:715.12|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:d713d6fe-53fe-42f3-9da9-5a71b104a7b3,timestamp:1727777575\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:55,489 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 717\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:55,489 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777575\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:55,489 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:716303.311|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777575\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:55,489 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:80.661|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777575\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:55,489 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777575\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:55,489 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 716\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:55,489 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777575\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:55,507 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777575\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:55,507 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777575507\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:55,508 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777575\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:55,518 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:55,519 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:55,519 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,206 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,208 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:699.35|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777576,365ffe3d-4630-47fe-8cd9-fcaac4475453, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,208 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:699.35|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:365ffe3d-4630-47fe-8cd9-fcaac4475453,timestamp:1727777576\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,208 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 701\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,208 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777576\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,208 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:700574.083|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777576\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,208 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.752|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777576\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,208 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777576\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,208 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 701\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,208 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777576\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,227 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777576\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,227 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777576227\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,228 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777576\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,250 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (2482, 2336)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,258 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (2482, 2336)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,258 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,983 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.447, [65.72, 40.65, 2430.13, 2094.19])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,983 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.447 at location [65.72, 40.65, 2430.13, 2094.19]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,991 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:763.5|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777576,9b01a6f4-5794-48a4-ad9f-9149f7f84a21, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,991 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:763.5|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:9b01a6f4-5794-48a4-ad9f-9149f7f84a21,timestamp:1727777576\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,992 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 765\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,992 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777576\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,992 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:764839.902|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777576\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,992 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:78.392|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777576\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,992 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777576\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,992 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 764\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:56,992 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777576\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,009 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777577\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,009 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777577009\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,010 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777577\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,029 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,032 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,032 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,733 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,734 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:724.06|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777577,9db1ca1a-0ad1-422f-a0cc-2e016ac25168, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,734 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:724.06|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:9db1ca1a-0ad1-422f-a0cc-2e016ac25168,timestamp:1727777577\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,734 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 725\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,735 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777577\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,735 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:725236.33|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777577\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,735 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:83.742|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777577\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,735 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777577\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,735 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 725\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,735 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777577\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,753 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777577\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,753 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777577753\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,754 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777577\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,759 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,761 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:57,761 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:58,485 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.423, [69.67, 62.53, 946.0, 857.17])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:58,485 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.423 at location [69.67, 62.53, 946.0, 857.17]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:58,487 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:732.87|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777578,3465cae4-002c-4dea-bb6b-097be99a23bf, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:58,487 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:732.87|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:3465cae4-002c-4dea-bb6b-097be99a23bf,timestamp:1727777578\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:58,487 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 735\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:58,487 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777578\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:58,487 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:734113.87|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777578\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:58,487 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:68.191|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777578\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:58,487 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777578\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:58,487 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 734\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:58,487 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777578\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:58,505 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777578\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:58,505 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777578505\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:58,506 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777578\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:58,513 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:58,515 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:58,515 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,218 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.162, [28.2, 158.22, 968.96, 822.51])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,218 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.162 at location [28.2, 158.22, 968.96, 822.51]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,220 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:713.8|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777579,8f790970-8d7b-4db9-8ffd-5ca62973fc7a, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,220 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:713.8|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:8f790970-8d7b-4db9-8ffd-5ca62973fc7a,timestamp:1727777579\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,220 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 715\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,220 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777579\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,220 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:714953.251|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777579\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,220 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:78.851|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777579\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,220 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777579\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,220 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 715\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,220 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777579\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,238 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777579\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,238 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777579238\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,239 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777579\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,245 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1008, 662)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,246 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1008, 662)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,246 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,972 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.429, [45.33, 43.29, 963.79, 615.49])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,972 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.429 at location [45.33, 43.29, 963.79, 615.49]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,973 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:734.14|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777579,a234fa04-edc6-4030-9e25-c52e8d013a48, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,973 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:734.14|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:a234fa04-edc6-4030-9e25-c52e8d013a48,timestamp:1727777579\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,973 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 735\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,973 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777579\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,973 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:735410.135|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777579\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,973 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:79.632|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777579\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,973 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777579\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,973 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 735\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,973 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777579\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,994 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777579\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,994 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777579994\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:12:59,995 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777579\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,020 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (2422, 2560)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,028 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (2422, 2560)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,028 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,770 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.194, [1035.31, 1513.63, 1406.04, 2240.57]), ('a photo of a tv', 0.13, [-32.83, -22.85, 2375.5, 2479.28])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,770 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.194 at location [1035.31, 1513.63, 1406.04, 2240.57]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,770 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.13 at location [-32.83, -22.85, 2375.5, 2479.28]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,771 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:775.97|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777580,ef539d3c-0c5a-4b4c-ab53-ec0cca6d9d1c, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,771 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:775.97|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:ef539d3c-0c5a-4b4c-ab53-ec0cca6d9d1c,timestamp:1727777580\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,772 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 779\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,772 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777580\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,772 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:777711.148|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777580\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,772 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:94.861|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777580\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,772 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777580\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,772 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 778\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,772 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777580\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,790 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777580\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,790 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777580790\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,791 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777580\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,803 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (1500, 951)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,805 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 951)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:00,805 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:01,507 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.258, [17.02, 10.59, 1509.16, 895.44])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:01,508 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.258 at location [17.02, 10.59, 1509.16, 895.44]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:01,509 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:717.73|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777581,318c83a6-ed75-4141-901f-d93b11031264, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:01,509 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:717.73|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:318c83a6-ed75-4141-901f-d93b11031264,timestamp:1727777581\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:01,509 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 719\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:01,509 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777581\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:01,509 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:719067.672|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777581\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:01,509 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.062|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777581\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:01,509 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777581\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:01,509 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 719\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:01,509 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777581\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:01,527 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777581\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:01,528 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777581528\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:01,528 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777581\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:01,540 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (1248, 1248)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:01,542 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (1248, 1248)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:01,542 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,247 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.615, [2.47, 186.15, 1242.83, 1064.09])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,247 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.615 at location [2.47, 186.15, 1242.83, 1064.09]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,249 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:720.29|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777582,e93a6d36-1384-49ae-91c4-c75d41f0ad6b, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,249 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:720.29|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:e93a6d36-1384-49ae-91c4-c75d41f0ad6b,timestamp:1727777582\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,249 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 722\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,249 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777582\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,249 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:721482.828|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777582\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,249 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:85.052|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777582\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,250 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777582\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,250 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 721\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,250 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777582\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,266 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777582\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,266 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777582266\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,267 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777582\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,269 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,269 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,269 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,964 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,968 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:701.16|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777582,d636be7d-2a45-4808-98d4-e7f57b91e84c, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,968 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:701.16|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:d636be7d-2a45-4808-98d4-e7f57b91e84c,timestamp:1727777582\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,969 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 703\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,969 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777582\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,969 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:702454.051|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777582\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,969 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:80.262|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777582\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,969 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777582\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,969 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 702\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,969 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777582\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,986 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777582\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,986 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777582986\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,987 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777582\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,990 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1024, 1024)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,992 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1024, 1024)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:02,992 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:03,717 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:03,718 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:731.39|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777583,57fbca60-c2a3-40f1-994d-7caa1e2e86fd, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:03,718 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:731.39|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:57fbca60-c2a3-40f1-994d-7caa1e2e86fd,timestamp:1727777583\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:03,718 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 733\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:03,718 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777583\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:03,718 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:732616.251|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777583\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:03,718 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:82.071|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777583\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:03,719 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777583\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:03,719 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 732\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:03,719 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777583\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:03,735 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777583\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:03,736 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777583736\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:03,736 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777583\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:03,751 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:03,754 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:03,755 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:04,487 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:04,489 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:752.35|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777584,9c5e5d06-38f7-452b-a644-36dbcf102cf3, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:04,489 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:752.35|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:9c5e5d06-38f7-452b-a644-36dbcf102cf3,timestamp:1727777584\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:04,489 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 754\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:04,489 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777584\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:04,489 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:753582.224|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777584\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:04,489 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:85.291|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777584\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:04,489 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777584\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:04,489 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 753\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:04,489 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777584\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:04,507 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777584\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:04,507 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777584507\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:04,508 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777584\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:04,521 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (1500, 951)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:04,523 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 951)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:04,523 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,264 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.258, [17.02, 10.59, 1509.16, 895.44])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,264 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.258 at location [17.02, 10.59, 1509.16, 895.44]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,265 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:757.18|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777585,a46e74b2-e5b7-4786-91f8-d02d9cdb99b7, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,266 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:757.18|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:a46e74b2-e5b7-4786-91f8-d02d9cdb99b7,timestamp:1727777585\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,266 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 759\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,266 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777585\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,266 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:758423.608|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777585\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,266 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:77.871|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777585\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,266 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777585\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,266 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 759\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,266 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777585\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,283 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777585\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,284 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777585284\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,284 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777585\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,293 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,295 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,295 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,991 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,992 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:707.53|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777585,2cfe423b-0792-4d6b-a386-009901596d52, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,992 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:707.53|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:2cfe423b-0792-4d6b-a386-009901596d52,timestamp:1727777585\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,992 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 709\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,992 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777585\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,993 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:708745.922|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777585\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,993 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:85.782|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777585\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,993 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777585\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,993 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 708\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:05,993 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777585\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,010 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777586\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,010 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777586010\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,011 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777586\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,026 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (1242, 1304)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,028 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (1242, 1304)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,028 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,717 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.648, [70.53, 268.79, 1162.62, 969.8])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,718 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.648 at location [70.53, 268.79, 1162.62, 969.8]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,718 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:707.09|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777586,5aac1983-feed-4bb4-b71b-c0123d73f112, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,718 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:707.09|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:5aac1983-feed-4bb4-b71b-c0123d73f112,timestamp:1727777586\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,718 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 708\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,719 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777586\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,719 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:708339.754|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777586\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,719 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:88.772|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777586\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,719 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777586\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,719 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 708\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,719 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777586\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,741 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777586\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,741 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777586741\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,743 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777586\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,771 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (2560, 1524)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,776 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1524)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:06,776 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:07,495 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.101, [1.77, -29.88, 2547.67, 1481.27])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:07,495 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.101 at location [1.77, -29.88, 2547.67, 1481.27]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:07,496 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:753.62|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777587,f8e7976b-bb97-4be9-b20b-8946039cd6df, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:07,497 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:753.62|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:f8e7976b-bb97-4be9-b20b-8946039cd6df,timestamp:1727777587\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:07,497 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 758\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:07,497 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777587\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:07,497 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:755651.985|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777587\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:07,497 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:64.292|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777587\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:07,497 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777587\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:07,497 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 756\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:07,497 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777587\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:07,515 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777587\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:07,515 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777587515\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:07,516 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777587\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:07,551 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (2000, 2000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:07,556 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (2000, 2000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:07,556 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:08,274 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:08,276 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:759.38|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777588,1fbb73da-0b92-4f21-8163-aca9a696e16b, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:08,276 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:759.38|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:1fbb73da-0b92-4f21-8163-aca9a696e16b,timestamp:1727777588\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:08,276 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 761\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:08,276 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777588\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:08,276 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:760671.821|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777588\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:08,276 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:86.632|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777588\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:08,276 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777588\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:08,276 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 761\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:08,276 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777588\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:08,294 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777588\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:08,294 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777588294\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:08,295 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777588\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:08,312 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:08,315 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:08,315 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,004 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,005 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:710.31|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777589,72ce46e5-ace3-4971-894f-110a65aaf256, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,006 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:710.31|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:72ce46e5-ace3-4971-894f-110a65aaf256,timestamp:1727777589\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,006 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 712\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,006 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777589\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,006 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:711780.29|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777589\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,006 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:84.451|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777589\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,006 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777589\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,006 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 712\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,006 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777589\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,024 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777589\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,024 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777589024\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,025 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777589\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,045 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,048 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,048 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,790 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.528, [20.64, 329.81, 1574.15, 1347.15])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,790 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.528 at location [20.64, 329.81, 1574.15, 1347.15]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,791 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:766.34|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777589,ebf21c10-4993-4df3-99da-e60963c5dcfd, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,791 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:766.34|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:ebf21c10-4993-4df3-99da-e60963c5dcfd,timestamp:1727777589\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,791 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 768\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,791 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777589\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,792 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:767674.885|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777589\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,792 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:78.331|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777589\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,792 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777589\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,792 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 767\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,792 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777589\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,809 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777589\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,809 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777589809\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,810 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777589\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,811 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,812 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:09,812 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:10,486 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.745, [48.79, 106.12, 456.31, 376.16])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:10,486 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.745 at location [48.79, 106.12, 456.31, 376.16]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:10,487 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:677.66|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777590,1547365d-4af7-4b0d-97cc-6f1f34672c07, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:10,488 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:677.66|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:1547365d-4af7-4b0d-97cc-6f1f34672c07,timestamp:1727777590\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:10,488 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 679\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:10,488 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777590\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:10,488 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:678866.697|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777590\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:10,488 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:84.562|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777590\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:10,488 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777590\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:10,488 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 679\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:10,488 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777590\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:10,506 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777590\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:10,506 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777590506\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:10,507 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777590\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:10,519 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (1500, 951)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:10,521 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 951)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:10,522 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,208 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.258, [17.02, 10.59, 1509.16, 895.44])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,208 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.258 at location [17.02, 10.59, 1509.16, 895.44]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,212 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:705.62|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777591,5e69d711-1793-4499-a9a5-61e7f361d942, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,212 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:705.62|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:5e69d711-1793-4499-a9a5-61e7f361d942,timestamp:1727777591\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,213 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 708\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,213 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777591\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,213 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:706882.166|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777591\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,213 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:88.291|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777591\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,213 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777591\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,213 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 707\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,213 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777591\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,232 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777591\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,233 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777591233\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,234 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777591\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,258 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (2560, 1920)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,265 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1920)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,265 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,970 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,972 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:737.95|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777591,7fb211b0-f473-49d3-9bb5-41c28a421815, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,972 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:737.95|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:7fb211b0-f473-49d3-9bb5-41c28a421815,timestamp:1727777591\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,972 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 740\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,972 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777591\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,972 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:739525.496|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777591\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,972 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:121.322|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777591\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,972 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777591\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,972 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 739\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,972 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777591\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,991 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777591\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,991 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777591991\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:11,992 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777591\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:12,001 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:12,002 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:12,002 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:12,684 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.209, [13.36, 226.04, 979.46, 797.66])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:12,684 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.209 at location [13.36, 226.04, 979.46, 797.66]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:12,685 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:693.43|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777592,12f41d22-0188-4d75-b624-b23a083d922b, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:12,686 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:693.43|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:12f41d22-0188-4d75-b624-b23a083d922b,timestamp:1727777592\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:12,686 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 695\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:12,686 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777592\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:12,686 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:694694.635|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777592\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:12,686 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:84.362|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777592\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:12,686 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777592\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:12,686 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 695\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:12,686 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777592\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:12,704 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777592\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:12,704 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777592704\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:12,705 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777592\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:12,717 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:12,720 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:12,720 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:13,435 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:13,440 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:734.85|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777593,7b807067-7982-434e-9432-db5344acd5f1, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:13,440 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:734.85|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:7b807067-7982-434e-9432-db5344acd5f1,timestamp:1727777593\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:13,441 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 736\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:13,441 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777593\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:13,441 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:736156.863|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777593\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:13,441 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:83.382|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777593\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:13,441 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777593\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:13,441 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 736\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:13,441 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777593\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:13,458 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777593\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:13,458 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777593458\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:13,459 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777593\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:13,465 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:13,466 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:13,466 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,150 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.535, [16.99, 356.57, 481.2, 638.64])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,150 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.535 at location [16.99, 356.57, 481.2, 638.64]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,152 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:693.15|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777594,0d851e0a-3856-43ab-8b73-cba3ff8db4e6, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,152 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:693.15|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:0d851e0a-3856-43ab-8b73-cba3ff8db4e6,timestamp:1727777594\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,152 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 695\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,152 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777594\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,152 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:694328.998|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777594\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,152 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:79.301|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777594\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,152 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777594\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,152 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 694\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,152 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777594\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,170 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777594\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,171 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777594171\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,172 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777594\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,179 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1000, 667)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,180 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 667)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,180 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,907 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.214, [36.35, 37.85, 968.01, 582.09])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,907 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.214 at location [36.35, 37.85, 968.01, 582.09]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,911 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:739.68|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777594,3d15acde-900a-43fc-bb4c-2849a99d8220, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,911 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:739.68|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:3d15acde-900a-43fc-bb4c-2849a99d8220,timestamp:1727777594\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,912 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 742\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,912 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777594\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,912 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:740968.375|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777594\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,912 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:83.672|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777594\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,912 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777594\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,912 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 740\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,912 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777594\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,929 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777594\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,929 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777594929\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,930 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777594\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,951 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,955 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:14,955 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:15,685 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:15,686 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:756.19|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777595,f9fd13ce-d766-4a1e-adf5-ed1a22b4378d, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:15,686 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:756.19|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:f9fd13ce-d766-4a1e-adf5-ed1a22b4378d,timestamp:1727777595\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:15,686 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 757\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:15,687 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777595\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:15,687 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:757524.774|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777595\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:15,687 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.811|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777595\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:15,687 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777595\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:15,687 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 757\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:15,687 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777595\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:15,707 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777595\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:15,707 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777595707\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:15,708 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777595\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:15,731 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (2560, 1920)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:15,738 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1920)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:15,738 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:16,454 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:16,456 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:747.68|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777596,f5d35625-1045-4684-84b9-1a32313509ef, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:16,456 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:747.68|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:f5d35625-1045-4684-84b9-1a32313509ef,timestamp:1727777596\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:16,456 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 750\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:16,456 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777596\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:16,456 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:749238.415|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777596\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:16,456 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:86.162|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777596\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:16,456 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777596\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:16,457 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 749\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:16,457 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777596\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:16,474 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777596\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:16,475 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777596475\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:16,475 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777596\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:16,485 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:16,487 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:16,487 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,210 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,211 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:735.74|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777597,a48ee638-9be8-4d91-9cf8-9f3375950236, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,211 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:735.74|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:a48ee638-9be8-4d91-9cf8-9f3375950236,timestamp:1727777597\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,212 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 738\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,212 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777597\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,212 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:736985.989|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777597\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,212 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:73.771|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777597\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,212 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777597\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,212 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 737\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,212 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777597\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,230 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777597\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,230 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777597230\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,231 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777597\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,235 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1024, 1024)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,236 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1024, 1024)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,237 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,935 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.356, [46.5, 278.39, 1002.0, 860.31])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,935 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.356 at location [46.5, 278.39, 1002.0, 860.31]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,937 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:705.7|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777597,720131e8-1219-48ff-b4b8-2d84e2de95b7, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,937 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:705.7|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:720131e8-1219-48ff-b4b8-2d84e2de95b7,timestamp:1727777597\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,937 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 707\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,937 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777597\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,937 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:706907.71|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777597\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,937 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:87.742|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777597\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,937 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777597\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,937 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 707\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,937 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777597\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,954 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777597\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,954 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777597954\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,955 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777597\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,965 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,966 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:17,966 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:18,668 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.159, [1.01, 138.81, 991.76, 723.69]), ('a photo of a tv', 0.166, [418.87, 715.18, 567.0, 909.27])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:18,668 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.159 at location [1.01, 138.81, 991.76, 723.69]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:18,668 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.166 at location [418.87, 715.18, 567.0, 909.27]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:18,669 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:714.65|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777598,f031546b-0d54-45d1-a60f-0ae17d5f50e1, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:18,670 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:714.65|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:f031546b-0d54-45d1-a60f-0ae17d5f50e1,timestamp:1727777598\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:18,670 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 717\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:18,670 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777598\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:18,670 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:715821.902|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777598\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:18,670 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:82.152|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777598\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:18,670 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777598\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:18,670 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 716\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:18,670 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777598\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:18,688 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777598\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:18,688 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777598688\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:18,689 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777598\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:18,698 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:18,699 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:18,700 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:19,396 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.523, [5.76, 88.75, 990.47, 688.03]), ('a photo of a tv', 0.113, [433.26, 741.16, 567.31, 913.57])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:19,396 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.523 at location [5.76, 88.75, 990.47, 688.03]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:19,396 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.113 at location [433.26, 741.16, 567.31, 913.57]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:19,397 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:708.81|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777599,62e8a835-d909-41f4-842d-9c6de1bb46cd, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:19,398 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:708.81|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:62e8a835-d909-41f4-842d-9c6de1bb46cd,timestamp:1727777599\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:19,398 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 711\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:19,398 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777599\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:19,398 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:710082.241|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777599\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:19,398 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:82.312|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777599\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:19,398 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777599\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:19,398 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 710\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:19,398 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777599\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:19,416 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777599\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:19,416 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777599416\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:19,417 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777599\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:19,424 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (1441, 1128)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:19,426 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (1441, 1128)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:19,426 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,125 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,127 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:709.55|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777600,179bd7bf-0033-4ca0-a7fe-7cec3d29bb67, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,127 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:709.55|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:179bd7bf-0033-4ca0-a7fe-7cec3d29bb67,timestamp:1727777600\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,127 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 712\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,127 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777600\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,127 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:710845.415|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777600\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,127 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:82.451|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777600\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,127 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777600\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,127 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 711\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,127 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777600\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,145 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777600\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,145 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777600145\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,146 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777600\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,166 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,170 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,170 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,911 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.324, [13.32, 331.42, 1571.82, 1349.36])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,912 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.324 at location [13.32, 331.42, 1571.82, 1349.36]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,913 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:766.78|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777600,d475b427-255c-4706-b58b-2d221bdb66e3, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,913 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:766.78|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:d475b427-255c-4706-b58b-2d221bdb66e3,timestamp:1727777600\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,913 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 768\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,913 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777600\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,913 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:767966.145|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777600\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,913 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:98.892|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777600\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,913 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777600\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,913 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 768\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,913 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777600\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,934 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777600\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,934 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777600934\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,935 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777600\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,990 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (2560, 1624)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,995 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1624)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:20,995 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:21,725 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.133, [1.32, -2.27, 2556.96, 1577.13])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:21,725 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.133 at location [1.32, -2.27, 2556.96, 1577.13]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:21,726 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:790.89|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777601,217c7884-750c-4121-8a01-473a91a0470d, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:21,727 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:790.89|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:217c7884-750c-4121-8a01-473a91a0470d,timestamp:1727777601\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:21,727 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 794\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:21,727 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777601\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:21,727 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:792403.575|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777601\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:21,727 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:83.061|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777601\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:21,727 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777601\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:21,727 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 793\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:21,727 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777601\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:21,744 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777601\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:21,745 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777601745\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:21,745 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777601\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:21,751 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (800, 800)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:21,752 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (800, 800)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:21,752 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:22,474 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:22,475 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:729.78|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777602,53af3c0f-ebd2-4d99-80b4-7ce05860f934, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:22,475 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:729.78|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:53af3c0f-ebd2-4d99-80b4-7ce05860f934,timestamp:1727777602\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:22,476 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 732\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:22,476 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777602\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:22,476 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:730969.123|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777602\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:22,476 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:82.221|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777602\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:22,476 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777602\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:22,476 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 730\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:22,476 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777602\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:22,494 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777602\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:22,494 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777602494\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:22,495 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777602\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:22,522 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (2560, 1584)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:22,527 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1584)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:22,527 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,273 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.108, [578.45, 96.89, 1985.42, 929.82])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,273 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.108 at location [578.45, 96.89, 1985.42, 929.82]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,275 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:779.3|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777603,6382cc62-2166-4e1d-80c4-76d7fc4069a0, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,275 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:779.3|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:6382cc62-2166-4e1d-80c4-76d7fc4069a0,timestamp:1727777603\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,275 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 781\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,275 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777603\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,275 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:780514.547|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777603\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,275 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.912|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777603\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,275 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777603\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,275 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 781\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,275 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777603\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,291 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777603\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,292 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777603292\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,292 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777603\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,301 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,302 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,302 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,984 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.512, [54.11, 225.53, 934.67, 780.64])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,984 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.512 at location [54.11, 225.53, 934.67, 780.64]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,985 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:692.64|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777603,0b4969ed-129f-4f53-a00a-c5e7a5886028, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,985 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:692.64|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:0b4969ed-129f-4f53-a00a-c5e7a5886028,timestamp:1727777603\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,986 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 695\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,986 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777603\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,986 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:693977.112|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777603\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,986 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.722|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777603\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,986 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777603\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,986 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 694\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:23,986 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777603\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,003 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777604\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,003 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777604003\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,004 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777604\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,023 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (2560, 1707)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,029 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1707)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,029 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,752 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.483, [98.83, 122.91, 2480.66, 1544.4])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,752 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.483 at location [98.83, 122.91, 2480.66, 1544.4]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,754 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:749.23|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777604,0ca0f5df-c07e-4317-9461-318998a92b37, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,754 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:749.23|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:0ca0f5df-c07e-4317-9461-318998a92b37,timestamp:1727777604\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,754 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 751\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,754 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777604\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,754 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:750472.018|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777604\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,754 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:78.701|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777604\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,754 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777604\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,754 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 751\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,754 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777604\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,772 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777604\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,772 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777604772\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,773 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777604\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,814 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (1992, 1951)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,819 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (1992, 1951)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:24,819 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:25,560 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.291, [96.19, 340.51, 1908.02, 1467.95])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:25,560 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.291 at location [96.19, 340.51, 1908.02, 1467.95]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:25,567 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:794.04|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777605,8b3780de-f132-48d3-b153-3a28601c29e0, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:25,567 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:794.04|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:8b3780de-f132-48d3-b153-3a28601c29e0,timestamp:1727777605\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:25,568 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 796\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:25,568 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777605\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:25,568 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:795478.774|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777605\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:25,568 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:59.841|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777605\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:25,568 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777605\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:25,568 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 795\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:25,568 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777605\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:25,586 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777605\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:25,586 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777605586\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:25,587 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777605\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:25,594 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:25,595 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:25,595 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:26,321 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.313, [3.21, 133.89, 981.79, 700.97]), ('a photo of a tv', 0.113, [31.21, 731.98, 154.34, 896.65])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:26,321 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.313 at location [3.21, 133.89, 981.79, 700.97]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:26,321 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.113 at location [31.21, 731.98, 154.34, 896.65]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:26,322 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:735.48|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777606,1e861041-0078-430b-aa1e-324f03ccb9fb, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:26,322 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:735.48|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:1e861041-0078-430b-aa1e-324f03ccb9fb,timestamp:1727777606\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:26,323 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 737\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:26,323 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777606\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:26,323 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:736713.764|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777606\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:26,323 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.582|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777606\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:26,323 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777606\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:26,323 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 736\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:26,323 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777606\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:26,341 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777606\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:26,341 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777606341\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:26,342 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777606\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:26,353 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (938, 1428)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:26,355 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (938, 1428)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:26,355 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,093 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.266, [9.4, 64.38, 917.6, 630.48]), ('a photo of a tv', 0.114, [26.25, 39.48, 919.41, 854.31])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,093 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.266 at location [9.4, 64.38, 917.6, 630.48]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,093 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.114 at location [26.25, 39.48, 919.41, 854.31]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,095 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:752.56|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777607,8d0f401d-754f-4cb1-9f7f-5ddcf283d146, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,095 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:752.56|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:8d0f401d-754f-4cb1-9f7f-5ddcf283d146,timestamp:1727777607\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,095 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 754\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,095 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777607\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,095 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:753831.263|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777607\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,095 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:67.822|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777607\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,095 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777607\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,095 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 754\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,095 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777607\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,113 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777607\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,113 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777607113\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,114 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777607\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,119 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,120 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,120 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,802 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.236, [23.71, 230.65, 983.65, 803.16])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,803 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.236 at location [23.71, 230.65, 983.65, 803.16]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,804 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:690.07|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777607,ba54da88-df82-4bfe-88ec-7f30b4636876, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,804 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:690.07|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:ba54da88-df82-4bfe-88ec-7f30b4636876,timestamp:1727777607\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,804 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 692\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,804 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777607\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,804 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:691365.591|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777607\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,804 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:85.222|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777607\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,804 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777607\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,804 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 691\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,804 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777607\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,822 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777607\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,822 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777607822\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,823 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777607\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,827 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,827 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:27,827 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:28,521 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.461, [2.16, 87.97, 499.48, 397.29])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:28,521 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.461 at location [2.16, 87.97, 499.48, 397.29]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:28,526 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:702.96|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777608,cba57409-8976-4513-9d9f-8f8491d7f7cd, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:28,526 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:702.96|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:cba57409-8976-4513-9d9f-8f8491d7f7cd,timestamp:1727777608\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:28,526 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 704\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:28,526 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777608\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:28,526 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:704146.665|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777608\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:28,526 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:90.601|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777608\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:28,526 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777608\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:28,527 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 704\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:28,527 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777608\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:28,548 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777608\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:28,548 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777608548\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:28,550 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777608\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:28,593 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (2560, 2521)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:28,601 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 2521)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:28,601 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:29,344 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.142, [198.83, 170.61, 2465.23, 1464.31])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:29,344 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.142 at location [198.83, 170.61, 2465.23, 1464.31]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:29,345 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:795.66|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777609,02b2a339-7b0e-4527-9a00-2e24b06837d8, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:29,346 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:795.66|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:02b2a339-7b0e-4527-9a00-2e24b06837d8,timestamp:1727777609\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:29,346 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 798\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:29,346 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777609\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:29,346 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:797274.476|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777609\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:29,346 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:101.482|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777609\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:29,346 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777609\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:29,346 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 797\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:29,346 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777609\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:29,364 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777609\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:29,364 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777609364\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:29,365 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777609\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:29,374 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1000, 667)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:29,374 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 667)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:29,374 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,092 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.357, [28.08, 40.34, 959.39, 591.82])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,092 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.357 at location [28.08, 40.34, 959.39, 591.82]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,094 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:728.36|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777610,00496f2c-b117-448e-8287-062a875bdc3b, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,094 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:728.36|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:00496f2c-b117-448e-8287-062a875bdc3b,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,094 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 730\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,094 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,094 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:729548.483|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,094 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:85.322|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,094 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,094 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 730\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,094 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,111 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,112 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777610111\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,112 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,117 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,118 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,118 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,260 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,260 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:2157.037368774414|#Level:Host|#hostname:295673d1428f,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,260 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:3950.7287559509277|#Level:Host|#hostname:295673d1428f,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,260 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:64.7|#Level:Host|#hostname:295673d1428f,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,261 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12950.8828125|#Level:Host|#hostname:295673d1428f,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,261 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:18269.7109375|#Level:Host|#hostname:295673d1428f,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,261 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:59.2|#Level:Host|#hostname:295673d1428f,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,809 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.365, [106.44, 74.93, 877.71, 905.11])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,809 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.365 at location [106.44, 74.93, 877.71, 905.11]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,811 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:698.26|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777610,0ea0016a-79eb-450c-b73b-796eed90ebe6, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,811 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:698.26|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:0ea0016a-79eb-450c-b73b-796eed90ebe6,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,811 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 700\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,811 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,811 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:699383.573|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,811 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:80.831|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,811 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,811 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 699\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,811 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,830 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,830 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777610830\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,831 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777610\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,842 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,846 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:30,846 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:31,579 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.22, [59.4, 277.11, 1484.36, 1375.83])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:31,579 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.22 at location [59.4, 277.11, 1484.36, 1375.83]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:31,580 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:749.47|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777611,7c015a19-0f60-4152-9144-654aeeff9b3f, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:31,580 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:749.47|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:7c015a19-0f60-4152-9144-654aeeff9b3f,timestamp:1727777611\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:31,581 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 751\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:31,581 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777611\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:31,581 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:750796.832|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777611\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:31,581 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:65.801|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777611\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:31,581 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777611\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:31,581 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 750\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:31,581 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777611\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:31,599 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777611\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:31,599 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777611599\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:31,600 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777611\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:31,620 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (1500, 1500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:31,622 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 1500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:31,623 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:32,350 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.3, [146.35, 101.61, 1336.8, 779.55])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:32,350 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.3 at location [146.35, 101.61, 1336.8, 779.55]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:32,351 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:751.13|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777612,da675984-6a2f-4d20-889d-5ec7b104a530, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:32,351 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:751.13|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:da675984-6a2f-4d20-889d-5ec7b104a530,timestamp:1727777612\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:32,352 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 753\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:32,352 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777612\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:32,352 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:752421.804|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777612\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:32,352 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.512|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777612\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:32,352 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777612\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:32,352 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 753\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:32,352 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777612\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:32,369 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777612\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:32,370 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777612370\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:32,370 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777612\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:32,380 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:32,381 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:32,381 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,110 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,112 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:741.38|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777613,a3873404-87dd-42d8-b548-f159e89b858f, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,112 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:741.38|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:a3873404-87dd-42d8-b548-f159e89b858f,timestamp:1727777613\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,112 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 743\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,112 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777613\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,112 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:742582.844|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777613\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,112 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:87.661|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777613\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,112 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777613\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,112 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 742\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,112 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777613\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,131 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777613\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,131 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777613131\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,132 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777613\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,141 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,144 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,144 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,846 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.371, [54.52, 226.74, 1483.86, 1495.43])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,846 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.371 at location [54.52, 226.74, 1483.86, 1495.43]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,847 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:715.42|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777613,67660acf-a6a7-4aa9-8282-74a891f619a0, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,847 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:715.42|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:67660acf-a6a7-4aa9-8282-74a891f619a0,timestamp:1727777613\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,847 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 717\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,847 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777613\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,847 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:716627.125|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777613\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,847 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:80.222|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777613\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,847 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777613\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,848 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 716\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,848 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777613\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,865 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777613\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,865 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777613865\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,866 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777613\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,879 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1200, 1151)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,881 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1200, 1151)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:33,881 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:34,565 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:34,567 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:700.36|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777614,6c2e5588-8a6d-4180-925a-6731f2eb2f95, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:34,567 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:700.36|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:6c2e5588-8a6d-4180-925a-6731f2eb2f95,timestamp:1727777614\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:34,567 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 702\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:34,567 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777614\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:34,567 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:701568.826|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777614\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:34,567 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:78.752|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777614\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:34,567 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777614\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:34,567 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 702\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:34,567 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777614\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:34,584 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777614\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:34,584 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777614584\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:34,585 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777614\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:34,599 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (1600, 1200)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:34,601 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1200)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:34,602 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:35,328 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:35,329 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:744.14|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777615,fa5e353b-718d-4065-a3db-03b6bd2d760a, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:35,329 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:744.14|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:fa5e353b-718d-4065-a3db-03b6bd2d760a,timestamp:1727777615\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:35,329 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 745\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:35,329 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777615\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:35,329 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:745362.667|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777615\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:35,330 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.861|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777615\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:35,330 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777615\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:35,330 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 745\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:35,330 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777615\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:35,348 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777615\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:35,348 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777615348\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:35,349 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777615\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:35,354 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1000, 586)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:35,355 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 586)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:35,355 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,078 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,079 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:730.36|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777616,39b40e3b-7ad4-4821-9c0b-c94ad340fee7, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,079 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:730.36|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:39b40e3b-7ad4-4821-9c0b-c94ad340fee7,timestamp:1727777616\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,079 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 732\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,079 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777616\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,079 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:731569.563|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777616\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,079 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:78.762|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777616\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,079 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777616\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,080 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 731\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,080 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777616\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,097 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777616\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,097 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777616097\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,098 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777616\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,104 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (1200, 1200)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,105 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (1200, 1200)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,106 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,839 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.137, [190.76, 351.93, 1035.75, 889.91])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,839 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.137 at location [190.76, 351.93, 1035.75, 889.91]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,846 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:748.13|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777616,59221456-ace8-49f0-967f-eaa26dcc43a3, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,846 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:748.13|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:59221456-ace8-49f0-967f-eaa26dcc43a3,timestamp:1727777616\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,846 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 750\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,846 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777616\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,846 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:749352.784|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777616\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,846 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:79.021|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777616\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,846 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777616\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,846 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 749\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,846 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777616\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,864 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777616\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,864 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777616864\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,865 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777616\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,873 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,875 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:36,875 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:37,571 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.41, [19.76, 197.14, 988.91, 816.58])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:37,571 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.41 at location [19.76, 197.14, 988.91, 816.58]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:37,572 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:707.1|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777617,fe999058-65e3-417c-8c3b-3c37078a3864, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:37,572 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:707.1|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:fe999058-65e3-417c-8c3b-3c37078a3864,timestamp:1727777617\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:37,572 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 708\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:37,572 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777617\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:37,572 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:708330.326|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777617\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:37,573 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:82.772|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777617\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:37,573 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777617\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:37,573 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 708\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:37,573 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777617\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:37,590 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777617\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:37,590 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777617590\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:37,591 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777617\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:37,595 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:37,595 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:37,595 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,269 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,271 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:679.4|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777618,ee9c6f93-226c-41aa-b2cb-69cc90efbaf5, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,271 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:679.4|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:ee9c6f93-226c-41aa-b2cb-69cc90efbaf5,timestamp:1727777618\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,271 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 681\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,271 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777618\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,271 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:680559.402|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777618\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,271 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:80.922|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777618\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,271 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777618\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,271 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 681\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,271 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777618\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,288 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777618\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,288 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777618288\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,289 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777618\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,291 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,291 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,291 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,962 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,964 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:674.7|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777618,9d8df9b2-4ed8-4b9c-8dbf-96fbd6d27d3e, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,964 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:674.7|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:9d8df9b2-4ed8-4b9c-8dbf-96fbd6d27d3e,timestamp:1727777618\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,964 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 676\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,964 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777618\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,964 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:675838.251|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777618\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,964 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:83.172|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777618\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,964 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777618\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,964 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 676\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,964 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777618\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,982 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777618\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,983 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777618983\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,983 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777618\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,990 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1920, 1080)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,993 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1920, 1080)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:38,993 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:39,696 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a dog', 0.108, [774.68, 53.89, 1100.01, 554.97])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:39,696 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a dog with confidence 0.108 at location [774.68, 53.89, 1100.01, 554.97]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:39,697 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:713.59|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777619,3bb90039-b601-438c-9f51-f5036707e188, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:39,697 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:713.59|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:3bb90039-b601-438c-9f51-f5036707e188,timestamp:1727777619\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:39,697 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 715\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:39,697 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777619\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:39,697 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:714781.08|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777619\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:39,697 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:79.572|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777619\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:39,697 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777619\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:39,698 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 714\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:39,698 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777619\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:39,715 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777619\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:39,716 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777619716\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:39,716 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777619\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:39,731 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1263, 1242)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:39,734 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1263, 1242)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:39,734 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:40,424 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.473, [221.29, 42.68, 1103.06, 592.44])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:40,424 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.473 at location [221.29, 42.68, 1103.06, 592.44]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:40,425 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:708.83|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777620,78e4fa6c-811a-424d-9592-268f13007b14, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:40,425 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:708.83|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:78e4fa6c-811a-424d-9592-268f13007b14,timestamp:1727777620\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:40,426 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 711\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:40,426 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777620\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:40,426 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:710081.039|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777620\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:40,426 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:83.951|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777620\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:40,426 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777620\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:40,426 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 710\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:40,426 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777620\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:40,444 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777620\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:40,444 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777620444\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:40,445 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777620\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:40,459 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:40,463 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:40,463 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,214 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,219 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:774.16|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777621,d43ffe5f-e063-4462-bb51-3da5feb09781, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,219 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:774.16|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:d43ffe5f-e063-4462-bb51-3da5feb09781,timestamp:1727777621\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,219 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 775\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,219 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777621\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,219 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:775451.377|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777621\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,219 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:74.972|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777621\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,220 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777621\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,220 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 775\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,220 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777621\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,237 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777621\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,238 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777621238\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,238 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777621\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,257 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1920, 1080)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,260 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1920, 1080)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,260 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,959 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.395, [424.72, -0.02, 1473.83, 603.42])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,959 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.395 at location [424.72, -0.02, 1473.83, 603.42]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,960 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:721.78|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777621,137b78dd-1e74-422f-9b52-ce40d8f769f0, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,960 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:721.78|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:137b78dd-1e74-422f-9b52-ce40d8f769f0,timestamp:1727777621\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,961 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 724\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,961 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777621\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,961 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:722982.967|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777621\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,961 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:76.841|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777621\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,961 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777621\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,961 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 723\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,961 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777621\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,979 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777621\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,979 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777621979\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,980 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777621\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,981 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (500, 375)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,982 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 375)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:41,982 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:42,654 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:42,655 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:675.62|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777622,f65efe95-c730-4994-8ee8-31e8c552b130, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:42,655 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:675.62|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:f65efe95-c730-4994-8ee8-31e8c552b130,timestamp:1727777622\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:42,656 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 677\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:42,656 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777622\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:42,656 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:676771.669|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777622\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:42,656 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:80.982|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777622\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:42,656 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777622\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:42,656 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 676\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:42,656 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777622\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:42,674 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777622\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:42,674 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777622674\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:42,675 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777622\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:42,675 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (300, 300)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:42,676 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (300, 300)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:42,676 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:43,374 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.159, [0.74, 81.23, 299.47, 222.11])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:43,374 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.159 at location [0.74, 81.23, 299.47, 222.11]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:43,375 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:700.81|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777623,0bf0bae1-762d-4f84-9981-26d61188bbc7, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:43,376 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:700.81|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:0bf0bae1-762d-4f84-9981-26d61188bbc7,timestamp:1727777623\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:43,376 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 702\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:43,376 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777623\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:43,376 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:702017.014|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777623\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:43,376 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:95.432|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777623\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:43,376 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777623\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:43,376 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 702\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:43,376 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777623\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:43,393 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777623\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:43,394 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777623394\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:43,394 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777623\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:43,400 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:43,402 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:43,402 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:44,397 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.462, [5.57, 104.7, 995.68, 733.64])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:44,397 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.462 at location [5.57, 104.7, 995.68, 733.64]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:44,399 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1003.98|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777624,72901c98-cb84-43fb-95d0-4c2689f2649e, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:44,399 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:1003.98|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:72901c98-cb84-43fb-95d0-4c2689f2649e,timestamp:1727777624\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:44,399 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 1006\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:44,399 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777624\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:44,399 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1005439.519|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777624\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:44,399 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:78.831|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777624\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:44,399 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777624\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:44,399 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1005\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:44,400 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777624\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:44,418 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777624\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:44,419 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777624419\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:44,420 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777624\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:44,433 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1500, 1500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:44,436 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 1500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:44,436 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:45,297 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.595, [5.08, -2.26, 1479.95, 980.23])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:45,297 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.595 at location [5.08, -2.26, 1479.95, 980.23]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:45,303 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:883.03|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777625,65b0a0bd-fc9e-43cc-8757-4c67afdb7cd5, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:45,303 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:883.03|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:65b0a0bd-fc9e-43cc-8757-4c67afdb7cd5,timestamp:1727777625\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:45,303 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 885\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:45,303 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777625\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:45,303 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:884531.121|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777625\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:45,303 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:68.251|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777625\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:45,303 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777625\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:45,303 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 884\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:45,303 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777625\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:45,324 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777625\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:45,324 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777625324\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:45,325 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777625\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:45,350 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1764, 1390)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:45,354 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1764, 1390)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:45,354 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:46,121 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.409, [256.62, 86.77, 1544.77, 873.97])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:46,121 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.409 at location [256.62, 86.77, 1544.77, 873.97]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:46,122 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:797.24|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777626,ffa5d983-c367-48ee-b534-042fa5b66535, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:46,122 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:797.24|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:ffa5d983-c367-48ee-b534-042fa5b66535,timestamp:1727777626\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:46,123 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 800\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:46,123 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777626\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:46,123 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:798821.033|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777626\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:46,123 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:76.142|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777626\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:46,123 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777626\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:46,123 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 798\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:46,123 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777626\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:46,142 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777626\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:46,142 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777626142\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:46,143 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777626\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:46,170 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (2440, 2560)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:46,178 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (2440, 2560)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:46,178 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,019 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.198, [77.34, 102.57, 2331.01, 1434.75]), ('a photo of a tv', 0.31, [1009.61, 1514.11, 1509.48, 2162.64])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,019 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.198 at location [77.34, 102.57, 2331.01, 1434.75]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,019 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.31 at location [1009.61, 1514.11, 1509.48, 2162.64]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,020 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:876.87|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777627,b71b911f-0fe0-4018-a8a3-e1a50d9e734c, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,020 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:876.87|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:b71b911f-0fe0-4018-a8a3-e1a50d9e734c,timestamp:1727777627\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,021 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 879\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,021 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777627\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,021 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:878361.963|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777627\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,021 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:89.572|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777627\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,021 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777627\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,021 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 879\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,021 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777627\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,038 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777627\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,038 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777627038\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,039 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777627\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,042 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,043 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,043 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,774 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.621, [12.62, 354.69, 488.59, 638.06]), ('a photo of a tv', 0.112, [21.17, 362.05, 480.11, 626.78])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,774 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.621 at location [12.62, 354.69, 488.59, 638.06]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,774 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.112 at location [21.17, 362.05, 480.11, 626.78]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,775 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:736.62|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777627,bc011524-2bca-400a-a06f-2338d338c00b, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,775 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:736.62|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:bc011524-2bca-400a-a06f-2338d338c00b,timestamp:1727777627\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,776 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 738\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,776 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777627\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,776 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:737952.823|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777627\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,776 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:94.322|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777627\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,776 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777627\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,776 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 738\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,776 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777627\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,794 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777627\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,794 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777627794\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,795 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777627\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,800 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (800, 800)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,801 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (800, 800)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:47,801 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:48,485 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.497, [42.76, 168.83, 758.64, 622.75])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:48,485 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.497 at location [42.76, 168.83, 758.64, 622.75]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:48,487 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:692.03|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777628,23fadc5f-b478-4584-b2a8-587b7a3129b5, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:48,487 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:692.03|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:23fadc5f-b478-4584-b2a8-587b7a3129b5,timestamp:1727777628\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:48,487 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 694\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:48,487 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777628\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:48,487 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:693211.121|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777628\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:48,488 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:69.521|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777628\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:48,488 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777628\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:48,488 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 693\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:48,488 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777628\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:48,505 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777628\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:48,506 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777628505\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:48,506 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777628\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:48,516 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:48,518 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:48,518 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,241 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.487, [18.19, 216.46, 790.47, 740.34])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,241 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.487 at location [18.19, 216.46, 790.47, 740.34]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,242 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:735.71|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777629,5a9b4713-e199-4e49-bd00-ee9794c58f6b, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,242 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:735.71|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:5a9b4713-e199-4e49-bd00-ee9794c58f6b,timestamp:1727777629\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,242 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 737\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,242 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777629\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,243 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:736940.753|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777629\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,243 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:77.291|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777629\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,243 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777629\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,243 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 736\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,243 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777629\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,259 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777629\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,260 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777629260\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,260 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777629\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,268 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,270 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,270 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,958 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.377, [0.67, 337.24, 506.2, 647.93])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,958 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.377 at location [0.67, 337.24, 506.2, 647.93]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,959 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:698.92|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777629,9b4d1244-3934-4aa6-9e11-0c6e128a66e4, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,960 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:698.92|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:9b4d1244-3934-4aa6-9e11-0c6e128a66e4,timestamp:1727777629\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,960 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 701\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,960 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777629\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,960 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:700050.953|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777629\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,960 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.211|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777629\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,960 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777629\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,960 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 700\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,960 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777629\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,977 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777629\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,977 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777629977\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,978 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777629\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,995 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,998 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:49,998 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:50,691 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:50,692 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:713.9|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777630,048095b2-e859-4f76-a6b2-116afd294583, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:50,692 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:713.9|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:048095b2-e859-4f76-a6b2-116afd294583,timestamp:1727777630\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:50,692 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 715\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:50,692 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777630\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:50,693 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:715049.873|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777630\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:50,693 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:82.152|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777630\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:50,693 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777630\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:50,693 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 715\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:50,693 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777630\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:50,710 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777630\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:50,710 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777630710\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:50,711 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777630\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:50,716 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1024, 1024)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:50,718 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1024, 1024)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:50,718 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:51,425 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.648, [50.47, 254.94, 958.64, 838.39])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:51,425 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.648 at location [50.47, 254.94, 958.64, 838.39]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:51,435 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:723.96|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777631,5fcd21a7-db64-4ef2-a61a-38c574912a5b, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:51,435 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:723.96|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:5fcd21a7-db64-4ef2-a61a-38c574912a5b,timestamp:1727777631\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:51,436 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 726\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:51,436 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777631\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:51,436 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:725229.588|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777631\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:51,436 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:79.222|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777631\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:51,436 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777631\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:51,436 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 725\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:51,436 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777631\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:51,453 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777631\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:51,454 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777631454\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:51,454 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777631\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:51,458 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (800, 800)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:51,459 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (800, 800)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:51,459 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,153 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,155 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:700.3|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777632,75e15b87-655f-47f5-bfce-1c4e7e8750d4, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,155 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:700.3|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:75e15b87-655f-47f5-bfce-1c4e7e8750d4,timestamp:1727777632\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,155 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 702\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,155 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777632\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,155 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:701478.211|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777632\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,155 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:82.392|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777632\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,155 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777632\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,155 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 701\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,155 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777632\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,173 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777632\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,173 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777632173\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,173 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777632\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,181 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,182 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,182 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,857 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.542, [25.1, 211.09, 955.67, 797.99])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,857 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.542 at location [25.1, 211.09, 955.67, 797.99]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,858 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:684.79|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777632,935863d3-587b-4ff2-a0c8-349f20e2f5ac, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,858 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:684.79|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:935863d3-587b-4ff2-a0c8-349f20e2f5ac,timestamp:1727777632\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,859 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 687\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,859 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777632\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,859 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:685944.512|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777632\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,859 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.151|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777632\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,859 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777632\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,859 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 686\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,859 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777632\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,877 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777632\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,877 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777632877\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,878 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777632\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,884 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (1000, 711)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,885 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 711)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:52,885 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:53,576 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:53,577 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:699.27|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777633,12956ed7-cc04-4347-80ad-3b74e1a5ebcc, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:53,577 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:699.27|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:12956ed7-cc04-4347-80ad-3b74e1a5ebcc,timestamp:1727777633\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:53,577 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 700\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:53,577 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777633\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:53,578 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:700548.313|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777633\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:53,578 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:79.861|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777633\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:53,578 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777633\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:53,578 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 700\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:53,578 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777633\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:53,595 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777633\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:53,595 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777633595\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:53,596 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777633\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:53,609 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1500, 951)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:53,611 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 951)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:53,611 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:54,333 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.258, [17.02, 10.59, 1509.16, 895.44])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:54,333 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.258 at location [17.02, 10.59, 1509.16, 895.44]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:54,335 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:738.58|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777634,a8c28db2-20ab-4a5b-bb49-9db775d9cee0, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:54,335 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:738.58|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:a8c28db2-20ab-4a5b-bb49-9db775d9cee0,timestamp:1727777634\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:54,335 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 740\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:54,335 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777634\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:54,335 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:739753.738|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777634\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:54,335 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:84.412|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777634\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:54,335 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777634\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:54,335 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 740\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:54,335 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777634\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:54,353 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777634\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:54,353 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777634353\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:54,354 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777634\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:54,358 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:54,360 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:54,360 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,060 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,065 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:710.99|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777635,4a66ab73-9ab6-4e74-81a5-03ea4519700e, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,065 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:710.99|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:4a66ab73-9ab6-4e74-81a5-03ea4519700e,timestamp:1727777635\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,065 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 712\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,065 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777635\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,065 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:712170.688|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777635\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,065 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:79.762|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777635\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,065 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777635\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,065 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 712\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,065 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777635\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,083 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777635\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,083 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777635083\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,084 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777635\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,096 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,097 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,097 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,780 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,782 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:697.55|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777635,4670fb7a-83d5-4ca3-bf64-5e9764c8e617, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,782 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:697.55|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:4670fb7a-83d5-4ca3-bf64-5e9764c8e617,timestamp:1727777635\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,782 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 699\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,782 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777635\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,782 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:698759.289|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777635\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,782 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:82.681|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777635\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,782 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777635\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,782 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 699\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,782 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777635\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,800 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777635\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,800 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777635800\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,801 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777635\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,809 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (1000, 925)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,810 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 925)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:55,810 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:56,520 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.471, [28.19, 8.09, 985.64, 567.61]), ('a photo of a tv', 0.325, [3.11, 579.06, 252.14, 890.2])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:56,520 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.471 at location [28.19, 8.09, 985.64, 567.61]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:56,520 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.325 at location [3.11, 579.06, 252.14, 890.2]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:56,521 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:720.29|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777636,5be7e94f-b32f-49a8-9965-b147b34cd50c, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:56,522 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:720.29|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:5be7e94f-b32f-49a8-9965-b147b34cd50c,timestamp:1727777636\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:56,522 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 722\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:56,522 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777636\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:56,522 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:721491.856|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777636\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:56,522 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:69.231|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777636\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:56,522 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777636\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:56,522 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 722\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:56,522 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777636\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:56,539 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777636\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:56,539 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777636539\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:56,540 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777636\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:56,544 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:56,546 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:56,546 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,232 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.623, [32.86, 223.03, 947.48, 806.92])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,232 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.623 at location [32.86, 223.03, 947.48, 806.92]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,240 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:700.1|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777637,bf8ef777-ed62-4190-b06a-d9f776919423, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,240 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:700.1|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:bf8ef777-ed62-4190-b06a-d9f776919423,timestamp:1727777637\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,240 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 701\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,240 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777637\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,241 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:701360.059|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777637\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,241 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:82.382|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777637\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,241 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777637\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,241 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 701\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,241 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777637\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,258 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777637\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,258 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777637258\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,259 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777637\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,262 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,262 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,262 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,980 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,985 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:726.01|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777637,32f6e6e6-64bc-41bb-845c-c4f23b860928, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,985 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:726.01|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:32f6e6e6-64bc-41bb-845c-c4f23b860928,timestamp:1727777637\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,985 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 727\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,985 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777637\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,985 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:727193.405|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777637\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,986 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.051|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777637\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,986 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777637\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,986 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 727\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:57,986 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777637\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,003 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777638\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,003 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777638003\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,004 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777638\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,009 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1024, 1024)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,010 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1024, 1024)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,010 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,707 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.556, [38.94, 235.41, 982.17, 822.94])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,707 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.556 at location [38.94, 235.41, 982.17, 822.94]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,709 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:704.57|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777638,ebfaf5aa-7910-4c8f-896a-8ef6a5699b6b, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,709 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:704.57|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:ebfaf5aa-7910-4c8f-896a-8ef6a5699b6b,timestamp:1727777638\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,709 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 706\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,709 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777638\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,709 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:705708.433|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777638\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,709 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:86.352|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777638\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,709 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777638\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,709 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 706\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,709 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777638\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,727 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777638\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,727 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777638727\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,728 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777638\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,743 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,747 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:58,747 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:59,448 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:59,453 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:725.15|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777639,cfe85b34-6e10-4aa5-a2d9-d44463fcc3df, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:59,453 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:725.15|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:cfe85b34-6e10-4aa5-a2d9-d44463fcc3df,timestamp:1727777639\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:59,454 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 727\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:59,454 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777639\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:59,454 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:726439.992|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777639\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:59,454 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:77.602|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777639\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:59,454 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777639\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:59,454 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 726\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:59,454 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777639\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:59,471 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777639\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:59,471 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777639471\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:59,472 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777639\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:59,502 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (2560, 1938)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:59,508 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1938)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:13:59,508 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,242 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.262, [485.79, 296.56, 2059.97, 1215.47]), ('a photo of a tv', 0.106, [1097.2, 1181.33, 1455.07, 1279.13])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,242 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.262 at location [485.79, 296.56, 2059.97, 1215.47]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,242 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.106 at location [1097.2, 1181.33, 1455.07, 1279.13]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,243 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:771.28|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777640,d85a51df-58d4-4e2e-b2cf-336b0d06f595, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,243 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:771.28|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:d85a51df-58d4-4e2e-b2cf-336b0d06f595,timestamp:1727777640\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,244 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 773\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,244 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777640\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,244 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:772575.679|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777640\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,244 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.802|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777640\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,244 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777640\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,244 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 773\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,244 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777640\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,262 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777640\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,262 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777640262\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,263 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777640\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,272 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (1500, 1500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,275 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 1500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,275 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,985 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.43, [71.23, 333.76, 1457.08, 1191.44])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,985 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.43 at location [71.23, 333.76, 1457.08, 1191.44]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,990 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:727.56|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777640,29c6db9a-93c7-4fe8-9af3-3099966936a5, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,990 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:727.56|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:29c6db9a-93c7-4fe8-9af3-3099966936a5,timestamp:1727777640\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,991 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 730\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,991 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777640\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,991 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:728820.049|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777640\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,991 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.242|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777640\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,991 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777640\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,991 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 728\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:00,991 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777640\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,008 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777641\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,008 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777641008\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,009 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777641\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,014 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (1067, 800)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,015 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (1067, 800)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,015 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,737 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.238, [629.72, 210.68, 1038.89, 512.78])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,737 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.238 at location [629.72, 210.68, 1038.89, 512.78]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,738 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:729.47|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777641,9753b40c-a846-4f24-a700-3abe988a9a1c, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,738 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:729.47|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:9753b40c-a846-4f24-a700-3abe988a9a1c,timestamp:1727777641\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,739 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 731\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,739 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777641\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,739 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:730655.864|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777641\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,739 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:80.022|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777641\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,739 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777641\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,739 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 730\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,739 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777641\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,756 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777641\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,757 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777641757\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,757 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777641\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,772 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (1180, 1269)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,774 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (1180, 1269)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:01,774 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:02,505 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.484, [26.51, 38.39, 1142.57, 700.7]), ('a photo of a tv', 0.115, [450.36, 661.27, 717.66, 728.22]), ('a photo of a tv', 0.151, [481.55, 760.41, 680.13, 1127.94])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:02,505 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.484 at location [26.51, 38.39, 1142.57, 700.7]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:02,505 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.115 at location [450.36, 661.27, 717.66, 728.22]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:02,505 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.151 at location [481.55, 760.41, 680.13, 1127.94]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:02,506 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:748.66|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777642,6be3af71-ad23-4bac-a5c3-1b549aead36f, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:02,506 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:748.66|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:6be3af71-ad23-4bac-a5c3-1b549aead36f,timestamp:1727777642\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:02,506 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 750\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:02,506 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777642\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:02,507 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:749954.885|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777642\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:02,507 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:86.601|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777642\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:02,507 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777642\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:02,507 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 749\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:02,507 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777642\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:02,524 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777642\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:02,525 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777642525\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:02,525 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777642\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:02,535 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:02,536 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:02,536 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:03,222 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.292, [9.34, 104.99, 1000.63, 683.06]), ('a photo of a tv', 0.153, [1.54, 55.78, 998.41, 984.89])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:03,222 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.292 at location [9.34, 104.99, 1000.63, 683.06]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:03,222 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.153 at location [1.54, 55.78, 998.41, 984.89]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:03,223 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:697.88|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777643,e0218e22-662d-4f06-954f-4010678ce497, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:03,223 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:697.88|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:e0218e22-662d-4f06-954f-4010678ce497,timestamp:1727777643\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:03,224 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 700\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:03,224 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777643\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:03,224 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:699196.559|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777643\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:03,224 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:126.303|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777643\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:03,224 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777643\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:03,224 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 699\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:03,224 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777643\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:03,242 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777643\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:03,242 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777643242\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:03,243 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777643\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:03,253 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:03,257 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:03,257 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,001 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.196, [7.88, 346.95, 1584.16, 1326.18])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,001 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.196 at location [7.88, 346.95, 1584.16, 1326.18]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,002 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:759.32|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777644,87fccc74-7a1b-4aef-9ad6-8c24fb071577, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,002 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:759.32|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:87fccc74-7a1b-4aef-9ad6-8c24fb071577,timestamp:1727777644\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,003 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 761\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,003 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777644\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,003 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:760672.581|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777644\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,003 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:80.152|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777644\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,003 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777644\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,003 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 761\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,003 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777644\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,021 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777644\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,021 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777644021\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,022 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777644\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,046 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1500, 1500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,049 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 1500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,049 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,776 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,777 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:755.26|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777644,0a2e4f0c-d575-478c-b245-25b7f4a9dbea, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,778 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:755.26|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:0a2e4f0c-d575-478c-b245-25b7f4a9dbea,timestamp:1727777644\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,778 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 757\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,778 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777644\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,778 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:756521.952|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777644\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,778 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:74.922|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777644\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,778 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777644\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,778 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 757\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,778 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777644\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,798 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777644\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,798 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777644798\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,799 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777644\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,829 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (2560, 2560)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,837 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 2560)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:04,837 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:05,584 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.408, [84.33, 533.45, 2463.1, 1987.2])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:05,584 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.408 at location [84.33, 533.45, 2463.1, 1987.2]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:05,588 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:788.83|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777645,ce7d674a-a569-4e9f-8296-ac4fa942944f, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:05,589 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:788.83|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:ce7d674a-a569-4e9f-8296-ac4fa942944f,timestamp:1727777645\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:05,589 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 791\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:05,589 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777645\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:05,589 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:790476.595|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777645\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:05,589 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:123.602|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777645\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:05,589 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777645\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:05,589 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 791\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:05,589 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777645\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:05,606 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777645\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:05,606 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777645606\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:05,607 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777645\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:05,613 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:05,614 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:05,614 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:06,337 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:06,338 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:730.73|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777646,87d89a92-1cb0-4ed5-8bce-162f41e4aa20, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:06,338 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:730.73|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:87d89a92-1cb0-4ed5-8bce-162f41e4aa20,timestamp:1727777646\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:06,338 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 732\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:06,338 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777646\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:06,338 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:731952.668|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777646\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:06,339 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:86.981|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777646\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:06,339 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777646\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:06,339 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 732\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:06,339 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777646\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:06,355 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777646\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:06,355 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777646355\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:06,356 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777646\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:06,365 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:06,366 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:06,366 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,092 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,093 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:736.9|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777647,09a599d8-e06b-479b-b205-1c4dffa8db33, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,093 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:736.9|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:09a599d8-e06b-479b-b205-1c4dffa8db33,timestamp:1727777647\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,093 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 738\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,093 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777647\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,094 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:738041.746|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777647\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,094 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:79.102|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777647\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,094 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777647\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,094 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 738\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,094 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777647\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,111 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777647\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,111 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777647111\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,112 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777647\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,134 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (1602, 1602)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,138 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (1602, 1602)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,138 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,829 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.36, [69.08, 396.98, 1527.08, 1245.99])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,829 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.36 at location [69.08, 396.98, 1527.08, 1245.99]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,831 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:718.69|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777647,2434e3b2-7b02-4cad-b301-4b4145000707, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,831 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:718.69|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:2434e3b2-7b02-4cad-b301-4b4145000707,timestamp:1727777647\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,831 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 720\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,831 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777647\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,831 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:719975.439|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777647\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,831 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:82.022|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777647\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,831 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777647\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,831 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 720\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,831 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777647\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,849 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777647\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,849 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777647849\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,850 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777647\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,854 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (800, 800)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,855 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (800, 800)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:07,855 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:08,530 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:08,531 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:681.67|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777648,68c9c695-845c-47f0-9f16-7b30516ce37b, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:08,532 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:681.67|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:68c9c695-845c-47f0-9f16-7b30516ce37b,timestamp:1727777648\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:08,532 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 683\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:08,532 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777648\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:08,532 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:682837.024|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777648\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:08,532 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:69.971|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777648\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:08,532 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777648\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:08,532 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 683\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:08,532 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777648\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:08,549 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777648\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:08,549 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777648549\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:08,550 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777648\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:08,570 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (2000, 2000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:08,575 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (2000, 2000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:08,575 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:09,300 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.571, [10.63, 316.9, 2003.36, 1679.75])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:09,300 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.571 at location [10.63, 316.9, 2003.36, 1679.75]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:09,305 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:755.2|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777649,922eba2d-6d9e-4e00-978b-6275fb7ea2b7, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:09,305 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:755.2|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:922eba2d-6d9e-4e00-978b-6275fb7ea2b7,timestamp:1727777649\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:09,305 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 756\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:09,305 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777649\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:09,305 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:756320.247|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777649\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:09,305 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:82.451|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777649\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:09,305 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777649\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:09,306 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 756\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:09,306 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777649\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:09,322 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777649\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:09,323 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777649322\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:09,323 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777649\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:09,326 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:09,327 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:09,327 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,000 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,001 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:677.61|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777650,7fb07abb-e545-47ed-9628-f826c1680aa3, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,001 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:677.61|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:7fb07abb-e545-47ed-9628-f826c1680aa3,timestamp:1727777650\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,001 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 679\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,001 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777650\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,001 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:678803.757|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777650\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,001 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:79.182|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777650\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,001 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777650\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,001 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 678\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,002 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777650\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,019 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777650\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,019 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777650019\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,020 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777650\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,056 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (2560, 1707)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,061 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (2560, 1707)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,061 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,812 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.168, [120.47, 124.63, 2479.86, 1498.4])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,812 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.168 at location [120.47, 124.63, 2479.86, 1498.4]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,813 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:793.09|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777650,cd17eb35-13e3-4a9d-a573-67803518aabb, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,813 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:793.09|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:cd17eb35-13e3-4a9d-a573-67803518aabb,timestamp:1727777650\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,813 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 794\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,813 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777650\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,814 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:794439.99|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777650\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,814 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:83.191|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777650\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,814 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777650\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,814 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 794\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,814 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777650\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,833 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777650\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,833 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777650833\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,834 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777650\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,886 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (2500, 2560)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,894 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (2500, 2560)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:10,894 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:11,648 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.493, [121.58, 140.79, 2389.28, 1500.09])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:11,648 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.493 at location [121.58, 140.79, 2389.28, 1500.09]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:11,650 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:815.03|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777651,046d831b-7820-4cf5-bb0f-bf74291f4600, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:11,650 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:815.03|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:046d831b-7820-4cf5-bb0f-bf74291f4600,timestamp:1727777651\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:11,650 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 817\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:11,650 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777651\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:11,650 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:816834.682|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777651\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:11,650 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:112.152|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777651\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:11,650 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777651\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:11,650 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 817\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:11,650 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777651\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:11,667 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777651\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:11,667 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777651667\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:11,668 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777651\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:11,681 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1500, 951)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:11,683 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 951)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:11,683 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:12,366 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.258, [17.02, 10.59, 1509.16, 895.44])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:12,366 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.258 at location [17.02, 10.59, 1509.16, 895.44]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:12,368 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:699.36|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777652,6690fe60-3b3a-4a59-8bf9-03c3aa8cbadf, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:12,368 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:699.36|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:6690fe60-3b3a-4a59-8bf9-03c3aa8cbadf,timestamp:1727777652\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:12,368 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 701\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:12,368 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777652\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:12,368 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:700716.448|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777652\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:12,368 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:143.683|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777652\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:12,368 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777652\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:12,368 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 700\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:12,368 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777652\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:12,386 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777652\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:12,386 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777652386\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:12,387 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777652\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:12,398 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:12,401 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:12,402 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,106 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.263, [59.14, 347.57, 1533.67, 1251.82]), ('a photo of a tv', 0.125, [54.61, 363.85, 1550.45, 1341.9])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,106 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.263 at location [59.14, 347.57, 1533.67, 1251.82]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,106 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.125 at location [54.61, 363.85, 1550.45, 1341.9]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,108 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:720.83|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777653,6a2c32a0-5b22-4e42-8a46-09d5e4e012f5, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,108 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:720.83|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:6a2c32a0-5b22-4e42-8a46-09d5e4e012f5,timestamp:1727777653\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,108 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 722\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,108 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777653\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,108 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:722264.512|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777653\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,108 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:89.722|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777653\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,108 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777653\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,109 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 722\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,109 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777653\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,126 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777653\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,126 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777653126\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,127 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777653\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,144 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (1500, 1009)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,146 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 1009)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,146 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,832 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.137, [18.09, -4.86, 1511.74, 991.96])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,832 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.137 at location [18.09, -4.86, 1511.74, 991.96]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,834 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:706.38|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777653,4c9f4f17-1f5f-4657-b661-cc830c0e555e, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,834 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:706.38|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:4c9f4f17-1f5f-4657-b661-cc830c0e555e,timestamp:1727777653\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,834 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 708\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,834 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777653\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,834 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:707554.28|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777653\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,834 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:72.731|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777653\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,834 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777653\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,834 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 708\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,834 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777653\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,850 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777653\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,851 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777653851\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,851 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777653\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,854 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,855 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:13,855 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:14,548 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:14,549 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:697.66|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777654,c5c1a05c-3038-4208-b6f4-e1560bd0c05d, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:14,549 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:697.66|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:c5c1a05c-3038-4208-b6f4-e1560bd0c05d,timestamp:1727777654\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:14,550 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 700\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:14,550 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777654\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:14,550 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:698776.032|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777654\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:14,550 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:75.522|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777654\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:14,550 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777654\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:14,550 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 698\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:14,550 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777654\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:14,567 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777654\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:14,567 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777654567\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:14,568 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777654\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:14,569 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:14,570 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (500, 500)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:14,570 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:15,241 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.403, [42.61, 131.83, 460.11, 395.16])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:15,241 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.403 at location [42.61, 131.83, 460.11, 395.16]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:15,242 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:674.3|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777655,fce9d149-2542-4a3e-8c57-20f1a3d35593, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:15,242 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:674.3|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:fce9d149-2542-4a3e-8c57-20f1a3d35593,timestamp:1727777655\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:15,243 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 676\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:15,243 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777655\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:15,243 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:675546.334|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777655\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:15,243 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:67.881|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777655\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:15,243 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777655\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:15,243 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 675\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:15,243 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777655\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:15,261 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777655\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:15,262 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777655262\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:15,263 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777655\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:15,324 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (2445, 2560)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:15,332 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (2445, 2560)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:15,332 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,068 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.301, [118.08, 135.76, 2330.99, 1412.29])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,068 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.301 at location [118.08, 135.76, 2330.99, 1412.29]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,069 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:806.66|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777656,0bed732d-053d-4a2e-a7ad-7e217597cf10, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,069 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:806.66|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:0bed732d-053d-4a2e-a7ad-7e217597cf10,timestamp:1727777656\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,070 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 809\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,070 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777656\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,070 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:808136.754|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777656\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,070 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:79.612|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777656\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,070 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777656\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,070 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 808\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,070 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777656\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,087 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777656\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,087 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777656087\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,088 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777656\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,095 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,096 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,096 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,776 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.512, [54.11, 225.53, 934.67, 780.64])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,776 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.512 at location [54.11, 225.53, 934.67, 780.64]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,778 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:689.93|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777656,054bf747-1ef9-4244-9b08-c1acf6644b59, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,778 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:689.93|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:054bf747-1ef9-4244-9b08-c1acf6644b59,timestamp:1727777656\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,778 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 691\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,778 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777656\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,778 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:691058.683|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777656\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,778 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:62.221|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777656\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,778 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777656\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,778 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 691\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,778 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777656\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,796 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777656\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,796 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777656796\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,797 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777656\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,821 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (2115, 1522)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,825 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (2115, 1522)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:16,825 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:17,588 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.436, [297.41, 116.67, 1806.35, 1003.06])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:17,588 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.436 at location [297.41, 116.67, 1806.35, 1003.06]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:17,590 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:791.99|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777657,b0fe60d8-37a1-4f5d-a323-65e4cdea3662, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:17,590 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:791.99|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:b0fe60d8-37a1-4f5d-a323-65e4cdea3662,timestamp:1727777657\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:17,590 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 794\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:17,590 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777657\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:17,590 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:793597.106|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777657\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:17,590 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:70.271|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777657\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:17,590 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777657\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:17,591 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 793\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:17,591 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777657\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:17,608 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777657\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:17,608 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777657608\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:17,609 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777657\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:17,613 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (600, 450)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:17,613 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (600, 450)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:17,613 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:18,459 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:18,464 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:854.68|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777658,d156d468-a66c-4397-8f44-53e985bc4515, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:18,464 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:854.68|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:d156d468-a66c-4397-8f44-53e985bc4515,timestamp:1727777658\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:18,464 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 856\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:18,464 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777658\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:18,464 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:855958.666|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777658\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:18,464 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:99.662|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777658\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:18,464 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777658\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:18,464 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 856\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:18,464 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777658\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:18,483 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777658\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:18,483 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777658483\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:18,484 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777658\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:18,534 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (2048, 2560)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:18,541 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (2048, 2560)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:18,541 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:19,308 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: []\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:19,310 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:825.79|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777659,e8bb89fc-50e9-484d-8535-7e36437b6e1b, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:19,310 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:825.79|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:e8bb89fc-50e9-484d-8535-7e36437b6e1b,timestamp:1727777659\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:19,310 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 827\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:19,310 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777659\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:19,312 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:827182.773|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777659\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:19,312 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:72.592|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777659\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:19,312 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777659\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:19,312 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 827\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:19,312 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777659\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:19,329 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777659\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:19,329 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777659329\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:19,330 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777659\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:19,341 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:19,345 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:19,345 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,081 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.51, [58.24, 363.17, 1582.79, 1252.01])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,081 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.51 at location [58.24, 363.17, 1582.79, 1252.01]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,089 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:759.01|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777660,78177de3-1789-4465-8fd3-d503ffe13d86, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,090 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:759.01|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:78177de3-1789-4465-8fd3-d503ffe13d86,timestamp:1727777660\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,090 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 761\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,090 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777660\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,090 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:760210.214|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777660\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,090 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:69.201|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777660\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,090 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777660\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,090 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 760\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,090 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777660\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,107 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777660\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,107 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777660107\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,108 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777660\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,109 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (355, 355)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,110 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (355, 355)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,110 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,782 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.405, [31.04, 82.34, 323.36, 260.4])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,782 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.405 at location [31.04, 82.34, 323.36, 260.4]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,784 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:675.32|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777660,b6641b23-bb91-45a9-90a5-947b835659f1, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,784 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:675.32|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:b6641b23-bb91-45a9-90a5-947b835659f1,timestamp:1727777660\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,784 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 677\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,784 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777660\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,784 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:676433.423|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777660\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,784 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:73.062|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777660\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,784 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777660\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,784 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 676\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,784 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777660\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,803 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777660\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,803 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777660803\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,804 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777660\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,819 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1200, 1200)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,821 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1200, 1200)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:20,821 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:21,520 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.338, [123.69, 115.55, 1093.3, 660.16])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:21,520 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.338 at location [123.69, 115.55, 1093.3, 660.16]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:21,522 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:717.58|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777661,8ba4f88a-62a5-4406-8ab0-4fd6caa225d9, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:21,522 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:717.58|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:8ba4f88a-62a5-4406-8ab0-4fd6caa225d9,timestamp:1727777661\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:21,522 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 719\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:21,522 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777661\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:21,522 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:718779.087|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777661\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:21,522 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:59.521|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777661\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:21,522 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777661\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:21,522 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 719\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:21,522 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777661\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:21,540 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777661\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:21,540 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777661540\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:21,541 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777661\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:21,548 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1024, 1024)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:21,549 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1024, 1024)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:21,549 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,235 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.192, [30.32, 104.0, 960.8, 913.7])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,235 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.192 at location [30.32, 104.0, 960.8, 913.7]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,237 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:696.02|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777662,7b4ea57a-9b3a-464d-81a5-8745642ff4d8, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,237 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:696.02|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:7b4ea57a-9b3a-464d-81a5-8745642ff4d8,timestamp:1727777662\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,237 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 697\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,237 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777662\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,237 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:697185.772|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777662\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,237 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:59.181|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777662\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,237 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777662\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,237 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 697\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,237 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777662\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,255 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777662\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,255 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777662255\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,256 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777662\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,264 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Image size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,265 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Processing image of size: (1001, 1001)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,265 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,944 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.341, [23.25, 355.15, 477.96, 628.33]), ('a photo of a tv', 0.373, [17.97, 358.35, 481.88, 634.66])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,944 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.341 at location [23.25, 355.15, 477.96, 628.33]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,944 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.373 at location [17.97, 358.35, 481.88, 634.66]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,945 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:688.98|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777662,220efe85-540d-44a4-9e45-c5b5e2660c2a, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,945 [INFO ] W-9002-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:688.98|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:220efe85-540d-44a4-9e45-c5b5e2660c2a,timestamp:1727777662\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,946 [INFO ] W-9002-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 691\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,946 [INFO ] W-9002-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777662\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,946 [INFO ] W-9002-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:690458.902|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777662\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,946 [INFO ] W-9002-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:103.002|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777662\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,946 [INFO ] W-9002-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777662\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,946 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 690\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,946 [INFO ] W-9002-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777662\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,964 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777662\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,965 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777662964\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,965 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777662\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,975 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Image size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,979 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Processing image of size: (1600, 1600)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:22,979 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:23,692 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.22, [59.4, 277.11, 1484.36, 1375.83])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:23,693 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.22 at location [59.4, 277.11, 1484.36, 1375.83]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:23,697 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:731.38|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777663,df791dbc-c2c7-4fb8-a0c6-988366c59385, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:23,697 [INFO ] W-9005-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:731.38|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:df791dbc-c2c7-4fb8-a0c6-988366c59385,timestamp:1727777663\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:23,697 [INFO ] W-9005-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 733\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:23,697 [INFO ] W-9005-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777663\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:23,697 [INFO ] W-9005-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:732573.013|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777663\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:23,697 [INFO ] W-9005-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:78.852|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777663\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:23,697 [INFO ] W-9005-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777663\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:23,697 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 732\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:23,697 [INFO ] W-9005-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777663\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:23,714 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777663\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:23,715 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777663715\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:23,715 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777663\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:23,728 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Image size: (1500, 951)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:23,730 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 951)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:23,730 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:24,425 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.258, [17.02, 10.59, 1509.16, 895.44])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:24,426 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.258 at location [17.02, 10.59, 1509.16, 895.44]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:24,426 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:710.75|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777664,80f39946-0b73-4f9e-83e0-40fe02634474, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:24,426 [INFO ] W-9000-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:710.75|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:80f39946-0b73-4f9e-83e0-40fe02634474,timestamp:1727777664\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:24,427 [INFO ] W-9000-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 713\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:24,427 [INFO ] W-9000-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777664\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:24,427 [INFO ] W-9000-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:711903.355|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777664\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:24,427 [INFO ] W-9000-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:73.031|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777664\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:24,427 [INFO ] W-9000-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777664\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:24,427 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 711\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:24,427 [INFO ] W-9000-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777664\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:24,443 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777664\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:24,444 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777664444\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:24,444 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777664\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:24,453 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:24,457 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:24,457 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,189 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.392, [46.49, 80.79, 1547.59, 1439.22])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,189 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.392 at location [46.49, 80.79, 1547.59, 1439.22]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,190 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:746.02|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777665,31f8fe4c-29c9-4624-8310-b13bf8c34aba, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,191 [INFO ] W-9007-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:746.02|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:31f8fe4c-29c9-4624-8310-b13bf8c34aba,timestamp:1727777665\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,191 [INFO ] W-9007-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 748\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,191 [INFO ] W-9007-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777665\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,191 [INFO ] W-9007-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:747125.343|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777665\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,191 [INFO ] W-9007-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:60.811|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777665\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,191 [INFO ] W-9007-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777665\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,191 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 747\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,191 [INFO ] W-9007-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777665\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,210 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777665\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,210 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777665210\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,211 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777665\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,262 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Image size: (2474, 2560)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,270 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Processing image of size: (2474, 2560)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,270 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,989 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.153, [101.07, 217.56, 2356.59, 1508.04])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,989 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.153 at location [101.07, 217.56, 2356.59, 1508.04]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,990 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:779.18|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777665,9550c261-7dfb-4417-b8e9-f703b13491ff, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,990 [INFO ] W-9004-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:779.18|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:9550c261-7dfb-4417-b8e9-f703b13491ff,timestamp:1727777665\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,991 [INFO ] W-9004-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 781\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,991 [INFO ] W-9004-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777665\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,991 [INFO ] W-9004-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:780599.487|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777665\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,991 [INFO ] W-9004-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:95.002|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777665\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,991 [INFO ] W-9004-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777665\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,991 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 780\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:25,991 [INFO ] W-9004-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777665\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,010 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777666\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,010 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777666010\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,011 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777666\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,019 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Image size: (1500, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,021 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Processing image of size: (1500, 1000)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,022 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,729 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.184, [129.85, 108.44, 1382.91, 830.29])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,729 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.184 at location [129.85, 108.44, 1382.91, 830.29]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,730 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:719.49|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777666,f83778c4-64b0-437b-80cc-63c27ff7ae24, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,731 [INFO ] W-9006-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:719.49|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:f83778c4-64b0-437b-80cc-63c27ff7ae24,timestamp:1727777666\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,731 [INFO ] W-9006-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 721\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,731 [INFO ] W-9006-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777666\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,731 [INFO ] W-9006-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:720913.298|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777666\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,731 [INFO ] W-9006-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:59.251|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777666\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,731 [INFO ] W-9006-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777666\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,731 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 721\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,731 [INFO ] W-9006-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777666\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,748 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777666\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,748 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777666748\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,749 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777666\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,758 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Image size: (1000, 667)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,759 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Processing image of size: (1000, 667)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:26,759 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:27,488 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.357, [28.08, 40.34, 959.39, 591.82])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:27,488 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.357 at location [28.08, 40.34, 959.39, 591.82]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:27,490 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:740.74|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777667,6a9e6038-e886-455b-864d-af74138ef1d5, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:27,490 [INFO ] W-9001-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:740.74|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:6a9e6038-e886-455b-864d-af74138ef1d5,timestamp:1727777667\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:27,490 [INFO ] W-9001-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 742\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:27,490 [INFO ] W-9001-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777667\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:27,490 [INFO ] W-9001-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:741904.022|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777667\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:27,490 [INFO ] W-9001-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:57.991|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777667\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:27,490 [INFO ] W-9001-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777667\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:27,490 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 742\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:27,490 [INFO ] W-9001-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777667\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:27,508 [INFO ] epollEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777667\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:27,509 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1727777667509\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:27,509 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend received inference at: 1727777667\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:27,517 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Image size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:27,520 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Processing image of size: (1601, 1601)\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:27,520 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - texts: [['a photo of a tv', 'a photo of a dog']]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:28,266 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - detections: [('a photo of a tv', 0.392, [46.49, 80.79, 1547.59, 1439.22])]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:28,266 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Detected a photo of a tv with confidence 0.392 at location [46.49, 80.79, 1547.59, 1439.22]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:28,271 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:761.27|#ModelName:model,Level:Model|#type:GAUGE|#hostname:295673d1428f,1727777668,527e2866-4be4-498d-a08b-2bcedd23756f, pattern=[METRICS]\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:28,271 [INFO ] W-9003-model_1.0-stdout MODEL_METRICS - PredictionTime.ms:761.27|#ModelName:model,Level:Model|#hostname:295673d1428f,requestID:527e2866-4be4-498d-a08b-2bcedd23756f,timestamp:1727777668\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:28,271 [INFO ] W-9003-model_1.0 ACCESS_LOG - /172.18.0.1:44552 \"POST /invocations HTTP/1.1\" 200 763\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:28,271 [INFO ] W-9003-model_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777668\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:28,271 [INFO ] W-9003-model_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:762444.977|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777668\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:28,271 [INFO ] W-9003-model_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:93.512|#model_name:model,model_version:default|#hostname:295673d1428f,timestamp:1727777668\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:28,271 [INFO ] W-9003-model_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777668\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:28,271 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 762\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:28,271 [INFO ] W-9003-model_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777668\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:30,238 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777670\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:30,239 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:2157.0361862182617|#Level:Host|#hostname:295673d1428f,timestamp:1727777670\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:30,239 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:3950.72993850708|#Level:Host|#hostname:295673d1428f,timestamp:1727777670\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:30,239 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:64.7|#Level:Host|#hostname:295673d1428f,timestamp:1727777670\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:30,239 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12908.45703125|#Level:Host|#hostname:295673d1428f,timestamp:1727777670\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:30,239 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:18312.140625|#Level:Host|#hostname:295673d1428f,timestamp:1727777670\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:14:30,239 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:59.3|#Level:Host|#hostname:295673d1428f,timestamp:1727777670\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:15:30,238 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777730\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:15:30,238 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:2157.0361862182617|#Level:Host|#hostname:295673d1428f,timestamp:1727777730\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:15:30,238 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:3950.72993850708|#Level:Host|#hostname:295673d1428f,timestamp:1727777730\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:15:30,238 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:64.7|#Level:Host|#hostname:295673d1428f,timestamp:1727777730\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:15:30,239 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12910.30859375|#Level:Host|#hostname:295673d1428f,timestamp:1727777730\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:15:30,239 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:18310.2890625|#Level:Host|#hostname:295673d1428f,timestamp:1727777730\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:15:30,239 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:59.3|#Level:Host|#hostname:295673d1428f,timestamp:1727777730\n"
     ]
    }
   ],
   "source": [
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=sm_model_name, \n",
    "    ExecutionRoleArn=role, \n",
    "    PrimaryContainer=container,\n",
    ")\n",
    "\n",
    "import json\n",
    "texts = json.dumps([[\"a photo of a tv\", \"a photo of a dog\"]])\n",
    "\n",
    "env = {\"threshold\" : \"0.1\",\n",
    "       \"texts\" : texts}\n",
    "\n",
    "\n",
    "response = sm_client.create_transform_job(\n",
    "    TransformJobName=job_name,\n",
    "    ModelName=sm_model_name,\n",
    "    MaxConcurrentTransforms=2,\n",
    "    MaxPayloadInMB=2,\n",
    "    BatchStrategy=\"SingleRecord\", ##'MultiRecord',\n",
    "    Environment=env,\n",
    "    TransformInput={\n",
    "        'DataSource': {\n",
    "            'S3DataSource': {\n",
    "                'S3DataType': 'S3Prefix',\n",
    "                'S3Uri': input_image_path \n",
    "            }\n",
    "        },\n",
    "        'ContentType': \"application/x-image\",\n",
    "    },\n",
    "    TransformOutput={\n",
    "        'S3OutputPath': output_path,\n",
    "        'Accept': 'application/json',\n",
    "    },\n",
    "    TransformResources={\n",
    "        'InstanceType': 'ml.m5.2xlarge',\n",
    "        'InstanceCount': 1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker kill 295673d1428f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating the container in SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-322537213286/240929-deploy-owl-vit/compressed_model/model.tar.gz'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "# Set to True to enable SageMaker to run locally\n",
    "# local_mode = True\n",
    "local_mode = False\n",
    "\n",
    "if local_mode:\n",
    "    from sagemaker.local import LocalSession\n",
    "    instance_type = \"local_gpu\"\n",
    "    sm_session = LocalSession()\n",
    "    sm_session.config = {'local': {'local_code': True}}\n",
    "    sm_client = sagemaker.local.LocalSagemakerClient()\n",
    "    smr_client = sagemaker.local.LocalSagemakerRuntimeClient()\n",
    "    model_data=f\"file://{Path.cwd()}/{local_model_weight}\"\n",
    "    input_image_path = f\"file://{Path.cwd()}/ecommerce-products/tv\"\n",
    "    output_path = f\"{Path.cwd()}/batchtransform-output\"\n",
    "else:\n",
    "    instance_type = \"ml.m5.2xlarge\"\n",
    "    sm_session = sagemaker.Session()\n",
    "    sm_client = boto3.client(\"sagemaker\")\n",
    "    smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "    model_data = f\"{model_data_url}/model.tar.gz\"\n",
    "    input_image_path = f\"{s3_input_data_path}/tv\"\n",
    "    output_path = f\"s3://{bucket}/{prefix}/batchtransform-output\"\n",
    "\n",
    "instance_count = 1\n",
    "ts = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "sm_model_name = f\"{local_model_weight}-model-{ts}\"\n",
    "endpoint_config_name = f\"{local_model_weight}-endpoint-config-{ts}\"\n",
    "job_name = f\"{local_model_weight}-batchtranform-{ts}\"\n",
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "container = {\n",
    "    \"Image\": image_uri,\n",
    "    \"ModelDataUrl\": model_data,\n",
    "    \"Environment\": {}\n",
    "}\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=sm_model_name, \n",
    "    ExecutionRoleArn=role, \n",
    "    PrimaryContainer=container,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:16:30,238 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:295673d1428f,timestamp:1727777790\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:16:30,238 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:2157.036018371582|#Level:Host|#hostname:295673d1428f,timestamp:1727777790\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:16:30,238 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:3950.7301063537598|#Level:Host|#hostname:295673d1428f,timestamp:1727777790\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:16:30,238 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:64.7|#Level:Host|#hostname:295673d1428f,timestamp:1727777790\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:16:30,238 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12873.14453125|#Level:Host|#hostname:295673d1428f,timestamp:1727777790\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:16:30,238 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:18347.453125|#Level:Host|#hostname:295673d1428f,timestamp:1727777790\n",
      "85s48v32c6-algo-1-pebdz  | 2024-10-01T10:16:30,238 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:59.4|#Level:Host|#hostname:295673d1428f,timestamp:1727777790\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "texts = json.dumps([[\"a photo of a tv\", \"a photo of a dog\"]])\n",
    "\n",
    "env = {\"threshold\" : \"0.1\",\n",
    "       \"texts\" : texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = sm_client.create_transform_job(\n",
    "    TransformJobName=job_name,\n",
    "    ModelName=sm_model_name,\n",
    "    MaxConcurrentTransforms=2,\n",
    "    MaxPayloadInMB=2,\n",
    "    BatchStrategy=\"SingleRecord\", ##'MultiRecord',\n",
    "    Environment=env,\n",
    "    TransformInput={\n",
    "        'DataSource': {\n",
    "            'S3DataSource': {\n",
    "                'S3DataType': 'S3Prefix',\n",
    "                'S3Uri': input_image_path \n",
    "            }\n",
    "        },\n",
    "        'ContentType': \"application/x-image\",\n",
    "    },\n",
    "    TransformOutput={\n",
    "        'S3OutputPath': output_path,\n",
    "        'Accept': 'application/json',\n",
    "    },\n",
    "    TransformResources={\n",
    "        'InstanceType': 'ml.m5.2xlarge',\n",
    "        'InstanceCount': 1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: Completed\n",
      "Batch Transform job completed successfully.\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/1.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/10.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/100.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/101.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/102.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/103.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/104.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/105.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/106.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/107.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/108.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/109.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/11.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/110.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/111.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/112.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/113.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/114.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/115.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/116.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/117.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/118.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/119.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/12.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/120.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/121.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/122.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/123.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/124.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/125.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/126.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/127.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/128.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/129.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/13.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/130.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/131.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/132.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/133.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/134.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/135.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/136.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/137.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/138.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/139.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/14.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/140.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/141.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/142.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/143.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/144.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/145.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/146.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/147.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/148.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/149.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/15.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/150.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/151.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/152.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/153.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/154.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/155.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/156.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/157.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/158.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/159.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/16.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/160.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/161.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/162.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/163.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/164.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/165.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/166.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/167.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/168.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/169.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/17.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/170.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/171.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/172.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/173.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/174.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/175.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/176.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/177.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/178.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/179.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/18.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/180.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/181.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/182.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/183.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/184.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/185.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/186.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/187.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/188.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/189.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/19.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/190.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/191.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/192.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/193.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/194.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/195.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/196.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/197.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/198.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/199.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/2.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/20.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/21.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/22.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/23.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/24.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/25.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/26.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/27.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/28.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/29.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/3.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/30.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/31.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/32.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/33.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/34.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/35.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/36.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/37.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/38.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/39.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/4.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/40.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/41.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/42.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/43.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/44.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/45.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/46.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/47.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/48.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/49.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/5.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/50.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/51.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/52.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/53.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/54.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/55.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/56.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/57.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/58.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/59.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/6.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/60.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/61.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/62.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/63.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/64.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/65.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/66.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/67.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/68.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/69.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/7.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/70.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/71.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/72.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/73.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/74.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/75.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/76.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/77.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/78.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/79.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/8.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/80.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/81.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/82.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/83.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/84.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/85.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/86.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/87.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/88.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/89.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/9.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/90.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/91.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/92.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/93.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/94.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/95.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/96.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/97.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/98.jpg.out\n",
      "Output file: 240929-deploy-owl-vit/batchtransform-output/99.jpg.out\n"
     ]
    }
   ],
   "source": [
    "# 작업 상태 확인\n",
    "while True:\n",
    "    response = sm_client.describe_transform_job(TransformJobName=job_name)\n",
    "    status = response['TransformJobStatus']\n",
    "    print(f\"Job status: {status}\")\n",
    "    \n",
    "    if status == 'Completed':\n",
    "        print(\"Batch Transform job completed successfully.\")\n",
    "        break\n",
    "    elif status == 'Failed':\n",
    "        print(\"Batch Transform job failed.\")\n",
    "        print(response['FailureReason'])\n",
    "        break\n",
    "    \n",
    "    time.sleep(30)  # 30초마다 상태 확인\n",
    "\n",
    "# 결과 확인 (선택사항)\n",
    "s3_client = boto3.client(\"s3\")\n",
    "response = s3_client.list_objects_v2(Bucket=bucket, Prefix=f\"{prefix}/batchtransform-output\")\n",
    "for obj in response.get('Contents', []):\n",
    "    print(f\"Output file: {obj['Key']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dirname = \"./batchtransform-output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {output_dirname}\n",
    "!aws s3 sync {output_path} {output_dirname} --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "    filename            label  confidence        x        y    width   height\n",
      "0    185.jpg  a photo of a tv       0.262   485.79   296.56  2059.97  1215.47\n",
      "1    185.jpg  a photo of a tv       0.106  1097.20  1181.33  1455.07  1279.13\n",
      "2     86.jpg  a photo of a tv       0.504   109.36   235.46   969.62   794.25\n",
      "3    172.jpg  a photo of a tv       0.341    23.25   355.15   477.96   628.33\n",
      "4    172.jpg  a photo of a tv       0.373    17.97   358.35   481.88   634.66\n",
      "..       ...              ...         ...      ...      ...      ...      ...\n",
      "160  180.jpg  a photo of a tv       0.493   121.58   140.79  2389.28  1500.09\n",
      "161   11.jpg  a photo of a tv       0.574     5.36   102.36   487.99   385.75\n",
      "162    1.jpg  a photo of a tv       0.589     2.87    76.06   499.37   413.30\n",
      "163  192.jpg  a photo of a tv       0.192     0.79    -2.61   992.68   571.46\n",
      "164   58.jpg  a photo of a tv       0.461     2.16    87.97   499.48   397.29\n",
      "\n",
      "[165 rows x 7 columns]\n",
      "\n",
      "총 탐지된 객체 수: 165\n",
      "\n",
      "컬럼: ['filename', 'label', 'confidence', 'x', 'y', 'width', 'height']\n",
      "\n",
      "처음 5행 (또는 전체):\n",
      "  filename            label  confidence        x        y    width   height\n",
      "0  185.jpg  a photo of a tv       0.262   485.79   296.56  2059.97  1215.47\n",
      "1  185.jpg  a photo of a tv       0.106  1097.20  1181.33  1455.07  1279.13\n",
      "2   86.jpg  a photo of a tv       0.504   109.36   235.46   969.62   794.25\n",
      "3  172.jpg  a photo of a tv       0.341    23.25   355.15   477.96   628.33\n",
      "4  172.jpg  a photo of a tv       0.373    17.97   358.35   481.88   634.66\n",
      "\n",
      "기본 통계:\n",
      "       confidence            x            y        width       height\n",
      "count  165.000000   165.000000   165.000000   165.000000   165.000000\n",
      "mean     0.338648   124.315697   246.404121  1252.059879  1002.633333\n",
      "std      0.166206   211.865324   267.941195   597.037530   437.542108\n",
      "min      0.101000   -32.830000   -29.880000   154.340000   222.110000\n",
      "25%      0.191000    18.190000    77.600000   934.670000   683.060000\n",
      "50%      0.341000    48.790000   168.830000  1093.300000   895.440000\n",
      "75%      0.474000   109.030000   344.640000  1536.210000  1296.790000\n",
      "max      0.745000  1097.200000  1529.160000  2556.960000  2488.810000\n",
      "\n",
      "라벨별 개수:\n",
      "a photo of a tv     161\n",
      "a photo of a dog      4\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 데이터 처리 및 DataFrame 생성\n",
    "rows = []\n",
    "\n",
    "for file_path in glob.glob(output_dirname + \"/*\"):\n",
    "    # 파일 읽기\n",
    "    filename = file_path.replace(\".out\", \"\").split(\"/\")[-1]\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # JSON 파싱\n",
    "    data = json.loads(content)\n",
    "\n",
    "    for item in data:\n",
    "        label, confidence, bbox = item\n",
    "        x, y, width, height = bbox\n",
    "        rows.append({\n",
    "            'filename' : filename,\n",
    "            'label': label,\n",
    "            'confidence': confidence,\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# 추가 정보 출력\n",
    "print(f\"\\n총 탐지된 객체 수: {len(df)}\")\n",
    "print(f\"\\n컬럼: {df.columns.tolist()}\")\n",
    "\n",
    "# 처음 5행 보기 (5개 이상의 객체가 탐지된 경우)\n",
    "print(\"\\n처음 5행 (또는 전체):\")\n",
    "print(df.head())\n",
    "\n",
    "# 통계 정보\n",
    "print(\"\\n기본 통계:\")\n",
    "print(df.describe())\n",
    "\n",
    "# 라벨별 개수\n",
    "print(\"\\n라벨별 개수:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 정보:\n",
      "    filename            label  confidence        x        y    width   height\n",
      "0    185.jpg  a photo of a tv       0.262   485.79   296.56  2059.97  1215.47\n",
      "1    185.jpg  a photo of a tv       0.106  1097.20  1181.33  1455.07  1279.13\n",
      "2     86.jpg  a photo of a tv       0.504   109.36   235.46   969.62   794.25\n",
      "3    172.jpg  a photo of a tv       0.341    23.25   355.15   477.96   628.33\n",
      "4    172.jpg  a photo of a tv       0.373    17.97   358.35   481.88   634.66\n",
      "..       ...              ...         ...      ...      ...      ...      ...\n",
      "160  180.jpg  a photo of a tv       0.493   121.58   140.79  2389.28  1500.09\n",
      "161   11.jpg  a photo of a tv       0.574     5.36   102.36   487.99   385.75\n",
      "162    1.jpg  a photo of a tv       0.589     2.87    76.06   499.37   413.30\n",
      "163  192.jpg  a photo of a tv       0.192     0.79    -2.61   992.68   571.46\n",
      "164   58.jpg  a photo of a tv       0.461     2.16    87.97   499.48   397.29\n",
      "\n",
      "[165 rows x 7 columns]\n",
      "\n",
      "총 탐지된 객체 수: 165\n",
      "고유한 이미지 파일 수: 140\n",
      "\n",
      "컬럼: ['filename', 'label', 'confidence', 'x', 'y', 'width', 'height']\n",
      "\n",
      "처음 5행:\n",
      "  filename            label  confidence        x        y    width   height\n",
      "0  185.jpg  a photo of a tv       0.262   485.79   296.56  2059.97  1215.47\n",
      "1  185.jpg  a photo of a tv       0.106  1097.20  1181.33  1455.07  1279.13\n",
      "2   86.jpg  a photo of a tv       0.504   109.36   235.46   969.62   794.25\n",
      "3  172.jpg  a photo of a tv       0.341    23.25   355.15   477.96   628.33\n",
      "4  172.jpg  a photo of a tv       0.373    17.97   358.35   481.88   634.66\n",
      "\n",
      "라벨별 개수:\n",
      "a photo of a tv     161\n",
      "a photo of a dog      4\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "이미지별 탐지된 객체 수 (상위 10개):\n",
      "filename\n",
      "101.jpg    3\n",
      "28.jpg     3\n",
      "128.jpg    3\n",
      "176.jpg    2\n",
      "195.jpg    2\n",
      "41.jpg     2\n",
      "44.jpg     2\n",
      "5.jpg      2\n",
      "26.jpg     2\n",
      "199.jpg    2\n",
      "dtype: int64\n",
      "\n",
      "상위 5개 라벨의 평균 신뢰도:\n",
      "label\n",
      "a photo of a tv     0.343609\n",
      "a photo of a dog    0.139000\n",
      "Name: confidence, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 데이터 처리 및 DataFrame 생성\n",
    "rows = []\n",
    "\n",
    "for file_path in glob.glob(output_dirname + \"/*.out\"):\n",
    "    # 파일 읽기\n",
    "    filename = file_path.split(\"/\")[-1].replace(\".out\", \"\")\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # JSON 파싱\n",
    "    try:\n",
    "        data = json.loads(content)\n",
    "        for item in data:\n",
    "            label, confidence, bbox = item\n",
    "            x, y, width, height = bbox\n",
    "            rows.append({\n",
    "                'filename': filename,\n",
    "                'label': label,\n",
    "                'confidence': confidence,\n",
    "                'x': x,\n",
    "                'y': y,\n",
    "                'width': width,\n",
    "                'height': height\n",
    "            })\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error decoding JSON in file: {filename}\")\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"DataFrame 정보:\")\n",
    "print(df)\n",
    "\n",
    "# 추가 정보 출력\n",
    "print(f\"\\n총 탐지된 객체 수: {len(df)}\")\n",
    "print(f\"고유한 이미지 파일 수: {df['filename'].nunique()}\")\n",
    "print(f\"\\n컬럼: {df.columns.tolist()}\")\n",
    "\n",
    "# 처음 5행 보기\n",
    "print(\"\\n처음 5행:\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# 라벨별 개수\n",
    "print(\"\\n라벨별 개수:\")\n",
    "label_counts = df['label'].value_counts()\n",
    "print(label_counts)\n",
    "\n",
    "# 시각화: 라벨별 개수 막대 그래프\n",
    "plt.figure(figsize=(12, 6))\n",
    "label_counts.plot(kind='bar')\n",
    "plt.title('Object Detection Results: Label Counts')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 신뢰도 분포 히스토그램\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['confidence'], bins=20, kde=True)\n",
    "plt.title('Distribution of Confidence Scores')\n",
    "plt.xlabel('Confidence')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# 이미지별 탐지된 객체 수\n",
    "objects_per_image = df.groupby('filename').size().sort_values(ascending=False)\n",
    "print(\"\\n이미지별 탐지된 객체 수 (상위 10개):\")\n",
    "print(objects_per_image.head(10))\n",
    "\n",
    "# 상위 5개 라벨의 평균 신뢰도\n",
    "top_5_labels = label_counts.head().index\n",
    "avg_confidence = df[df['label'].isin(top_5_labels)].groupby('label')['confidence'].mean().sort_values(ascending=False)\n",
    "print(\"\\n상위 5개 라벨의 평균 신뢰도:\")\n",
    "print(avg_confidence)\n",
    "\n",
    "# 시각화: 바운딩 박스 크기 vs 신뢰도 산점도\n",
    "df['bbox_area'] = df['width'] * df['height']\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='bbox_area', y='confidence', data=df, alpha=0.5)\n",
    "plt.title('Bounding Box Area vs Confidence')\n",
    "plt.xlabel('Bounding Box Area')\n",
    "plt.ylabel('Confidence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
